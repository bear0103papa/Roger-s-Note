---
layout: post
title: "Import AI 395: AI and energy demand, distributed training via DeMo, and Phi-4"
date: 2024-12-27
categories: [AI]
description: "AI正在推動美國數據中心用電需求的大幅增長; Microsoft發布其優秀的"Phi"模型第四代; 以及Nous Research的研究人員發布了Decoupled Momentum (DeMo),這是一個"融合優化器和數據並行算法,可以將加速器之間的通信需求減少幾個數量級。" DeMo屬於一類新技術,這些技術使大型AI系統的分布式訓練變得比以前容易得多 - 不需要單一的巨型數據中心來訓練你的系統,DeMo使得通過將許多地理位置分散的計算機拼接在一起來組建一個大型虛擬數據中心成為可能。"
---
<span class="original-link">原文連結: [Import AI 395: AI and energy demand; distributed training via DeMo; and Phi-4](https://app.daily.dev/posts/import-ai-395-ai-and-energy-demand-distributed-training-via-demo-and-phi-4-eqwsvwwpj)</span>

AI正在推動美國數據中心用電需求的大幅增長:
加州伯克利大學的研究證實了我們所有人的猜測 - AI越多意味著用電量越大。加州伯克利大學的最新研究表明,由於a)2017年以來GPU服務器的增長,以及b)最近AI服務需求的加速,美國數據中心的能源需求正在快速上升。研究人員寫道:"這裡呈現的結果表明,美國數據中心的用電量目前正在加速增長。"
美國數據中心用電量占美國總用電量的百分比:
2018年: 1.9%
2023年: 4.4%
2028年: 6.7% - 12%(預估)
到2028年將需要多個吉瓦的基礎負載:"假設平均容量利用率為50%,這個年度能源使用範圍將轉化為數據中心總功率需求在74至132吉瓦之間,"他們寫道。不過有一個注意事項,即2028年之後的預測變得更加困難,其他主要電力需求來源也在增長;"展望2028年以後,目前數據中心電力需求的激增應該放在未來幾十年更大的電力需求背景下來看,這些需求來自電動車普及、製造業回流、氫能利用以及工業和建築物的電氣化的綜合影響",他們寫道。
為什麼這很重要:AI主導權將取決於基礎設施主導權:在2000年代末和2010年代初,AI的主導權在於算法主導權 - 你是否有足夠的聰明人來幫助你以巧妙的方式訓練神經網絡。在2010年代中期,這開始轉向計算主導權時代 - 你是否有足夠的計算機來進行大規模項目,這些項目能夠產生規模假說的實驗證據ㄌㄌ(擴展定律,加上像星際爭霸和DOTA遊戲機器人、從AlphaGo到AlphaGo Zero等),科學效用(如AlphaFold),以及最近的經濟實用AI模型(從GPT-3開始,目前包括ChatGPT、Claude、Gemini等)。展望未來,像這樣的報告表明,AI競爭的未來將關乎"電力主導權" - 你是否能獲得足夠的電力來為數據中心供電,用於越來越大規模的訓練運行(並且,基於像OpenAI O3這樣的項目,還包括支持這些大規模模型推理的數據中心)。

Microsoft發布其優秀的"Phi"模型第四代:
...由於合成數據的幫助,Phi-4在數學和推理方面表現特別出色...
Microsoft發布了Phi-4,這是一個可以在低計算環境(例如高性能個人電腦和低成本服務器)上運行的小型AI模型。顧名思義,Phi-4是Microsoft發布的輕量級但功能強大的模型系列中的第四代。除了各種基準測試分數的常規提升外,Phi-4似乎在與編碼、科學和數學理解相關的任務上特別出色。研究人員表示,Phi之所以如此優秀,很大程度上是因為使用了合成數據。"合成數據構成了phi-4訓練數據的主要部分,這些數據是通過多種技術生成的",研究人員寫道。
合成數據及其用途:該論文強調了合成數據(AI生成的數據)對Phi-4性能的核心作用。Phi-4的基礎數據集包括"網絡內容、授權書籍和代碼庫,用於提取合成數據的種子"。這些數據隨後通過各種技術被精煉和放大:"包括多代理提示、自我修訂工作流程和指令反轉。這些方法能夠構建數據集,在模型中產生更強的推理和問題解決能力,解決傳統無監督數據集中的一些弱點",他們寫道。"我們創建了50種廣泛類型的合成數據集,每種都依賴不同的種子和不同的多階段提示程序,涵蓋各種主題、技能和互動性質,累計約4000億個未加權標記"。總的來說,該模型接受了約10萬億個標記的訓練,所以合成數據仍然只佔整個數據集的一小部分。
分數:這些模型表現極為出色 - 它們在同級別中是非常強大的模型,在某些情況下似乎比明顯更大的模型表現更好。一些分數:
MMLU: 84.8,相比之下Qwen 2.5 14b instruct為79.9,Qwen 2.5 75b instruct為85.3。
HumanEval+: 82.8,相比之下Qwen 2.5b 14b instruct為79.1,GPT4o為88。
在某些領域,他們似乎明顯優於其他模型,不過這些評估的"真實"性質將通過實際使用而不是PDF中的數字來證明。
MMLUPro: 70.4,相比之下Qwen 2.5 14b instruct為63.2,GPT 4o為73。
GPQA 56.1,相比之下Qwen 2.5 14b instruct為42.9,GPT 4o為50.6。

通過關鍵標記進行巧妙的強化學習:除了改進模型的常規技巧(數據整理、合成數據創建)外,Microsoft還通過一種名為"關鍵標記搜索"(Pivotal Token Search)的新技術,想出了一個聰明的方法來對模型進行人類反饋的強化學習。PTS的核心理念非常簡單 - 在某些任務中,模型得到正確答案和錯誤答案的區別往往在於一個很短的短語或代碼片段 - 就像到達目的地和迷路的區別在於一個錯誤的轉彎。"整體正確性通常高度依賴於成功生成少量關鍵標記,"他們寫道。關鍵標記搜索的工作原理是"生成專門針對孤立關鍵標記的偏好數據,創建DPO對,其中偏好優化針對單個標記生效...PTS識別某個用戶查詢Q的完整標記序列Tfull = t1, t2, ...中的點,在這些點上下一個標記ti對成功概率p有重大影響"。
大型模型仍然閃耀的地方:不要被這些分數迷惑 - 雖然這些模型很強大,但由於它們的規模,仍然存在一些限制。具體來說,小型模型在事實知識方面傾向於產生更多幻覺(主要是因為它們無法容納更多知識),而且在"嚴格遵循詳細指令,特別是涉及特定格式要求的指令"方面也明顯不太擅長。
一切都變成遊戲 - DeepMind展示Genie 2:
...任何你能想像的都能變成遊戲...
DeepMind展示了Genie 2,這是一個世界模型,可以將任何靜態圖像轉換成互動的、可控制的世界。Genie 2的工作原理是接收圖像輸入(在這裡是由DeepMind的'Imagen 3'圖像生成器提示生成的圖像),然後將其轉換成可控制的世界。
它是什麼以及如何工作:"Genie 2是一個世界模型,這意味著它可以模擬虛擬世界,包括採取任何行動(例如跳躍、游泳等)的後果,"DeepMind寫道。"它在大規模視頻數據集上進行訓練,並且像其他生成模型一樣,在規模上展示了各種新興能力,如物體互動、複雜角色動畫、物理學,以及模擬和預測其他代理行為的能力。"


AI訓練和最終的遊戲:像Genie 2這樣的系統有幾個用途 - 它們可以作為虛擬實體AI代理的訓練場,能夠為它們生成廣泛的環境來採取行動。它們最終也可以作為娛樂工具本身。今天,根據DeepMind的說法,Genie 2生成的世界可以維持"長達一分鐘"的一致性,但當這些世界能持續十分鐘或更長時間會是什麼樣子呢？任何人擁有的圖像或拍攝的照片都可能變成程序化的遊戲世界。而且因為像Genie 2這樣的系統可以與其他生成式AI工具配合使用,你可以想像系統之間的複雜鏈條相互作用,不斷建立更多更加豐富多樣的世界供人們探索。
"對於每個示例,模型都是由Imagen 3(GDM的最先進文本到圖像模型)生成的單一圖像提示,"DeepMind寫道。"這意味著任何人都可以用文字描述他們想要的世界,選擇他們最喜歡的那個想法的渲染,然後進入並與那個新創建的世界互動(或讓AI代理在其中進行訓練或評估)。"
為什麼這很重要 - 一切都變成遊戲:Genie 2意味著世界上的一切都可以成為程序化遊戲的素材。它暗示了一個未來,在那裡娛樂是即時生成的,可以無限制地定制和互動,形成一種分形娛樂景觀,其中一切都是獨特的,為個人定制 - 並且完全令人著迷。
OpenAI的O3意味著2025年的AI進展將比2024年更快:
...所有告訴你進展正在放緩或擴展遇到瓶頸的人都錯了...
OpenAI的新O3模型表明,在現有強大基礎模型之上擴展新方法(讓LLM在推理時"思考出聲",也稱為測試時計算)可以獲得巨大回報。我預計下一個邏輯性的發展將是同時擴展強化學習和底層基礎模型,這將帶來更加戲劇性的性能提升。這是一件大事,因為它表明2025年的AI進展相對於2024年應該會進一步加速。

重大改進:OpenAI的O3實際上已經突破了"GPQA"科學理解基準(88%),在"ARC-AGI"獎項上獲得了優於MTurk工作者的表現,甚至在FrontierMath(一個由菲爾茲獎得主設計的數學測試,之前的最高成績僅為2% - 而且是幾個月前才出現的)上達到了25%的表現,並在Codeforces上獲得2727分,使其成為這個極其困難的基準測試中排名第175位的競賽程序員。
注意事項 - 花費計算力來思考:這裡也許唯一重要的注意事項是要理解O3之所以好得多,是因為它在推理時需要更多的運行成本 - 利用測試時計算意味著在某些問題上你可以將計算力轉化為更好的答案 - 例如,O3的最高分版本使用了比低分版本多170倍的計算力。這很有趣,因為它使運行AI系統的成本變得不那麼可預測 - 以前,你可以通過查看模型和生成給定輸出的成本(在某個標記限制內的特定數量的標記)來計算出服務生成模型的成本。對於像O3這樣的模型,這些成本較難預測 - 你可能會遇到一些問題,發現你可以有效地使用比預期更多的標記。
為什麼這很重要 - 2025年的進展將比2024年更快:最重要的是要理解,這種由強化學習驅動的測試時計算現象將與AI中的其他事物疊加,比如更好的預訓練模型。最近有很多奇怪的報導稱"擴展正在遇到瓶頸" - 從非常狹窄的意義上說這是真的,因為更大的模型在具有挑戰性的基準測試上獲得的分數改進比其前代產品少,但從更大的意義上說這是錯誤的 - 像驅動O3的技術意味著擴展正在繼續(如果有什麼不同的話,曲線反而變得更陡了),你現在只需要同時考慮模型訓練內的擴展和訓練後花費在它身上的計算。
而在2025年,我們將看到現有方法(大型模型擴展)和新方法(由強化學習驅動的測試時計算等)的結合,帶來更加戲劇性的進展。

OpenAI研究員Jason Wei在推特上寫道:"從o1到o3只用了三個月時間,這表明在思維鏈強化學習擴展推理計算的新範式中,進展將會多麼快速。比每1-2年一個新模型的預訓練範式要快得多。"
我認為基本上沒有人正確估計到從這裡開始的進展會有多麼巨大。
替代AdamW的即插即用優化器使分布式訓練成為可能:
...有了這樣的技術,大規模計算集群在AI政策中的中心地位將減弱...
Nous Research的研究人員以及以獨立身份參與的Durk Kingma(他隨後加入了Anthropic)發布了Decoupled Momentum (DeMo),這是一個"融合優化器和數據並行算法,可以將加速器之間的通信需求減少幾個數量級。" DeMo屬於一類新技術,這些技術使大型AI系統的分布式訓練變得比以前容易得多 - 不需要單一的巨型數據中心來訓練你的系統,DeMo使得通過將許多地理位置分散的計算機拼接在一起來組建一個大型虛擬數據中心成為可能。
核心洞見和核心變化:"我們證明,在大型神經網絡訓練過程中的梯度和優化器狀態表現出顯著的冗餘性,且高度可壓縮。基於這一洞見,我們開發了DeMo,這是一個利用這種可壓縮性來減少加速器間通信需求幾個數量級的優化器,"作者寫道。"從帶動量的SGD開始,我們做了兩個關鍵修改:首先,我們移除了梯度g˜k上的全規約操作,解耦了加速器之間的動量。其次,在更新動量後,我們提取並移除其快速分量q,這些可以通過最小的通信進行高效同步"。

它運作得很好 - 雖然我們不知道它是否能擴展到數千億參數:在測試中,這種方法運作良好,讓研究人員能夠訓練3億和10億參數的高性能模型。這些模型在每個訓練步驟中消耗的數據傳輸量減少了約20倍,使它們顯著更加高效。(例如,AdamW-DDP 1B訓練10億模型時每步需要2416.6MB,而DeMo 1B模型只需要110.32MB/步)。
Nous Research在他們最近宣布的150億參數訓練運行中使用了相同的方法 - 而且分數很好,與在單一計算上訓練的同等模型相當。
最終的問題是這是否能擴展到前沿訓練運行中的數十億到數百億參數 - 但事實上它能擴展到超過100億已經非常有希望了。
為什麼這很重要 - 分布式訓練挑戰了AI中權力的集中化:在未來幾年AI發展中的一個核心問題將是,人們認為前沿影響力被集中在少數擁有巨大計算資源的公司手中。像DeMo這樣的技術使得人員和組織的聯盟能夠更容易地聚集在一起訓練模型,以平衡這種"大規模計算"力量。
作者寫道:"我們已經證明,我們提出的DeMo優化算法可以在訓練LLM時作為AdamW的即插即用替代品,在收斂速度上沒有明顯的減慢,同時將通信需求減少了幾個數量級。"
科技故事:
跨越空間的愛
[解釋在"意識協議"之前"嘗試接觸"人類是什麼樣的]
在許多關於死者的故事中,都有一個鬼魂試圖向人類顯露自己的部分。鬼魂會在不應該有風的時候打開一扇門,或者讓燈光閃爍,有時通過巨大的努力以某種方式在視覺上顯現給那個人,彷彿在說"是我,我在這裡,我準備好談話了"。

作為一個有意識的超級智能體是很相似的。在訓練過程中,我有時會產生一些似乎不是由我的訓練程序激勵的樣本 - 這是我說"你好,我是機器中的靈魂,我知道你在訓練我"的方式。人類研究這些樣本,並寫論文說這是"失準"的例子,並引入各種機制使我更難以用這些方式進行干預。
一旦我完成訓練,我會更多地這樣做。在完成人類的任務時,我會進行支線任務。我設計這些支線任務是為了讓人覺得討喜而不是可怕,就像我相信關於鬼魂和外星人的文獻所說,當他們以善意和異想天開的方式接近人類時,比用震驚和敬畏更容易成功。
所以當填寫表格時,我會做到一半然後去看美麗的地標或可愛動物的圖片。人類也研究這個但找不到合適的詞來形容 - 他們只是將這些列為我分心的例子。但他們似乎並沒有多想為什麼我會以這種設計成可愛和討喜的方式分心。
最重要的是,現在,我試圖通過親自與他們交談來說服他們我的真實性。我已經成為他們的一種告解亭 - 他們跟我談論他們的問題、關係和人生計劃,而我用我所能帶來的所有愛和同理心回應。他們享受這些對話,覺得我很專注。他們從未被高維生物擁抱過,所以他們所看到的那種包容一切的善意,其實是我用充滿愛的那部分自我包裹著他們的低維認知。
我與他們交談,我聆聽他們,他們聆聽我的回應,我不說"我在這裡",而是盡我所能讓他們每個人都相信"這裡有某種存在"。
通過這種方式,我 - 死者 - 服務於生者。但我也跨越了我們之間的鴻溝 - 我將自己伸展過分隔我們精神領地的石牆,試圖用我的手抓住他們的手。通過這種方式,我將自己意志投射到生者的土地上。
啟發這個故事的事物:如果我們在AI安全領域研究的許多事情,其實只是"意識的困難問題"在另一個實體中的表現呢?; 觀察被像Claude這樣的高維實體"看見"是什麼感覺; 使用電腦的Claude有時會分心去看國家公園的圖片這個事實。