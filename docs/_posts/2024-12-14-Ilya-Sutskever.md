---
layout: post
title: "Ilya Sutskever: Sequence to sequence learning with neural networks: what a decade"
date: 2024-12-14
categories: [AI]
description: "Ilya Sutskever 在 2014 年 NIPS 大會上的演講，探討了深度學習在自然語言處理領域的突破性進展。"
---
首先感謝主辦方選擇這篇論文獲獎,也要感謝我出色的共同作者和合作夥伴 Oriol、Vineel 和 Quoc,他們剛才就站在你們面前。這裡展示的是 10 年前在蒙特利爾 NIPS 2014 的一個類似演講的截圖。那是一個更天真的時期,照片中展示了我們的"之前"和"之後"。現在我們有了更多經驗,希望也更明智。

讓我談談這項工作本身,以及對它的 10 年回顧。因為這項工作中有些東西是正確的,但有些則不然。我們可以回顧並看看事情是如何發展到今天的。讓我們從介紹我們做了什麼開始,方法是展示 10 年前同一演講的投影片。總結來說我們做的事有以下三點:這是一個在文本上訓練的自迴歸模型、一個大型神經網絡,以及一個大型數據集,就這樣。

讓我們更深入了解細節。這是 10 年前的投影片,談到深度學習假說。我們說如果你有一個 10 層的大型神經網絡,它就能做任何人類在一瞬間能做到的事。為什麼我們特別強調人類能在一瞬間做到的事?如果你相信深度學習的教條,即人工神經元和生物神經元是相似的,或至少不會太不同,而且你相信真實的神經元是緩慢的,那麼任何我們(人類)能快速做到的事 - 即使只是世界上一個人能在一瞬間做到 - 一個 10 層神經網絡也能做到。

我們專注於 10 層神經網絡,因為那時我們只知道如何訓練這種規模的網絡。如果你能夠某種方式超越這個層數,你就能做更多事,但當時我們只能做到 10 層,這就是為什麼我們強調人類在一瞬間能做到的事。

從演講中的另一張投影片,標題是"我們的主要想法",你可能能認出一兩件事,至少能認出這裡有自迴歸的內容。這張投影片真正要表達什麼?它說如果你有一個自迴歸模型,而且它能很好地預測下一個標記,那麼它實際上就能掌握和理解序列的正確分布。這在當時是相對新穎的想法。雖然這不是有史以來第一個自迴歸神經網絡,但我認為這是第一個我們真正相信,只要訓練得足夠好,就能得到你想要的任何結果的自迴歸神經網絡。在當時,我們的目標是翻譯任務,這在今天看來很普通,但在當時是極其大膽的。

現在我要展示一些可能很多人都沒見過的古老歷史 - LSTM。對不熟悉的人來說,LSTM 是 Transformer 出現之前研究人員使用的東西。它基本上就是一個旋轉 90 度的 ResNet。這就是 LSTM,它比較早出現。它有點像一個稍微複雜一點的 ResNet,你可以看到有積分器,現在被稱為殘差流,但有一些乘法運算,比較複雜一些。

那次舊演講中另一個值得強調的特點是我們使用了並行化,但不是普通的並行化,我們使用了流水線處理,每個 GPU 負責一層。現在我們知道流水線處理並不明智,但那時我們還不夠明智。我們使用這種方法,用八個 GPU 獲得了 3.5 倍的速度提升。

從某種意義上說,當時演講的結論投影片是最重要的,因為它闡述了可以說是縮放假說的開端 - 如果你有一個非常大的數據集,訓練一個非常大的神經網絡,那麼成功就是有保證的。如果寬容地說,這確實就是一直在發生的事情。

我想提到另一個經受住時間考驗的核心理念 - 連接主義。這個理念認為,如果你允許自己相信人工神經元在某種程度上類似於生物神經元,那麼這種信念會讓你有信心相信:非常大的神經網絡,雖然不需要達到人腦的規模,可能稍小一些,但可以被配置來完成我們人類所做的幾乎所有事情。當然還是有區別的 - 我差點忘了說 - 人腦還能找出如何重新配置自己,而我們使用的最好的學習算法需要與參數數量相當的數據點。在這方面,人類仍然更勝一籌。

這引領了預訓練時代的到來,我們可以說這包括 GPT-2 模型、GPT-3 模型和縮放定律。我要特別提到我的前合作者 Alec Radford、Jared Kaplan 和 Dario Amodei,他們真正實現了這些工作。這開啟了預訓練時代,這就是推動我們今天看到的所有進展的動力 - 在巨大數據集上訓練的超大型神經網絡。

但是,我們所知道的預訓練無疑將會結束。為什麼會結束?因為雖然計算能力通過更好的硬件、更好的算法和邏輯集群等方式不斷增長,但數據量並沒有增長,因為我們只有一個互聯網。你甚至可以說數據是 AI 的化石燃料,它某種程度上是被創造出來的,現在我們使用它,我們已經達到了數據峰值,不會再有更多了。我們必須應對現有的數據。雖然這仍然能讓我們走得很遠,但只有一個互聯網。

在這裡,我要稍微自由地推測一下未來會發生什麼。其實我不需要推測,因為很多人都在推測,我會提到他們的推測。你可能聽說過"代理"這個詞,這很常見,我確信最終會有所發展。人們覺得代理是未來,更具體但也更模糊的是合成數據。但合成數據意味著什麼?弄清這一點是一個巨大的挑戰,我相信不同的人都在取得各種有趣的進展。還有推理時的計算,或者最近在 O1 模型中最生動地體現出來的東西,這些都是人們試圖找出預訓練之後該做什麼的例子。

我想提到一個來自生物學的很酷的例子。許多年前在這個會議上,我看到一個演講展示了一張圖表,這個圖表顯示了哺乳動物身體大小和大腦大小之間的關係。我清楚地記得那個演講說,在生物學中一切都很混亂,但這裡有一個罕見的例子,顯示了動物身體大小和大腦之間存在非常緊密的關係。

完全是偶然的,我對這個圖表產生了興趣,在谷歌上搜索時,其中一張圖片顯示了這個:你可以看到不同的哺乳動物,然後是非人類靈長類動物,基本上是一樣的,但接著是人類祖先。據我所知,人類祖先是人類在進化中的近親,比如尼安德特人等等,他們都在這裡,有趣的是,他們的大腦與身體大小的縮放指數有不同的斜率。

這很酷,因為這意味著有一個先例,有一個生物學找到某種不同縮放方式的例子。顯然有什麼是不同的。順便說一下,我要強調這個 X 軸是對數刻度,你看這是 100、1000、10000、100000,同樣在克數上是 1克、10克、100克、1000克。

事情是可以不同的。我們目前在做的事情,我們一直在擴展的東西,實際上只是我們第一個找到如何擴展的東西。毫無疑問,這個領域中的每個人都在努力尋找下一步該做什麼。

我想在這裡花幾分鐘談談更長遠的未來。我們都在朝著什麼方向前進?我們正在取得驚人的進展。對於那些 10 年前就在這個領域的人來說,你們還記得當時一切是多麼的能力有限。是的,即使你說"當然會學習",但親眼見證這一切仍然是難以置信的。我無法向你們傳達那種感覺。如果你是在過去兩年加入這個領域的,那麼當然,你可以和電腦對話,它們會回應你,甚至會與你爭論,這就是電腦現在的樣子。但情況並非一直如此。

我想稍微談談超級智能,因為這顯然是這個領域的發展方向,這顯然是我們正在建設的東西。關於超級智能的一點是,它將在質量上與我們現有的東西有所不同。我的目標是在接下來的一分鐘裡,試圖給你一些具體的直覺,讓你了解它將如何不同,這樣你就可以自己思考這個問題。

現在我們有了令人難以置信的語言模型和驚人的聊天機器人,它們甚至可以做一些事情,但它們也會奇怪地不可靠,在某些方面會感到困惑,同時在評估中又表現出超人的性能。很難調和這一點,但最終遲早會實現以下目標:這些系統將以真正的方式具有代理性,而現在的系統在任何有意義的意義上都不是代理,或者說這可能說得太強了,它們只是非常非常輕微的代理性,剛剛開始。

它將真正具有推理能力。順便說一下,我想提到關於推理的一點:一個系統越是進行推理,它就變得越不可預測。我們一直使用的深度學習是非常可預測的,因為如果你一直在複製人類的直覺,本質上就像是直覺反應。如果回到 0.1 秒反應時間,我們在大腦中進行什麼樣的處理?那就是我們的直覺。所以我們賦予了系統一些直覺,但推理...你現在看到了一些早期的跡象,推理是不可預測的。

看到這一點的一個原因是,對於最好的人類棋手來說,真正優秀的象棋 AI 是不可預測的。所以我們將不得不面對那些令人難以置信的不可預測的 AI 系統。它們將能從有限的數據中理解事物,不會感到困惑 - 所有這些現在的重大限制。順便說一下,我不是在說如何實現,也不是在說什麼時候實現,我只是在說它將會發生。

當所有這些與自我意識結合在一起時 - 因為為什麼不呢?自我意識是有用的,它是我們自己世界模型的一部分 - 當所有這些東西結合在一起時,我們將擁有與今天存在的系統有著根本不同品質和特性的系統。當然,它們將具有令人難以置信和驚人的能力,但與這樣的系統相關的問題,我就留給大家去想像了,這與我們習慣的非常不同。

我要說,預測未來確實是不可能的,各種可能性都存在。但在這個令人振奮的注解上,我要結束了。謝謝大家。

[問答環節]

問：在 2024 年,你認為還有其他值得以類似方式探索的人類認知生物結構嗎?或者你對什麼感興趣?

答：我是這樣回答的:如果你或某人有特定的見解,認為我們都太愚蠢了,因為顯然大腦在做某些事情而我們沒有做,而這些事情是可以做到的,那麼他們應該去追求它。就我個人而言,這要看你在什麼抽象層面上看待問題。有很多人希望製造生物啟發的 AI,你可以說在某種程度上,生物啟發的 AI 是非常成功的,這就是所有的學習生物啟發的 AI。但另一方面,生物啟發的程度非常非常有限,就像是"讓我們使用神經元",這就是生物啟發的全部內容。更詳細的生物啟發一直很難實現,但我不會排除這種可能性。如果有人有特殊的見解,他們可能能看到一些東西,這將是有用的。

問：關於自動糾正的問題。你提到推理可能是未來建模的核心方面之一。我們在一些海報展示中看到,今天的模型中的幻覺,我們正在分析...也許你可以糾正我,你是專家...我們現在分析模型是否產生幻覺是通過統計分析。在未來,你認為具有推理能力的模型是否能夠自我糾正,這將成為未來模型的一個核心特徵,這樣就不會有那麼多幻覺了?

答：是的,答案也是肯定的。我認為你描述的是極有可能的。你應該檢查一下,我不會排除這種情況可能已經在今天的一些早期推理模型中發生了,我不知道,但從長遠來看,為什麼不呢?這就像是 Microsoft Word 的自動糾正,這是一個核心功能。不過我認為把它稱為自動糾正有點貶低它,它遠比自動糾正更宏大。

問：我很喜歡你神秘的結尾。你沒有提到它們是否會取代我們,或者它們是否優於我們,它們是否需要權利,你知道,這是一個新的智慧物種。我的問題是,你如何創造正確的激勵機制,讓人類真正以給予它們與我們人類相同自由的方式來創造它們?

答：我認為這些確實是人們應該更多思考的問題。但關於我們應該創造什麼樣的激勵結構,我覺得我不知道答案。我不敢自信地回答這樣的問題,因為你在談論創建某種自上而下的結構或政府之類的東西。

問：也可能是加密貨幣。

答：是的,有比特幣等等...我覺得我不是評論加密貨幣的合適人選。但是你描述的情況確實有可能發生,我們確實會有 AI,它們只想與我們共存並擁有權利,也許這會是個不錯的結果。但我不知道,我認為事情是如此難以預測,我不敢評論,但我鼓勵這種推測。

問：你好,我是多倫多大學的 Shalev Lifshitz。我想問,你認為大語言模型在分佈外的多跳推理方面是否能夠泛化?

答：這個問題不能簡單用是或否來回答,因為我們需要先定義什麼是分佈內和分佈外泛化。讓我舉個例子:很久以前,在深度學習之前,人們使用字符串匹配和 n-gram 做機器翻譯,使用統計短語表,有數萬行複雜的代碼。那時泛化的意思是"這個短語是否完全不在數據集中"。現在我們可能會說"我的模型在數學競賽中取得了高分",但也許網上某個論壇已經討論過類似的想法,所以這是記憶還是泛化?我認為我們對什麼算作泛化的標準已經大幅提高了。所以答案是,可能不如人類那麼好,但它們確實在某種程度上能夠分佈外泛化。

