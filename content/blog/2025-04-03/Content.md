---
layout: post
title: "Yann LeCun 與 Bill Dally 對談：超越大型語言模型，探索 AI 的未來"
date: 2025-04-03
categories: [
  '2024',
  '人工智慧',
  '科技訪談',
  'Yann LeCun',
  'Bill Dally'
]
description: "AI 先驅 Yann LeCun 和 NVIDIA 首席科學家 Bill Dally 深入探討了當前 AI 的發展，特別是大型語言模型的局限性，以及未來 AI 在理解物理世界、推理、規劃和記憶方面的挑戰與方向。他們還討論了開源、硬體需求和 AI 的社會影響。"
toc: true  # 啟用目錄功能

---

<span class="original-link">原文連結： [Yann LeCun 與 Bill Dally 對談：超越大型語言模型，探索 AI 的未來](https://www.youtube.com/watch?v=UYnm_h6EPFg&ab_channel=cestlapinlapin)</span>

## Yann LeCun 與 Bill Dally 對談：超越大型語言模型，探索 AI 的未來

請歡迎 Bill Dally 和 Yann LeCun 大家好，嗯，我們就來聊聊關於 AI 的事情，希望，呃，你們會覺得有趣。那麼，嗯，Yann，過去一年 AI 領域發生了很多有趣的事情，在你看来，過去一年中最令人興奮的發展是什麼？

呃，多到數不清，但我告訴你一件事，可能會讓你們中的一些人驚訝，嗯，我對大型語言模型（LLM）不再那麼感興趣了。你知道，它們有點像是最後的事情，它們掌握在，你知道的，產業產品人員手中，有點，你知道的，在邊際上改進，呃，試圖獲取，你知道的，更多數據、更多算力，生成合成數據。

嗯，我認為在四個方面有更有趣的問題：你如何讓機器理解物理世界？

Jensen 今天早上在他的主題演講中談到了這一點。你如何讓它們擁有持久的記憶？這一點沒有太多人談論。然後最後兩個是，你如何讓它們進行推理和規劃？當然，有一些努力試圖讓，你知道的，LLM 進行推理，但在我看來，這是一種非常，有點，簡化的看待推理的方式。我認為可能有，你知道的，更好、更優的方式來做這件事。所以，嗯，所以我對那些在這個社群、在科技社群中很多人可能在五年後才會感到興奮的事情感到興奮。嗯，但現在看起來不那麼令人興奮，因為它是一些晦澀的學術論文。

但如果不是 LLM 在推理物理世界、擁有持久記憶和規劃，那會是什麼？底層模型會是什麼？

## 世界模型：理解物理世界的關鍵

嗯，很多人正在研究世界模型，對吧？那麼什麼是世界模型？世界模型是，我們所有人的頭腦中都有世界模型。這使我們能夠，嗯，基本上，你知道的，操縱思想。所以，你知道，我們有一個當前世界的模型，你知道如果我從頂部推這個瓶子，它可能會翻倒，但如果我從底部推它，它會滑動。

嗯，你知道，如果我壓得太用力，它可能會爆開。所以我們有物理世界的模型，我們在生命的最初幾個月就獲得了這些模型，這就是我們能夠應對現實世界的原因。處理現實世界比處理語言要困難得多。所以我認為，我們需要的能夠真正處理現實世界的系統架構，與我們目前處理的架構完全不同。對吧，LLM 預測詞元（token），對吧？但詞元可以是任何東西。我的意思是，所以我們的，你知道的，自動駕駛汽車模型使用詞元，來自感測器的詞元，它產生驅動汽車的詞元，在某種意義上，它是在推理物理世界，至少是關於哪裡開車安全，不會撞到柱子。

嗯，為什麼詞元不是表示物理世界的正確方式？

詞元是離散的，好的。所以當我們談論詞元時，通常我們談論的是一個有限的可能性集合。在一個典型的 LLM 中，可能的詞元數量大約是 10 萬個左右，對吧？嗯，所以當你訓練一個系統來預測詞元時，你永遠無法訓練它預測文本序列中確切的下一個詞元。但你可以產生一個關於你字典中所有可能詞元的機率分佈，你知道，它只是一個包含 10 萬個介於零和一之間且總和為一的數字的長向量。我們知道如何做到這一點。我們不知道如何用，呃，用視頻，用那些高維度且連續的自然數據來做到這一點。每一次試圖讓系統理解世界或建立世界的心理模型，透過訓練來預測像素級別的視頻，基本上都失敗了。嗯，即使是訓練像某種神經網路這樣的系統來學習圖像的良好表示，每種試圖透過從損壞或轉換過的版本重建圖像的技術，基本上都失敗了。並非完全失敗，它們有點用，但效果不如我們稱之為聯合嵌入（joint embedding）的替代架構，這些架構基本上不試圖在像素級別進行重建，它們試圖學習圖像、視頻或正在訓練的自然信號的表示，一種抽象表示，以便你可以在那個抽象表示空間中進行預測。嗯，我經常用的一個例子是，如果我拍攝這個房間的視頻，我移動相機，停在這裡，然後我要求系統預測，你知道的，那個視頻的後續內容是什麼，它可能會預測這是一個房間，裡面有人坐著等等。它無法預測你們每一個人長什麼樣，對吧？這從視頻的初始片段來看是完全不可預測的。所以世界上有很多事情是根本無法預測的。如果你訓練一個系統在像素級別進行預測，它會花費所有資源試圖想出它根本無法創造的細節。所以這完全是浪費資源。

我們嘗試過的每一次嘗試，我已經研究這個 20 年了，使用自我監督學習通過預測視頻來訓練系統，都行不通。只有當你在表示層面進行時才有效。這意味著那些架構不是生成式的。


你基本上是說 Transformer 沒有能力... 但是人們有視覺 Transformer (Vision Transformer)，他們得到了很好的結果。

## 抽象表示 vs. 詞元：JEPA 架構的興起

我不是那個意思，因為你可以為此使用 Transformer，對吧？你可以將 Transformer 放入那些架構中，只是，呃，我所說的那種架構叫做 JEPA，聯合嵌入預測架構 (Joint Embedding Predictive Architecture)，對吧？所以取一段視頻或一張圖像或其他任何東西，甚至文本，將其通過一個編碼器，你得到一個表示。然後取該文本、視頻的後續部分，或圖像的轉換版本，也將其通過一個編碼器。嗯，現在試著在那個表示空間中進行預測，而不是在輸入空間中進行預測。


對吧？所以你可以使用相同的訓練方法，即填空，但你是在這個潛在空間（latent space）進行，而不是在原始表示層面。


完全正確。困難在於，如果你不小心，如果你不使用那種，呃，聰明的技術來做這件事，系統會崩潰。基本上，它會完全忽略輸入，只產生一個恆定的表示，這對輸入來說沒有提供太多資訊。所以你必須，你知道的，直到五六年前，我們還沒有任何技術來防止這種情況發生。所以，嗯，現在，如果你想將其用於代理系統（agentic system）或能夠推理和規劃的系統，那麼你需要的是這個預測器，它，你知道的，當它觀察到一段視頻時，它會得到一些關於世界狀態、當前世界狀態的概念。它需要做的是能夠預測世界的下一個狀態會是什麼，嗯，基於我可能採取的一個我正在想像的行動。好的？所以你需要一個預測器，給定世界狀態和你想像的一個行動，可以預測世界的下一個狀態。嗯，如果你有這樣一個系統，那麼你就可以規劃一系列行動來到達一個特定的結果。這才是我們所有人進行規劃和推理的真正方式。我們不是在詞元空間裡做的，你知道的。嗯，讓我舉個很簡單的例子，對吧？現在有很多所謂的代理推理系統，它們的工作方式是生成大量大量的詞元序列，使用各種不同的方式隨機生成不同的詞元。然後有第二個神經網路試圖從所有生成的序列中選擇最佳的一個。嗯，這有點像，你知道的，在不知道如何編寫程式的情況下編寫程式。你編寫一個隨機的程式，然後測試它們，然後保留那個真正給出正確答案的程式。我的意思是，這完全沒有希望。

嗯，實際上有一些關於超級優化（super optimization）的論文建議正是這樣做。

對，對於短程式。

對於短程式，你當然可以，因為... 但它是指數級增長的隨著行數。所以就像，你知道的，過了一段時間後就完全沒希望了。

## 邁向 AMI (先進機器智慧)：時程、挑戰與 LeCun 的觀點

是的，是的。所以很多人說，嗯，通用人工智慧（AGI），或者我想你會稱之為 AMI，即將到來。嗯，你的看法是什麼？嗯，你知道，你認為它什麼時候會到來？為什麼？差距在哪裡？

是的，是的，是的。我不喜歡 AGI 這個術語，因為，呃，人們用這個術語來指代具有人類水平智能的系統，而可悲的是，人類智能是高度專業化的。所以稱之為通用（General）我認為是用詞不當。嗯，所以我更喜歡 AMI 這個詞，我們讀作 AMI，意思是先進機器智慧 (Advanced Machine Intelligence)。好的？這只是詞彙問題。嗯，我認為我正在描述的這個概念，即系統，你知道的，可以學習世界的抽象心智模型，並使用它們進行推理和規劃，我認為我們可能在三到五年內對如何讓它至少在小規模上運作有一個很好的掌握。然後這將是一個，你知道的，擴展它們等等的問題。嗯，直到我們達到人類水平的 AI。現在，事情是這樣的。歷史上，在 AI 領域，嗯，一代又一代的 AI 研究人員發現了一種新的範式，並聲稱就是它了，在 10 年內，或者 5 年，或者隨便多久，嗯，我們將擁有達到人類水平的智能。我們將擁有在所有領域都比人類更聰明的機器。這種情況已經持續了 70 年。嗯，並且每隔 10 年左右就會有那些，你知道的，浪潮。嗯，當前的浪潮也是錯誤的。那種認為，你知道的，你只需要擴展 LLM，或者讓它們生成，你知道的，數千個詞元序列並選擇好的那些，就能達到人類水平的智能，並且你將在，你知道的，幾年內，我認為有些預測是兩年內，擁有一個數據中心裡的“天才之國”，引述某位不願透露姓名的人的話。我認為這是無稽之談。這完全是胡說八道。我的意思是，當然，對於很多應用來說，你知道的，近期的系統將會達到，如果你願意的話，博士水平，但在，你知道的，總體智能方面，不，我們還差得很遠。我的意思是，你知道的，當我說很遠時，它可能在十年左右發生。所以也不是那麼遠。

所以，嗯，AI 已經以多種方式應用，改善了人類的狀況，讓生活更輕鬆。你認為 AI 的哪個應用，你知道的，最引人注目，最有利？

## AI 的正面影響：科學、醫療與日常生活

嗯，所以，我的意思是，有一些明顯的，明顯的事情，當然。我的意思是，我認為，嗯，AI 對科學和醫學的影響，嗯，可能會比我們目前能想像的要大得多，儘管它已經相當大了。你知道的，不僅僅是在研究方面，比如蛋白質折疊和藥物設計以及類似的事情，理解，你知道的，生命的機制，而且也是短期的，對吧？我的意思是，嗯，現在在美國，你經常會進行醫學影像檢查，其中會涉及到 AI，對吧？如果是乳房 X 光檢查，它很可能已經用深度學習系統進行了預篩選以檢測腫瘤。如果你去做核磁共振（MRI），你必須在那台 MRI 機器裡待的時間減少了四倍左右，因為，你知道的，現在我們可以某種程度上，嗯，恢復，用更少的數據恢復 MRI 圖像的某種高解析度版本。所以像很多短期的後果，當然，你知道的，我們每一輛汽車，你知道的，Nvidia 是其中一個大供應商，但是，大多數現在出廠的汽車都配備了，呃，至少是，呃，駕駛輔助系統或自動緊急煞車系統。它們在歐洲現在已經是必需設備好幾年了。那些東西將碰撞減少了 40%。我的意思是，它們拯救了生命。我的意思是，這些顯然是巨大的應用。嗯，而這些不是生成式 AI，對吧？這不是 LLM。這是，嗯，感知，基本上。當然對於汽車來說還有一點控制。現在，嗯，你知道的，顯然，對於現有的或幾年內將存在的 LLM，有很多應用，呃，在工業界，在，呃，在服務業等等。嗯，但是，嗯，嗯，但是，你知道的，我們也必須考慮到它的局限性，那就是，部署具有預期準確性和可靠性水平的系統比大多數人想像的要困難得多。對於自動駕駛來說當然是這樣，對吧？這，呃，它一直是一個不斷後退的目標線，關於我們何時能實現第五級自動駕駛。而且，呃，我認為這將是，你知道的，同樣的事情。AI 通常失敗的地方不是在基礎技術上，不是在，你知道的，華麗的演示中，而是當你實際需要部署它、應用它，並使其足夠可靠，並將其與現有系統整合時。那才是變得困難、昂貴且比預期花費更多時間的地方。

當然，像自動駕駛汽車這樣的事情，它必須一直都正確，否則有人可能會，你知道的，受傷或死亡。那種，你知道的，準確性水平必須幾乎是完美的。但是有很多應用，如果它只是在大多數時候做對了，就非常有益。嗯，你知道的，即使是一些醫療應用，有醫生會進行二次檢查。或者當然是娛樂和類似的事情，教育，你只是想利大於弊，而且做錯的後果並非災難性的。

絕對是的。所以，我的意思是，對於大多數這些系統來說，真正最有用的系統是那些讓人生產力更高和/或更有創造力的系統。是的，一個基本上輔助他們的程式碼助手。對吧？嗯，我的意思是，這在醫學上是真的，在藝術上是真的，在，你知道的，產生文本或... 但 AI 並不是在取代人，它基本上是在給他們提供強力工具。

嗯，它在某個時候可能會，但是，呃，但我不認為人們會接受這個，對吧？我的意思是，基本上我們與未來 AI 系統的關係，包括超級智能，你知道的，超人類系統，是我們將成為它們的老闆。你知道的，我們將會擁有一群超級智能的虛擬人員為我們工作。我不知道你怎麼樣，但我喜歡和比我聰明的人一起工作。

我也是。這是世界上最棒的事情。

是的。所以，反過來看，正如 AI 能在多方面造福人類一樣，它也有陰暗面，人們會用它來做一些事情，比如，你知道的，製造深度偽造（deep fakes）和假新聞，以及，呃，你知道的，如果應用不當，它可能導致，你知道的，情感困擾。你對 AI 的使用最大的擔憂是什麼？我們如何緩解這些擔憂？

## AI 的風險與應對策略

嗯，所以，有一件事，Meta 肯定非常熟悉，就是使用 AI 作為對抗攻擊的反制措施，無論攻擊來自 AI 還是其他。嗯。嗯，所以，可能令人驚訝的一件事是，你知道的，儘管 LLM 和各種，呃，你知道的，深度偽造之類的東西已經存在好幾年了，嗯，我們負責，你知道的，檢測和處理這類攻擊的同事告訴我們，像是我們沒有看到，你知道的，生成內容在社交網路上發布的數量大幅增加，或者至少不是以惡意方式發布的，而且通常會標記為合成內容。嗯，所以我們沒有看到所有那些人們在三四年前警告的災難場景，關於，你知道的，這將摧毀，你知道的，所有的信息，以及，你知道的，有一個有趣的故事，我需要告訴你。嗯，那就是在，呃，2023 年秋天，抱歉是 2022 年，呃，我在 Meta 的同事們，一個小團隊，整合了一個在整個科學文獻上訓練的 LLM。好的？所有他們能找到的技術論文。嗯，它叫做 Galactica。他們把它放上網，附有一篇長論文描述了它是如何訓練的。嗯，開源代碼和一個你可以直接玩的演示系統，對吧？嗯，而這個東西遭到了 Twitter 圈的尖酸刻薄的抨擊。基本上，人們說：“哦，這太可怕了，這會害死我們的，它會摧毀科學交流系統。現在任何傻瓜都可以，你知道的，寫一篇聽起來很科學的論文，關於吃碎玻璃的好處之類的。” 所以，我的意思是，當時有如此，你知道的，負面意見的海嘯，以至於，你知道的，我可憐的同事們，一個五個人的小團隊，晚上都睡不著覺，他們下架了那個演示。他們留下了開源代碼和論文，但下架了演示。嗯，我們的結論是，世界還沒有準備好接受這種技術，而且沒有人感興趣。三週後，ChatGPT 出現了。好的？那簡直就像是彌賽亞的第二次降臨，對吧？然後，就像，我們互相看著說，剛才發生了什麼？嗯，考慮到之前那個的反應，我們簡直無法理解公眾對這個的熱情。是的。嗯，所以，而且我認為，你知道的，OpenAI 實際上也對 ChatGPT 在公眾中的成功感到非常驚訝。所以很多是觀感問題。嗯，而且，你知道的，我認為，呃，這個論述...

但是 ChatGPT 並沒有試圖寫學術論文，或者做科學研究。它基本上是你可以與之交談，問任何問題的東西。它試圖比那更通用。

對。呃，所以在某種程度上，它對更多人更有用，或者，你知道的，更接近有用。嗯，所以肯定存在危險。存在各種濫用的情況。嗯，但再次強調，對抗濫用的反制措施就是更好的 AI。存在，你知道的，不可靠的系統，正如我之前談到的。解決方法是更好的 AI 系統，它們，你知道的，具備常識，也許有推理能力，能夠檢查答案是否正確，並評估自己答案的可靠性，這目前還不完全是這樣。嗯，但是，但是災難性的場景，坦率地說，我不，我是一個不相信它們的人。好的？所以人們會適應。我傾向於認為 AI 主要是為了好的方面，即使其中夾雜著一些壞的方面。

所以作為一個在大西洋兩岸都有家的人，你有非常全球化的視角。你認為未來 AI 的創新會來自哪裡？

嗯，所以它可以來自任何地方。呃，任何地方都有聰明人。呃，沒有人壟斷好點子。我的意思是，有些人有巨大的優越感，認為他們可以不與任何人交談就想出所有好點子。以我作為科學家的經驗來看，情況並非如此。你必須，你知道的，好的點子來自於很多人的互動和思想交流，以及，你知道的，在過去十年或一年半左右，代碼的交流也是如此。所以這就是為什麼，呃，你知道的，我一直是開源 AI 平台的堅定倡導者，以及為什麼 Meta 在一定程度上也採納了這種哲學。我們對好點子沒有選擇權。儘管我們自認為很聰明，但我們就是沒有。你知道的，最近關於 DeepSeek 的故事確實表明好點子可以來自任何地方。現在中國有很多非常優秀的科學家。一個很多人應該知道的故事是，如果你問自己，在過去 10 年裡，所有科學領域中引用次數最多的論文是哪一篇？那篇論文發表於 2015 年，正好是 10 年前。嗯，它是關於一種特殊的神經網路架構，叫做 ResNet，殘差網路。嗯，它來自北京的微軟亞洲研究院，由一群，呃，中國科學家完成。呃，第一作者是 Kaiming He。一年後，他加入了，呃，加州的 FAIR，Meta，在那裡待了大約八年，最近他去了 MIT。是的，去了 MIT，完全正確。所以，你知道的，這告訴你世界各地有很多優秀的科學家。嗯，想法可以從任何地方產生。呃，但是要真正將這些想法付諸實踐，你需要像，你知道的，一個龐大的基礎設施，大量的計算能力，你需要給你朋友、你的同事很多錢，對吧？去買...

但是擁有開放的知識社群會讓進步更快，因為，你知道的，有人在這裡想出了一半的好點子，另一個人有另一半，如果他們交流，那麼事情就會發生。但如果他們都非常封閉和保守，你知道的，進步就不會發生。

沒錯。另一件事是，你需要為了讓創新思想湧現，呃，作為 Nvidia 的首席科學家，你知道這一點，你需要給人們很長的空間，對吧？你你需要讓人才真正地，嗯，創新，而不是像強迫他們每三個月或每六個月產出一些東西。事實上，這幾乎就是 DeepSeek 所發生的事情。嗯，Llama 也是這樣。一個不廣為人知的故事是，呃，2022 年在 FAIR 有好幾個 LLM 項目。呃，一個項目擁有相當多的資源，得到了領導層的支持等等。嗯，另一個則有點像巴黎十幾個夥伴的“海盜”項目，他們基本上決定建立自己的 LLM，因為他們出於某種原因需要它。嗯，那個項目變成了 Llama。那個大項目你從未聽說過，它被停止了。所以即使你沒有，你知道的，所有的支持，你也能想出好點子。基本上，如果你在某種程度上與你的管理層隔離開，他們讓你獨自工作，你知道的，呃，你可能會想出比你被要求按計劃創新時更好的點子。好的？所以，你知道的，有十幾個人，他們做出了 Llama 1。然後當然，呃，做出了決定，選擇這個作為平台，而不是另一個項目。嗯，然後圍繞它建立了一個團隊來生產 Llama 2，最終它被開源了，基本上在業界引起了一場革命。呃，在整個版圖中。然後是 Llama 3。截至昨天，Llama 的下載量已經超過十億次。我覺得這太驚人了。我的意思是，我假設這包括了很多你們，但像是，那些人都是誰？對吧？我的意思是，你肯定認識他們，因為他們肯定都買 Nvidia 的硬體，對吧？來運行那些東西。

我們感謝你賣了所有那些 GPU。

是的。所以，讓我們多談談開源。我認為，你知道的，Llama 在這方面確實具有創新性，因為它是一個，你知道的，最先進的，嗯，你知道的，LLM，至少是開放權重（open weight）提供的，這樣人們就可以，你知道的，下載並自己運行它。這樣做的利弊是什麼？我的意思是，你，你知道的，公司顯然投入了巨額資金來開發模型、訓練模型、微調模型，然後把它送出去。那麼，這樣做有什麼好處？又有什麼壞處？

## 開源的力量：推動創新與多樣性

嗯，所以我認為，如果你是一家期望直接從該服務中獲得收入的公司，如果你那是你唯一的業務，那麼當然，你知道的，這對你來說可能不利，去透露你所有的秘密。嗯，但如果你是一家像 Meta 這樣的公司，在某種程度上像 Google，嗯，你知道的，收入來自其他來源，廣告，呃，在 Meta 的情況下是廣告，你知道的，Google 有各種來源，呃，你知道的，未來可能還有其他來源。但是，嗯，但重要的是不是你短期內能產生多少收入，而是你是否能建立你想要構建的產品所需的功能。以及，呃，以及，你知道的，你是否能讓世界上盡可能多的聰明人為之做出貢獻。嗯，對於整個世界來說，如果其他一些公司將 Llama 用於其他目的，這對 Meta 並沒有損害，比如，你知道的，他們沒有可以建立在此基礎上的社交網絡。所以我的意思是，這對 Google 來說威脅更大，因為顯然你可以用它來構建搜索引擎。所以這可能就是為什麼他們對這種方法不太積極的原因。但是，嗯，呃，我們看到的另一件事是 PyTorch 的影響，首先，嗯，以及它對，對整個版圖，對社群的影響，還有 Llama 2，它基本上，你知道的，啟動了整個初創企業生態系統。

我的意思是，你知道的，我們在更大的行業中也看到了這一點，現在人們有時會用一個 API，一個專有 API 來原型化一個 AI 系統，然後當到了部署的時候，最經濟有效的方法是在 Llama 上進行，因為你可以在本地運行它，或者其他一些開源模型。但最大的，你知道的，從哲學上講，我認為最大的因素，想要擁有開源平台的最重要原因是，你知道的，在很短的時間內，我們，我們每一次與數位世界的互動都將由 AI 系統介導。呃，我現在戴著 Ray-Ban Meta 智能眼鏡，我可以通過它與 Meta AI 交談，問它任何問題。嗯，我們不相信人們會想要一個單一的，呃，助手，而且那些助手會來自美國西海岸或中國的少數幾家公司。我們需要極其多樣化的助手。它們需要能說世界上所有的語言，理解世界上所有的文化，所有的價值體系，所有的興趣中心。嗯，你知道的，它們需要有像不同的偏見，政治觀點等等。所以我們需要多樣化的助手，原因和我們需要多樣化的媒體一樣。

否則我們都會從相同的來源獲得相同的信息，這對民主和，你知道的，其他一切都不好。所以，所以我們需要一個任何人都可以用來構建那些助手的平台，一個多樣化的助手群體。而現在，這只能通過，呃，開源平台來完成。我認為這在未來會變得更加重要，因為如果我們想要，你知道的，基礎模型能說世界上所有的語言等等，沒有任何單一實體能夠獨自完成這件事。嗯，你知道的，誰會去收集世界上所有語言的所有數據，然後把它交給，你知道的，OpenAI、Meta 或 Google 或 Anthropic？沒有人。他們想保留那些數據。所以他們想，你知道的，世界上的地區會想要將他們的數據貢獻給一個全球基礎模型，但實際上並不會給出那些數據。他們可能會為訓練一個全球模型做出貢獻。我認為這就是未來的模式。基礎模型將是開源的，將以分佈式的方式進行訓練，世界各地的不同數據中心可以訪問數據的不同子集，並且基本上訓練出一種，如果你願意的話，共識模型。所以，這就是，呃，這就是使開源平台完全不可避免的原因，而專有平台我認為將會消失。

是的，是的，而且這對於語言和其他事物的多樣性以及應用來說都很有意義。所以一個特定的公司可以下載 Llama，然後在他們不想上傳的專有數據上進行微調。

嗯，這就是現在正在發生的事情。我的意思是，大多數 AI 初創公司的商業模式基本上就是圍繞這個，對吧？就是，你知道的，為垂直應用構建專門的系統。

是的，是的。嗯，所以，你知道的，在 Jensen 的主題演講中，他有一個很棒的例子，關於使用一個，呃，嗯，代理 LLM 來做婚禮座位安排，決定誰將坐在桌子周圍。那是一個很好的例子，說明了在訓練上投入努力和在推理上投入努力之間的權衡。所以在一個案例中，你可以有一個非常強大的模型，你花費了大量的資源進行訓練。或者你可以構建一個不那麼強大的模型，但基本上運行它很多次，這樣它就可以推理並完成任務。你如何看待，你知道的，訓練時間和推理或測試時間之間的權衡？嗯，在構建一個強大模型時，最佳點在哪裡？

首先，我認為，呃，你知道的，Jensen 絕對是對的，呃，你最終能從一個能夠某種程度上，你知道的，推理的系統中獲得更多力量。我不同意的是，進行推理的正確方式是，你知道的，當前那些通過推理能力增強的 LLM 的方式。

## 推理的未來：在抽象空間中進行

你是說它有效，但不是正確的方式。

它不是正確的方式。我認為，呃，當我們推理時，當我們思考時，我們是在某種抽象的心智狀態中進行的，這與語言無關。

你不想把詞元踢出去，你想在你的潛在空間，而不是抽象空間裡推理。

對。我的意思是，如果我告訴你，你知道的，想像一個立方體漂浮在你面前，我將那個立方體繞垂直軸旋轉 90 度。好的？你可以在腦海中做到這一點。這與語言無關。嗯，你知道的，一隻貓可以做到這個。呃，我們顯然無法通過語言向貓說明這個問題，但是，你知道的，貓做的事情比這複雜得多，當它們計劃像，你知道的，一些軌跡跳到一件家具上時，對吧？它們做的事情比那複雜得多。而且，嗯，那與語言無關。它肯定不是在，所以，你知道的，詞元空間中完成的，那會是某種行動。它是在某種抽象的心智空間中完成的。所以這，呃，這就是未來幾年的挑戰。嗯，那就是找出允許這類事情發生的新架構。這就是我過去一直在研究的。

所以，所以我們應該期待一種新的模型，讓我們能夠在這個抽象空間中進行推理嗎？

呃，它被稱為，我們稱之為 JEPA。呃，或者 JEPA 世界模型。我們已經，你知道的，嗯，我的同事和我已經發表了一系列關於這方面的論文，關於這種，你知道的，邁向這個方向的第一步，在過去幾年裡。所以 JEPA 的意思是聯合嵌入預測架構。這就是那些學習抽象表示並能夠某種程度上操縱那些表示，呃，並且也許能夠推理並產生行動序列以，你知道的，達到特定目標的世界模型。我認為那就是未來。我大約三年前寫了一篇關於這個的長篇論文，解釋了這可能如何運作。

是的。所以，嗯，你知道的，要運行那些模型，你需要很棒的硬體。而且，嗯，你知道的，在過去十年中，GPU 的能力已經提高了，你知道的，大約 5 到 10,000 倍，基本上在 AI 模型的訓練和推理方面，從 Kepler 到，呃，到 Blackwell。我們今天已經看到更多能力即將到來。嗯，然後橫向擴展（scale out），嗯，和縱向擴展（scale up）提供了更多的能力。嗯，在你看来，未來會發生什麼？你預期會有什麼樣的東西，嗯，能讓我們構建你的 JEPA 模型和其他更強大的模型？

## 硬體需求與未來展望：從 GPU 到新興技術

嗯，所以，嗯，我的意思是，繼續推出它們，你知道的，因為我們將需要我們能得到的所有計算能力。呃，所以，我的意思是，這種在抽象空間中推理的想法在運行時計算成本會很高。它與我們都非常熟悉的東西有關，對吧？所以心理學家談論系統一和系統二。系統一是你可以完成的任務，而不需要真正地思考它們。你已經習慣了它們，你可以在不太思考的情況下完成它們。所以如果你是一個有經驗的司機，你可以開車，即使沒有駕駛輔助，你也可以在不太思考的情況下開車。你知道的，你可以同時和別人說話。你可以，你知道的，嗯，等等。但如果你是一個，一個第一次開車的人，在最初的幾個小時裡，你在方向盤後面，你必須真正專注於你在做什麼，對吧？

而且你在計劃各種災難場景和類似的事情。想像各種各樣的事情。所以那是系統二。你在調動你整個前額葉皮層，你的世界模型，你的內部世界模型，來弄清楚，你知道的，將要發生什麼，然後計劃行動，以便好的事情發生。嗯，然而當你熟悉了這個之後，你可以只使用系統一，並某種程度上自動地完成它。所以這個想法是，你從，呃，你知道的，使用你的世界模型開始，你能夠完成一個任務，即使是一個你從未遇到過的任務，零樣本（zero-shot），對吧？你不需要被訓練來解決那個任務。你只需要，所以你可以僅僅基於你對世界的理解和你的規劃能力來完成那個任務，而無需學習任何東西。這就是當前系統所缺少的。但是如果你多次完成那個任務，那麼最終它會被編譯成所謂的策略（policy），對吧？所以一個某種反應式的系統，允許你僅僅完成那個任務而無需規劃。呃，所以第一件事，這個推理是系統二。那種自動的、潛意識的、反應式的策略是系統一。嗯，（現有模型）可以做系統一，並且正試圖慢慢地走向系統二。但最終我認為我們需要一個不同的架構來實現系統二。

好的。你認為會是你的，那是叫 JEPA 嗎？

嗯，我認為它不會是一個生成式架構，如果你希望系統理解物理世界。物理世界比語言難理解得多得多。我們認為語言是人類能力的縮影，你知道的，智力能力的縮影。但事實上，語言很簡單，因為它是離散的。而且它是離散的，因為它是一種交流機制，它需要是離散的，否則它就不會抗噪音。你現在就無法理解我說的話，對吧？所以由於這個原因它很簡單。呃，但現實世界要複雜得多。比如，好吧，這兒有件事，你們中的一些人可能聽我以前說過。呃，當前的 LLM 通常用大約 30 萬億個詞元進行訓練，對吧？詞元通常大約是 3 個字節。所以那是 0.9 * 10 的 13 次方字節，假設是 10 的 14 次方字節。嗯，我們任何一個人讀完這些需要超過 40 萬年，因為那基本上是互聯網上所有可用文本的總和，對吧？現在，一個，心理學家告訴我們，一個 4 歲的孩子總共清醒了 16,000 個小時。我們大約有 2MB 的數據通過視神經進入我們的視覺皮層。嗯，每秒 2MB，大致上。將這個乘以 16,000 小時乘以 3600。大約是 10 的 14 次方字節。在四年內，通過視覺，你看到的數據量相當於你需要 40 萬年才能讀完的文本量。我的意思是，這告訴你，我們永遠無法達到 AGI，無論你指的是什麼，呃，僅僅通過文本訓練。這根本不可能發生。

是的。所以回到硬體。在脈衝系統（spiking systems）方面已經取得了很多進展，那些，呃，嗯，那些倡導這個並研究與生物系統工作方式類比的人表明，神經形態硬體（neuromorphic hardware），你知道的，有其作用。你認為在哪個地方，嗯，神經形態硬體會補充或取代 GPU 來進行 AI？

呃，短期內不會。嗯。嗯，你之後會給我那 20 塊錢的。

什麼？

嗯。好吧，我得告訴你一個關於這個的故事。所以我，呃，當我 1988 年開始在貝爾實驗室工作時，我所在的團隊實際上專注於用於神經網路的模擬硬體。他們，你知道的，建造了好幾代完全模擬的神經網路，然後是混合模擬數位，然後在 90 年代中期變成了完全數位。嗯，那時人們對神經網路失去了興趣，所以就沒有意義了。

嗯，像這樣奇特的底層原理的問題在於，呃，你知道的，當前的數位 CMOS 處於一個如此深的局部最小值，以至於需要一段時間，你知道的，替代技術和巨額投資，才能讓替代技術趕上。而且甚至不清楚在原理層面上是否有任何優勢。所以像，你知道的，模擬或脈衝神經元或，你知道的，脈衝神經網路，呃，可能有一些內在的優勢，除非它們基本上使硬體重用變得非常困難，對吧？我的意思是，我們目前使用的每一塊硬體都太大太快了，在某種意義上。所以你必須基本上重用同一塊硬體，你知道的，多路複用同一塊硬體來計算不同的模型。是的，你的神經網路。對吧？嗯，如果你使用模擬硬體，基本上你不能使用多路複用。所以你必須為你虛擬神經網路中的每一個神經元配備一個物理神經元。

這意味著現在你無法將一個像樣大小的神經網路放在單個晶片上。你必須做多晶片。一旦你能做到這一點，它會非常快，但它不會高效，因為你需要進行跨晶片通信，而且，你知道的，記憶體變得複雜。而且，嗯，最終你需要實際進行數位通信，因為那是唯一能高效完成的方式，呃，為了抗噪音。事實上，大腦，這裡有一條有趣的信息。嗯，大多數大腦或大多數動物，在大多數動物的大腦中，神經元通過脈衝進行通信。好的？脈衝是二進制信號。所以它是數位的。它不是模擬的。神經元的計算層面可能是模擬的，但神經元之間的通信實際上是數位的。除了微小的動物。所以如果你拿秀麗隱桿線蟲（C. elegans），對吧？一種 1 毫米長的蠕蟲，呃，它有 302 個神經元。它們不發出脈衝。它們不需要發出脈衝，因為它們不需要遠距離通信。所以它們可以在那個尺度上使用模擬通信。所以，你知道的，這告訴你，即使我們想使用像模擬計算這樣的奇特技術，我們也將不得不以某種方式使用數位通信，如果不是為了記憶體的話。所以目前還不清楚。我的意思是，我知道你多次進行過這種計算。呃，我可能對此了解得比你少得多，但是，呃，我短期內看不到它會發生。可能有一些邊緣計算的角落。所以如果你想要像一個超級便宜的微控制器，它將運行，你知道的，你的吸塵器或你的割草機的感知系統。嗯，那麼也許模擬計算是有意義的，如果你能把整個東西放在一個單一的晶片裡，並且你可以使用，也許，我不知道，相變記憶體或類似的東西來儲存權重，也許。我知道有些人正在認真地構建那些。

那屬於人們稱之為 PIM 或處理器內存儲技術的範疇，包括模擬和數位。你認為它們有作用嗎？它們是...

是的，當然。所以我的意思是，我的一些同事實際上對此非常感興趣，因為他們想製造像那些，你知道的，智能眼鏡的後繼產品。你想要的是一些，你知道的，視覺處理，基本上一直進行。而現在這是不可能的，因為功耗。嗯。呃，就像，你知道的，一個感測器，像一個圖像感測器，你不能讓它在一副這樣的眼鏡裡一直開著。你會在幾分鐘內耗盡電池。所以一個潛在的解決方案是實際上在感測器上直接進行處理。這樣你就不必把數據移出晶片，這才是真正消耗能量的地方，對吧？移動數據才是消耗能量的，而不是計算本身。所以有，你知道的，相當多的這方面的工作，但我們還沒到那一步。
所以你認為那是一個有前途的方向。

嗯，我認為這是一個有前途的方向。事實上，生物學已經弄清楚了這一點，對吧？或者我們的視網膜，嗯，大約有 6000 萬個光感測器。在我們視網膜前面有四層神經元，透明的神經元，它們處理信號，將其壓縮到 100 萬根視神經纖維，傳到我們的視覺皮層。所以有壓縮，特徵提取，你知道的，各種各樣的東西。嗯，為了真正地，嗯，從視覺系統中獲取，你知道的，大部分有用信息。

是的。那麼，那麼其他新興技術呢？你認為，你知道的，量子或超導邏輯或其他任何即將出現的技術，會給我們在 AI 處理能力方面帶來巨大的進步嗎？

呃，超導也許吧。我對此了解不夠，無法真正判斷。光學一直非常令人失望。我認為，呃，已經有好幾代了。我的意思是，我記得在 1980 年代，我對關於神經網路的光學實現的講座感到非常驚訝，但它們從未實現。我的意思是，技術顯然在發展，所以也許情況會改變。呃，我認為那裡的大部分成本就像模擬一樣，你在與數位系統接口的轉換中損失了它。然後對於量子，我對量子計算極度懷疑。我的意思是，我認為我看到的量子計算唯一的中期應用是模擬量子系統，比如，你知道的，如果你想做像量子化學或類似的事情，也許。呃，像對於其他任何事情，我，我極度懷疑。

好的。所以，所以你談到了構建能夠像幼兒動物一樣通過觀察學習的 AI。嗯，你知道的，你認為這會對硬體提出什麼樣的要求？你認為我們需要如何發展硬體來實現這一點？

## 從觀察中學習：JEPA 世界模型的挑戰與前景

你能給我們多少？

不，問題是你願意買多少。

你買得越多，省得越多，賺得越多，正如我們今天聽到的，對吧？

完全正確。

呃，是的，不，它不會便宜。它不會便宜，因為，呃，我的意思是，視頻，好吧，讓我告訴你一個我一些同事做的實驗。嗯，直到大約一年前。所以有一種用於自我監督學習的技術，使用重建來學習圖像表示。就是我告訴你行不通的那種東西。好的？呃，那是一個叫做 MAE 的項目，Masked Autoencoder。所以它基本上是一個自動編碼器，一個去噪自動編碼器，非常像，你知道的，現在使用的那種，對吧？所以你拿一張圖像，通過移除它的一些部分來損壞它，實際上是很大一部分。然後你訓練一些巨大的神經網路來重建完整的圖像，基本上是在像素級別，或者在詞元級別。呃，然後你使用內部表示作為下游任務的輸入，你進行監督訓練，物體識別或其他什麼。嗯，它有效。好的？呃，你必須燒開一個小池塘來冷卻那些液冷，嗯，GPU，呃，GPU 集群才能做到這一點。嗯，它的效果遠不如那些聯合嵌入架構好。你可能聽說過 Dino，Dino V2，呃，UA 等等。所以那些是聯合嵌入架構，它們往往效果更好，而且訓練成本實際上更低。

所以在聯合嵌入中，你基本上有兩個輸入類別的兩個潛在空間。

沒錯。而不是將所有東西轉換成一種詞元。

嗯，與其擁有一張圖像，然後是一個損壞或轉換過的版本，然後從損壞或轉換過的版本重建完整圖像，你不如取完整圖像和損壞/轉換過的版本，你將它們都通過編碼器，然後你試圖，試圖連接那些嵌入，從部分可見的那個，損壞的那個的表示中訓練完整圖像的表示。好的？所以它們是聯合嵌入預測架構。嗯，那樣效果更好，而且更便宜。好的？現在 MAE 團隊說，好吧，這對圖像似乎還行，讓我們試試用視頻來做這個。所以現在你必須對視頻進行詞元化，基本上把一個視頻轉換成，你知道的，16x16 的補丁，即使是很短的視頻也有很多補丁。嗯，然後訓練一些巨大的神經網路來重建視頻中缺失的補丁，也許預測未來的視頻。嗯，那需要燒開一個小湖泊，而不是一個小池塘。而且基本上是失敗的。那個項目被停止了。好的？所以我們現在的替代方案是一個叫做 VJEPA 的項目。我們正在接近第二個版本。基本上它是那些聯合嵌入預測架構之一。所以它對視頻進行預測，但是在表示層面。而且它似乎效果非常好。我們有一個例子，這個的第一個版本是在非常短的視頻上訓練的，只有 16 幀。它被訓練來，呃，基本上從一個部分遮蔽的版本預測完整視頻的表示。那個系統顯然能夠告訴你某個特定視頻在物理上是否可能，至少在受限的情況下是這樣。

它給你一個二進制輸出，這是可行的，這是不行的，或者也許...

嗯，不，比那簡單。你測量系統產生的預測誤差。所以你對一個視頻使用那些 16 幀的滑動窗口，你觀察，你知道的，你能否預測像接下來的幾幀。你測量預測誤差。當視頻中發生一些非常奇怪的事情時，比如一個物體消失了，或者改變了形狀，或者，你知道的，類似的事情，或者自發出現，或者不遵守物理定律。

所以它通過觀察視頻就能判斷物理上是否真實。

是的，這些是，你知道的，我的意思是，你在自然視頻上訓練它，然後你在合成視頻上測試它，其中發生了一些非常奇怪的事情，對吧？
所以如果你在發生奇怪事情的視頻上訓練它，那就會變成正常，它就不會...

是的，沒錯。

檢測到那些是奇怪的。

是的。所以你不會那麼做。

不，我的意思是，它有點對應於，就像如果你，呃，你知道的，人類嬰兒，呃，需要一段時間來學習直覺物理學，比如，呃，你知道的，一個沒有支撐的物體會掉落的事實。嗯。所以基本上是重力的影響。嬰兒大約在 9 個月大的時候學會這個。所以如果你給一個五六個月大的嬰兒看一個場景，一個物體似乎漂浮在空中，他們，他們不會感到驚訝。但到了九個月或十個月大的時候，他們，他們會睜大眼睛看著它，你實際上可以測量到這一點，就像心理學家有方法測量注意力一樣。這意味著嬰兒內部的世界模型，心智模型，被違反了。嬰兒看到了一些她認為不可能的事情。

與預期不符。

是的，對。所以她必須看著它來糾正她的內部角色模型，說，像是，你知道的，也許我應該學習一下這個，對吧？

是的。所以，所以你談到了在這個，你知道的，聯合嵌入空間中進行推理和規劃。我們需要什麼才能達到那一步？模型方面和硬體方面的瓶頸是什麼？

很大程度上只是讓它運作起來。所以我們需要一個好的配方，你知道的，就像在人們想出一個好的配方來訓練，呃，比如說，即使是簡單的卷積網路之前。好的？所以，你知道的，回到，你知道的，直到 2000 年代末期。嗯，Geoff Hinton 只是，呃，你知道的，告訴大家，你知道的，用反向傳播（backprop）訓練深度，呃，深度網路非常困難。嗯，你知道的，Yann 可以用卷積網路（ConvNet）做到，但他是世界上唯一能做到的人。這當然在當時是真的，但也不完全是真的。好的？嗯，結果發現並沒有那麼難。但是有很多技巧你必須弄清楚，像是，你知道的，工程技巧或直覺技巧，或者，你知道的，你使用哪個非線性函數，ResNet 的這個想法，對吧？在過去 10 年裡被引用了 25 萬次的論文，所有科學領域中被引用次數最多的論文。嗯，這是一個非常簡單的想法，對吧？你只是讓連接跳過每一層，這樣默認情況下，深度神經網路中的一層基本上計算的是恆等函數。而神經網路所做的是對此的偏離。

非常簡單的想法，但那讓你可以避免在反向傳播時梯度消失。

是的，沒錯。它允許訓練，你知道的，有 100 層或類似層數的神經網路。而現在我們，我們，在此之前，人們有所有這些技巧，他們會拿出，嗯，你知道的，中間的東西，並在那些上面設置損失函數來避免，因為你無法一直反向傳播到底。

沒錯，是的。

你知道的，一層會死掉，你的網路基本上就死了。所以你必須像重新開始訓練。所以，你知道的，人們很快就放棄了，因為他們就是沒有所有的技巧。所以在人們想出一個包含所有殘差連接（residual connections），你知道的，呃，你知道的，Adam 優化器和歸一化（normalization）等等的好的配方之前。順便說一下，我們剛剛有一篇論文表明你在 Transformer 中不需要歸一化。嗯，你知道的，類似的事情。在你擁有這個完整的配方和所有技巧之前，它真的，你知道的，什麼都行不通。你知道的，同樣的還有，還有 NLP，自然語言處理系統，對吧？在 2010 年代中期有那些系統，基於基本上是去噪自動編碼器，像 BERT 類型的系統，你取一段文本，你損壞它，訓練一個大的神經網路來恢復缺失的單詞。最終那被 GPT 風格的架構所取代，你只是在整個系統上進行訓練，你基本上將其訓練為自動編碼器，但你不需要損壞輸入，因為架構是因果的。呃，這是一個配方，對吧？結果證明在擴展方面非常成功。所以我們必須為那些 JEPA 架構想出一個好的配方，能夠擴展到同樣的程度。這就是所缺少的。

是的。我們前面有一個閃爍的紅燈。所以，呃，在我們結束之前，你有什麼最後的想法想留給觀眾嗎？

嗯，是的，我的意思是，我想強調我之前提出的觀點。我認為，呃，AI 的進步將會需要，以及朝向，呃，你知道的，人類水平 AI 或先進機器智慧或 AGI，無論你怎麼稱呼它的進步，將需要來自每個人的貢獻。它不會來自，它不會來自像某個在秘密進行研發的單一實體。那根本不會發生。它不會是一個事件。它將是許多，你知道的，沿途的連續進步。呃，而且人類不會在這發生後的一小時內被滅絕，因為它不會是一個事件。好的？嗯，而且因為它將需要來自，基本上是世界各地的貢獻。嗯，它將必須是開放研究，並基於開源平台，如果它們需要大量訓練。而且，呃，我們將需要像更便宜的硬體。你需要降低你的價格。抱歉。

你得跟 Jensen 談談這個。

[音樂] 嗯，我們將擁有一個 AI 助手高度多樣化的未來，它們將在我們的日常生活中幫助我們，呃，也許通過我們的智能眼鏡或其他智能設備隨時陪伴我們。我們將成為它們的老闆。它們，它們將為我們工作。這將會，這將會像是我們所有人都將成為經理。好的？

那真是個糟糕的未來。

嗯，就此打住，我想，呃，我要感謝你進行了一場真正啟發智力的對話。而且，呃，希望我們有機會再這樣做一次。

好的。是的。謝謝。

是的，謝謝你。
[音樂]
