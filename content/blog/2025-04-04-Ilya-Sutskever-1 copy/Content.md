---
layout: post
title: "Ilya Sutskever 與 Jensen Huang對談: AI Today & Vision of the Future"
date: 2025-04-04
categories: [
  'Ilya Sutskever',
  'Jensen Huang',
  'AI',
  'Deep Learning',
  'Machine Learning',
  'OpenAI',
  'Technology',
  '2023',

]
description: "Ilya Sutskever 分享了他投身 AI 領域的初衷、對深度學習潛力的早期信念，以及 OpenAI 的創立與發展歷程。他強調了 OpenAI 早期兩個核心理念：透過壓縮實現非監督式學習（這導致了 GPT 系列模型的基礎），以及強化學習（最終演化為 RLHF，用於微調 ChatGPT 等模型）。Sutskever 解釋了大型語言模型如何透過預測下一個詞來學習世界模型，並闡述了從 GPT-3 到 GPT-4 的顯著進步，特別是在理解、推理和多模態（結合文本與視覺）能力上的提升。他指出，雖然模型能力驚人，但目前最大的挑戰在於提高可靠性，減少「幻覺」和錯誤。他認為多模態學習不僅增強了模型的實用性（例如理解圖像），也能深化模型對世界的理解。最後，Sutskever 對 AI 未來的發展保持樂觀，預期可靠性將是近期的研究重點，並對神經網路僅透過擴大規模就能取得如此驚人的成果表示驚嘆。
"
toc: true # 啟用目錄功能

---

<span class="original-link">原文連結： [Ilya Sutskever 與 Jensen Huang對談: AI Today & Vision of the Future](https://www.youtube.com/watch?v=GI4Tpi48DlA&ab_channel=XiaoYang)</span>

**本次採訪為2023/5/17 Ilya Sutskever的採訪**

## 投身 AI 與深度學習的緣起

關於深度學習，你的直覺是什麼？你為什麼知道它會成功？你有沒有任何直覺，認為它會帶來這樣的成功？好的，首先，非常感謝你的引述和所有好話。由於深度學習令人難以置信的力量，很多事情都改變了。我想這是我個人的起點，我對人工智慧感興趣是出於各種原因，從對其影響的直觀理解和欣賞開始，而且我對意識是什麼、人類經驗是什麼充滿好奇，感覺人工智慧的進展會對此有所幫助。下一步是，那時我是在 2002-2003 年開始的，似乎學習是人類能做而電腦完全做不到的事情。在 2003、2002 年，電腦什麼也學不會，甚至理論上是否可行都不清楚。所以我認為，在學習、人工學習、機器學習方面取得進展，將會帶來人工智慧的最大進步。

然後我開始環顧四周，看看有什麼現成的東西，似乎沒有什麼太有希望的，但我非常幸運，Jeff Hinton 是我大學的教授，我找到了他，他正在研究神經網路，這立刻就說得通了，因為神經網路具有學習的特性，我們是自動編程平行電腦。那時候平行電腦還很小，但前景是，如果你能以某種方式弄清楚神經網路的學習是如何運作的，那麼你就可以從資料中編程小型平行電腦，而且它也足夠像大腦，而大腦是能運作的，所以它具備了這幾個有利因素。當時還不清楚如何讓它運作起來，但在所有存在的東西中，這似乎具有迄今為止最大的長期潛力。人工智慧的大爆炸，快轉到現在，你來到矽谷，和一些朋友創辦了 OpenAI，你現在是首席科學家，在 OpenAI 最開始時，關於要做什麼的最初想法是什麼？因為你們研究了好幾樣東西，一些發明和工作的軌跡，你可以看到最終導向了 ChatGPT 的時刻，但最初的靈感是什麼？你當時是如何著手研究智慧的，並導致了現在的成果？

## OpenAI 的創立與雙軌核心理念

是的，很顯然，當我們開始時，並非百分之百清楚該如何進行，而且這個領域與現在相比也非常不同。所以現在你已經習慣了，我們已經習慣了，有這些令人驚嘆的人工製品，這些驚人的神經網路正在做著不可思議的事情，每個人都如此興奮。但在 2015 年、2016 年初，當我們剛開始時，整件事看起來相當瘋狂。研究人員少得多，大概只有現在領域人數的百分之一到千分之一。那時候大概有 100 人，他們大多在 Google 或 DeepMind 工作，僅此而已。然後有些人開始學習相關技能，但那仍然非常非常稀缺，非常罕見。在 OpenAI 成立之初，我們有兩個重要的初步想法，它們具有很強的生命力，並且一直伴隨著我們至今，我現在就來描述它們。

我們最初擁有的一個重大想法，也是我早期特別興奮的一個，是透過壓縮實現非監督式學習的想法。背景是，今天我們理所當然地認為非監督式學習是件容易的事，你只需在所有資料上進行預訓練，一切都會如你所預期的那樣運作。但在 2016 年，非監督式學習是機器學習中一個未解的問題，沒有人確切知道該怎麼做，一點頭緒都沒有。沒錯，iyanla Khan 會四處演講，說非監督式學習面臨巨大挑戰，而我堅信，對資料進行非常好的壓縮將會帶來非監督式學習。現在，壓縮並不是通常用來描述實際所做事情的語言，直到最近，許多人才突然明白，那些 GPT 模型實際上壓縮了訓練資料。你可能還記得 Ted Chiang 在《紐約時報》上的那篇文章，也提到了這一點。但在真正的數學意義上，訓練這些自回歸生成模型確實壓縮了資料。

直觀上，你可以理解為什麼這應該有效，如果你把資料壓縮得非常好，你必須提取出其中所有隱藏的秘密，因此，這就是關鍵。所以這是我們當時非常興奮的第一個想法，這導致了 OpenAI 的相當多工作，包括情感神經元（sentiment neuron），我會非常簡短地提一下。這項工作在機器學習領域之外可能不太為人所知，但它非常有影響力，尤其是在我們的思考方式上。這項工作的結果是，當你訓練一個神經網路時——那時候還不是 Transformer，是在 Transformer 之前——一個小的循環神經網路 LSTM，就是你自己也做過的一些工作，你知道的，同樣的 LSTM 加上一些調整，試圖預測亞馬遜評論中的下一個標記，下一個字元。我們發現，如果你能足夠好地預測下一個字元，那個 LSTM 內部就會有一個神經元對應於它的情感。這真的很酷，因為它顯示了非監督式學習的一些進展。

它驗證了這樣一個想法：真正好的下一個字元預測，下一個某物的預測，也就是壓縮，確實有可能發現資料中的秘密。這就是我們在這些 GPT 模型中看到的，對吧？你進行訓練，人們說這只是統計相關性。我的意思是，到了這個時候，任何人都應該很清楚，那種觀察，對我來說，直觀地開啟了整個世界：我從哪裡獲得非監督式學習的資料？因為如果我能讓你預測下一個字元，我就有大量的資料，而且我知道標準答案是什麼，我知道答案是什麼，我就可以用它來訓練一個神經網路。所以那項觀察、遮罩（masking）以及其他技術、其他方法，開啟了我的思路，關於世界將從哪裡獲得所有用於非監督式學習的資料。

## 強化學習之路：從遊戲到 RLHF

你一直相信擴大規模（scaling）會提高這些模型的性能，是的，更大的網路，更深的網路，更多的訓練資料會擴大規模。OpenAI 發表了一篇關於擴展定律（scaling laws）以及損失（loss）與模型大小、資料集大小之間關係的非常重要的論文。當 Transformer 出現時，它給了我們機會在非常合理的時間內訓練非常非常大的模型。但是，關於擴展定律或模型和資料大小的直覺，以及你 GPT-1、2、3 的旅程，哪個先出現？你是先看到了 GPT 1 到 3 的證據，還是先有了關於擴展定律的直覺？

直覺。所以，我會這樣說，我堅信越大越好，我們在 OpenAI 的目標之一就是弄清楚如何正確地使用規模。從一開始，OpenAI 內部就對規模有著強烈的信念。問題是，具體用它來做什麼？因為我現在要提到，我們正在談論 GPT，但還有另一條非常重要的工作線，我還沒有提到，那就是第二個大想法。但我認為現在是繞道談談的好時機，那就是強化學習。這顯然也很重要，你用它做什麼？所以在 OpenAI 內部完成的第一個真正的大項目是我們努力解決一個即時戰略遊戲。背景是，即時戰略遊戲就像一項競技運動，是的，對吧，你需要聰明，你需要更快，你需要快速的反應時間，有團隊合作，而且你在與另一支隊伍競爭，這相當複雜。

而且那個遊戲有一個完整的競技聯盟，遊戲叫做 Dota 2。所以我們訓練了一個強化學習代理與自己對抗，目標是達到一個水平，以便能與世界上最好的玩家競爭。那也是一個重大的任務，是一條非常不同的路線，是強化學習。是的，我記得你們宣布那項工作時的數據。順便說一下，這就是我之前問到的關於 OpenAI 產出了大量工作，其中一些看起來像是繞道，但實際上，正如你現在解釋的，它們可能看起來是繞道，但它們確實導向了我們現在正在談論的一些重要工作，比如 GPT。

是的，我的意思是，確實存在真正的融合，GPT 提供了基礎，而來自 Dota 的強化學習演變成了來自人類回饋的強化學習（RLHF）。沒錯，而這種結合給了我們 ChatGPT。

## 大型語言模型：透過預測學習世界

你知道，有一個誤解，認為 ChatGPT 本身只是一個巨大的大型語言模型，但它周圍有一個相當複雜的系統。你能否為觀眾簡要解釋一下微調、強化學習、以及各種周邊系統，讓你們能夠控制它、給予它知識等等？

是的，我可以。思考它的方式是，當我們訓練一個大型神經網路來準確預測網路上大量不同文本中的下一個詞時，我們正在做的是學習一個世界模型。看起來我們正在學習這個，表面上可能看起來我們只是在學習文本中的統計相關性，但事實證明，僅僅為了學習文本中的統計相關性，為了把它們壓縮得非常好，神經網路學到的是產生這些文本的過程的某種表示。這些文本實際上是世界的投影。外面有一個世界，它在這個文本上留下了投影，所以神經網路正在學習的是越來越多關於世界、關於人、關於人類狀況、他們的希望、夢想和動機、他們的互動以及我們所處情境的方面。神經網路學習了這些的一個壓縮的、抽象的、可用的表示。這就是透過準確預測下一個詞所學到的。此外，你預測下一個詞越準確，這個過程的保真度就越高，解析度就越高。

這就是預訓練階段所做的。但這並沒有指定你希望我們的神經網路展現出的期望行為。你看，一個語言模型，它真正試圖回答的是以下問題：如果我在網路上隨機看到一段文本，它以某個前綴、某個提示開始，它會如何補全？如果你只是隨機地在網路上看到某段文本。但這不同於：我想要一個助手，它要真實，要有幫助，要遵守某些規則而不違反它們。這需要額外的訓練。這就是微調和來自人類教師的強化學習以及其他形式的 AI 輔助發揮作用的地方。不僅僅是來自人類教師的強化學習，也是來自人類和 AI 協作的強化學習。我們的教師與 AI 一起工作，教導我們的 AI 如何行事。但在這裡，我們不是在教它新知識。

這不是正在發生的事情。我們是在教導它，我們在與它溝通，我們在向它傳達我們希望它成為什麼樣子。這個過程，第二階段，也極其重要。我們第二階段做得越好，這個神經網路就會越有用、越可靠。所以第二階段也極其重要，除了第一階段的學習一切，盡可能多地從世界的投影中學習關於世界的一切。

## GPT-4 的躍升：理解、推理與多模態

（ChatGPT）幾個月前才問世，是人類歷史上增長最快的應用程式。關於原因有很多很多解釋，但其中一些顯而易見的事情是，它是任何人創造過的最容易使用的應用程式。它執行任務，它做事情，它做的事情超乎人們的預期。任何人都可以使用它，沒有說明書，沒有錯誤的使用方式，你只需使用它。如果你的指令或提示是模稜兩可的，對話會釐清歧義，直到你的意圖被應用程式、被 AI 理解。其影響當然非常顯著。現在，昨天，也就是 GPT-4 發布後的第二天，僅僅幾個月後，GPT-4 在許多領域的表現令人震驚：SAT 分數、GRE 分數、律師資格考試，它能夠在非常高水平、非常能幹的人類水平上執行的測試數量令人震驚。ChatGPT 和 GPT-4 之間的主要區別是什麼，導致了它在這些領域的改進？

所以，GPT-4 是在 ChatGPT 基礎上的一個相當大的改進，涵蓋了非常多的維度。我們訓練 GPT-4，我想說，是在六個多月前，也許是八個月前，我不記得了。GPT（應指基礎模型）是 ChatGPT 和 GPT-4 之間的第一個巨大差異，這也許是最重要的差異，那就是 GPT-4 所基於的基礎模型能以更高的準確性預測下一個詞。這非常重要，因為一個神經網路預測文本中下一個詞的能力越好，它對文本的理解就越深。這個說法現在可能已經被許多人接受了，但對於為什麼會這樣，可能仍然不夠直觀或不完全直觀。所以我想稍微繞個彎，給出一個類比，希望能澄清為什麼更準確地預測下一個詞會帶來更深的理解，真正的理解。

讓我們考慮一個例子，假設你讀一本偵探小說，情節複雜，故事情節曲折，人物眾多，事件繁多，充滿謎團和線索，很不清晰。然後假設在書的最後一頁，偵探已經收集了所有線索，召集了所有人，說：「好了，我要揭露罪犯的身份了，那個人的名字是……」預測那個詞。準確地預測那個詞。天哪，對吧？是的。現在，雖然有很多不同的詞，但透過越來越好地預測那些詞，對文本的理解程度不斷提高。GPT-4 能更好地預測下一個詞。是的。

人們說深度學習不會帶來推理能力，深度學習不會帶來推理能力。但為了預測那個下一個詞，從所有在場的代理人以及他們的所有優點或缺點或意圖和背景中找出答案，並且能夠預測出那個詞——誰是兇手——這需要一定程度的推理，相當程度的推理。那麼，它是如何學會推理的呢？如果它學會了推理，你知道，我想問你的一個問題是，在 ChatGPT 和 GPT-4 之間進行的所有測試中，有些測試 GPT-3 或 ChatGPT 已經做得很好，有些測試 GPT-3 或 ChatGPT 做得不那麼好，而 GPT-4 做得好得多，還有一些測試兩者都還做得不好。我很想知道，其中一些似乎與推理有關，也許在微積分方面，它無法將問題分解成合理的步驟來解決？

但是，在某些領域，它似乎展示了推理能力。那麼，這是否是一個在預測下一個詞的過程中學習推理的領域？以及，GPT-4 現在有哪些限制會阻礙其推理能力的進一步提升？

你知道，推理並不是一個定義得非常清晰的概念，但我們可以試著這樣定義它：當你或許能夠更進一步，能夠以某種方式多思考一下，並因為你的推理而得到更好的答案。我想說，神經網路，你知道，也許存在某種限制，可以透過例如要求神經網路大聲思考來解決。這已被證明對推理極其有效。但我認為，基礎神經網路究竟能走多遠還有待觀察。我認為我們尚未完全發掘它的潛力。但是，是的，我的意思是，在某些方面，推理確實還沒有達到神經網路其他某些能力的水平。儘管我們希望神經網路的推理能力更高，我認為很有可能，按部就班地發展將會持續提高神經網路的推理能力。我不會，我不會必然自信地排除這種可能性。

是的，因為其中一件很酷的事情是，你問 ChatGPT 一個問題，在它回答問題之前，先告訴我你知道什麼，然後再回答問題。你知道，通常當有人回答問題時，如果你先告訴我你擁有的基礎知識或你做出的基礎假設，然後再回答問題，這確實會提高我對答案的可信度。當你展示推理過程時，你也在展示一定程度的推理能力。所以在我看來，ChatGPT 內在就嵌入了這種能力。

是的，在某種程度上是這樣。思考現在正在發生的事情的一種方式是，這些神經網路擁有許多這些能力，只是它們還不夠可靠。事實上，你可以說可靠性目前是這些神經網路變得有用、真正有用的最大單一障礙。如果它們有時仍然會產生一些幻覺，或者犯一些意想不到的錯誤，是你不會期望人犯的錯誤，正是這種不可靠性使得它們的用處大大降低。但我認為，也許再多一點研究，利用我們現有的想法，也許再加上一些更具雄心的研究計劃，我們也能夠實現更高的可靠性。那將會真正有用，那將使我們能夠擁有非常精確、非常準確的護欄。沒錯。並且會讓它在不確定的地方要求澄清，或者在不知道某事時說不知道，需要更多信息，並且極其可靠地做到這一點。所以我認為這些是目前真正的瓶頸。

## 多模態學習：拓展理解的維度

所以這不是關於它是否展現出某種特定能力的問題，而更多是關於可靠程度的問題。完全正確。

多模態。GPT-4 能夠從文本和圖像中學習，並對來自文本和圖像的輸入做出回應。首先，多模態學習的基礎，當然，Transformer 使我們能夠從多模態中學習，對文本和圖像進行標記化。但在基礎層面上，請幫助我們理解多模態如何增強對世界的理解，超越單純的文本？而且我的理解是，當你進行多模態學習時，即使只是文本提示，文本理解能力實際上也可能得到增強。請告訴我們多模態在基礎層面的重要性，以及由此產生的主要突破和特性差異。

所以，多模態有兩個維度，兩個它之所以有趣的原因。第一個原因比較謙遜，第一個原因是多模態很有用。讓神經網路能夠看到視覺信息特別有用，因為世界是非常視覺化的，人類是非常視覺化的動物。我相信人類大腦皮層的三分之一視覺核心是專門用於視覺的。因此，如果沒有視覺能力，我們的神經網路雖然仍然相當可觀，但其用處就不如它本可以達到的那麼大。所以這是一個非常簡單的有用性論證，能看見東西本身就很有用，而 GPT-4 看得相當好。關於視覺，還有第二個原因，那就是我們透過從圖像中學習，除了從文本中學習之外，可以更多地了解世界。

這也是一個強有力的論證，儘管它並不像看起來那麼清晰。我給你舉個例子，或者在舉例之前，我先做個一般性的評論。對於人類，我們人類，我們一生中大概能聽到十億個詞。只有十億個詞。這太驚人了。是的，這不算多。是的，這不算多。所以我們需要補充，我們需要……這還不包括我自己腦子裡的詞。那就二十億吧，但你明白我的意思。

是的，我們可以這樣看，因為十億秒是 30 年。所以你可以大概看到，我們每秒鐘看不到幾個詞。如果你有一半時間在睡覺，那麼幾十億個詞就是我們一生中得到的全部。因此，盡可能多地獲取信息來源對我們來說變得非常重要，我們絕對從視覺中學到更多東西。同樣的論點也適用於我們的神經網路，除了，除了神經網路可以從如此多的詞語中學習這一事實。

所以，那些很難從幾十億詞的文本中了解世界的事情，可能會從數萬億詞中變得更容易。我給你舉個例子，考慮顏色。當然，人需要看見才能理解顏色。然而，那些從未見過一個光子的純文本神經網路，如果你問它們哪些顏色彼此更相似，它會知道紅色比藍色更像橙色。它會知道藍色比黃色更像紫色。這是怎麼發生的？

一個答案是，關於世界的信息，即使是視覺信息，也會慢慢地透過文本滲透進來，但速度很慢，不如視覺快。但是當你有大量文本時，你仍然可以學到很多東西。當然，一旦你同時加入了視覺和從視覺中學習世界，你會學到額外的、文本中未捕捉到的東西。但我不會說這是一個二元對立，有些東西是完全不可能只從文本中學到的。我認為這更像是一個匯率問題，特別是當你想要學習時，如果你像人類一樣，想從十億或一億詞中學習，那麼當然，其他信息來源就變得遠為重要。

在你看到的關於分數的背景下，非常有趣的是你們發布的數據，顯示了哪些測試 GPT-3 表現良好，哪些測試 GPT-4 表現顯著更好。你認為多模態對這些測試的貢獻有多大？

哦，我的意思是，是以一種非常直接的方式。任何時候，如果有一個測試，其中一個問題需要你看圖表才能理解，比如，在一些數學競賽中，像有一個針對高中生的數學競賽叫做 AMC 2012，對吧，那裡大概很多問題都有圖表。所以 GPT-3.5 在那個測試上表現相當差。GPT-4 僅使用文本，我想，我不記得了，但大概是從 2% 的成功率提高到 20% 的準確率。但當你加入視覺能力時，它躍升到 40% 的成功率。所以視覺確實起了很大作用。視覺能力非常好，我認為能夠進行視覺推理並進行視覺交流也將非常強大和美好，這些都超越了僅僅學習關於世界。

你有好幾樣東西需要學習，你可以學習關於世界，你可以進行視覺推理，你可以進行視覺交流。現在，在未來，也許在某個未來版本中，如果你問你的神經網路：“嘿，給我解釋一下這個”，它不會只生成四段文字，而是會生成：“嘿，這有個小圖表，清楚地向你傳達了你需要知道的一切。”那真是不可思議。

## 未來挑戰與展望：可靠性的追求

請告訴我們，盡你所能，關於我們現在所處的位置，以及你認為在不久的將來，但也不要太遙遠，比如一兩年內，整個語言模型領域會發展到什麼程度，以及你最感興趣的一些領域。

你知道，預測很難，而且，雖然很難說出太具體的事情，但我認為可以安全地假設進展將會繼續，我們將不斷看到系統在它們能做的事情上令我們震驚。當前的前沿將圍繞可靠性，圍繞系統是否可以被真正信任，達到一個你可以信任它產出的程度，達到一個如果它不理解某事，它會要求澄清，說它不知道某事，說它需要更多信息的程度。我認為這些可能是最大的，改進將對這些系統的用處產生最大影響的領域。因為現在，這確實是阻礙因素。你讓 AI，你讓神經網路，也許總結一些長文檔，你得到一個摘要。

你確定某些重要細節沒有被遺漏嗎？這仍然是一個有用的摘要，但當你知道所有重要的點都已被涵蓋時，情況就不同了。就像，特別是，即使存在合理的模糊性，也沒關係，但如果一個點顯然很重要，以至於任何看到那個點的人都會說這非常重要，那麼當神經網路也能可靠地認識到這一點時，那才是關鍵。同樣適用於護欄，同樣適用於它清晰地遵循用戶、操作者意圖的能力。所以我認為在接下來的兩年裡我們會看到很多這方面的進展。是的，因為這兩個領域的進展將使這項技術被人們信任使用，並能夠應用於如此多的事情。

我本以為那會是最後一個問題，但我還有一個，抱歉。好的。所以，ChatGPT 到 GPT-4。當你第一次開始使用 GPT-4 時，它展示了哪些讓你都感到驚訝的技能？

嗯，它展示了很多非常酷的東西，確實非常酷且令人驚訝。它相當不錯。所以，我會提到兩個，讓我看看，我只是在想最好的表達方式。簡短的回答是，它的可靠性水平令人驚訝。之前的神經網路，如果你問它們一個問題，有時它們可能會以一種有點傻的方式誤解某些東西，而 GPT-4 則不再發生這種情況。它解決數學問題的能力變得強大得多。就像，你真的可以，有時候，你知道，真正進行推導，進行冗長複雜的推導，你可以轉換單位等等，那真的很酷。你知道，像很多人…

它能完成一個證明。它能完成一個證明，這相當驚人。當然不是所有的證明，但相當一部分是的。或者另一個例子，像很多人注意到的，它有能力創作詩歌，你知道，每個詞都以相同的字母開頭，或者每個詞都以某個…它非常非常清晰地遵循指令。仍然不完美，但比以前好得多。是的，非常好。在視覺方面，我真的很喜歡它解釋笑話的能力，它可以解釋迷因（memes）。你給它看一個迷因，問它為什麼好笑，它會告訴你，而且是正確的。視覺部分我認為也非常… 就像真的親眼看到它，當你可以就某個帶有複雜圖表的複雜圖像提出後續問題並得到解釋時，那真的很酷。

## 回顧與驚嘆：神經網路的意外成功

但是，是的，總的來說，退一步說，你知道，我從事這個行業已經有相當長的時間了，實際上，差不多整整 20 年了。[音樂] 而我發現最令人驚訝的事情是，它竟然真的奏效了。是的。就像，結果證明，一直以來都是同一個小東西，雖然現在不再小了，而且嚴肅得多，也更加激烈，但它是同一個神經網路，只是更大了，可能在更大的數據集上以不同的方式訓練，但使用的是相同的基本訓練算法。是的。所以，就像，哇。我想說這是我覺得最驚訝的。是的。每當我退一步思考，我就會想，那些關於“嗯，大腦有神經元，所以也許人工神經元也一樣好，所以也許我們只需要用某種學習算法來訓練它們”的觀念性想法，怎麼可能如此難以置信地正確？那會是最大的驚喜。

