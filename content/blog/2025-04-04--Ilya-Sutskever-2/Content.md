---
layout: post
title: "Ilya Sutskever: 建構 AGI、對齊、未來模式、間諜、微軟、台灣與啟蒙"
date: 2024-04-04
categories: [
  'Ilya Sutskever',
  '人工智慧',
  '2023',

]
description: "這篇訪談記錄了 Dwarkesh Patel 對 OpenAI 共同創始人暨首席科學家 Ilya Sutskever 的深入對話。內容涵蓋了通用人工智慧（AGI）的建構路徑、模型對齊（Alignment）的挑戰與重要性、未來模型的發展方向、AI 的經濟與社會影響、當前技術的限制（如可靠性）、數據與計算資源的角色、與微軟的合作關係、對潛在間諜活動和地緣政治風險（如台灣）的看法，以及對 AGI 可能如何幫助人類提升認知與實現啟蒙的哲學思考。Sutskever 強調了持續研究、理解模型行為以及多種方法結合對於實現安全且有益的 AGI 的重要性。"
toc: true # 啟用目錄功能

---

<span class="original-link">原文連結： [Ilya Sutskever: 建構 AGI、對齊、未來模式、間諜、微軟、台灣與啟蒙](https://www.dwarkesh.com/p/ilya-sutskever)</span>

**本次採訪為2023/3/27 Ilya Sutskever的採訪**

Ilya Sutskever
但我不會低估與實際上比我們更聰明的模型、能夠歪曲其意圖的模型的對齊（alignment）難度。

Dwarkesh Patel
你擔心間諜嗎？

Ilya Sutskever
我真的不擔心它被洩露的方式。我們都能變得更加開明，因為我們將與一個通用人工智慧（AGI）互動，它將幫助我們更正確地看待世界。就像，想像一下與歷史上最好的冥想老師交談。Microsoft 一直是我們非常非常好的合作夥伴。所以我質疑下一個標記預測不能超越人類表現的說法。

如果你的基礎神經網路足夠聰明，你只需問它，像，一個擁有卓越洞察力、智慧和能力的人會怎麼做？

Dwarkesh Patel
好的。今天我很榮幸能採訪 Ilya Suitsgever，他是 OpenAI 的聯合創始人兼首席科學家。Elia，歡迎來到月球協會（Lunar Society）。

## 區別頂尖科學家的特質

Ilya Sutskever
謝謝。很高興來到這裡。

Dwarkesh Patel
第一個問題，不允許謙虛。有很多科學家，或者也許沒有那麼多科學家，會在他們的領域取得重大突破。但在他們的職業生涯中，能夠做出多個獨立的、定義他們領域的突破的科學家則少得多。區別是什麼？

是什麼讓你與其他研究人員不同？為什麼你能在航空領域（應為人工智慧領域）取得多個突破？

Ilya Sutskever
嗯，謝謝你的好話。

很難回答這個問題。我的意思是，我非常努力。我付出了你所擁有的一切。

到目前為止，這奏效了。

我想僅此而已。

Dwarkesh Patel
明白了。

為什麼 GPT 沒有被更多地非法使用的解釋是什麼？為什麼沒有更多外國政府用它來散佈宣傳或詐騙老奶奶之類的？

Ilya Sutskever
我的意思是，也許他們還沒有真正開始大量地這樣做，但如果現在已經有一些這樣的事情發生，我也不會感到驚訝。當然可以想像他們會使用一些開源模型並試圖將它們用於那個目的。

就像，我當然，我會預計這將是他們未來會感興趣的事情。

Dwarkesh Patel
這在技術上是可能的，他們只是還沒有。

Ilya Sutskever
想得夠多，或者還沒有像大規模使用他們的技術那樣去做。或者也許它正在發生，只是你不知道而已。

Dwarkesh Patel
如果正在發生，你能追蹤到嗎？

Ilya Sutskever
我認為大規模追蹤是可能的，是的。我的意思是，這需要一個小的特殊操作。是可能的。

## AGI 的時間表與經濟影響

Dwarkesh Patel
現在有一個窗口期，AI 在經濟上非常有價值，其規模相當於飛機，比方說。但我們還沒有達到 AGI。那個窗口期有多大？

Ilya Sutskever
我的意思是，我認為這個窗口期，很難給你一個精確的答案，但它肯定會是一個好幾年的窗口期。這也是一個定義問題，因為 AI 在成為 AGI 之前，其價值將會年復一年地越來越大，我會說，是以指數級的方式。所以在某種意義上，可能會感覺像，尤其是在事後看來，可能會感覺只有一兩年，因為那兩年比之前的幾年更大。但我會說，僅去年一年，AI 就已經產生了相當可觀的經濟價值。明年會更大，之後會更大。所以我認為將會有一段好幾年的時間，但我會說，從現在到 AGI，基本上都會是這樣。

Dwarkesh Patel
好的，嗯，因為我很好奇，如果有一家初創公司正在使用你們的模型，對吧。

在某個時刻，如果你擁有了 AGI，世界上就只有一個生意了，對吧？那就是 OpenAI。他們還有多少窗口期？任何企業還有多少窗口期，他們實際上在生產 AGI 無法生產的東西？

Ilya Sutskever
是的，嗯，我的意思是，這是一樣的，這和問 AGI 還有多久到來是同一個問題？我認為這是一個很難回答的問題。我的意思是，我也猶豫是否要給你一個數字，因為存在這種「觀望效應」（stainware effect），樂觀的人，從事這項技術的人，往往會低估到達目標所需的時間。但我認為我讓自己立足的方式是特別思考自動駕駛汽車。有一個類比，如果你看看特斯拉，看看它的自動駕駛行為，它看起來什麼都能做。

它什麼都能做。

但也很明顯，在可靠性方面還有很長的路要走。

我們可能在我們的模型方面也處於類似的位置，看起來我們也能做所有事情，與此同時，我們需要做更多的工作，直到我們真正解決所有問題，讓它變得真正好、真正可靠、健壯和…

Dwarkesh Patel
到 2030 年，表現良好。AI 將佔 GDP 的百分之多少？

Ilya Sutskever
哦，天哪。很難回答這個問題。非常難回答。

Dwarkesh Patel
給我一個大致範圍。

Ilya Sutskever
就像，問題是我的誤差範圍是對數級的。所以我可以想像，像，我可以想像一個巨大的百分比。我也可以同時想像一個令人失望的小百分比。

Dwarkesh Patel
好的，那麼讓我們假設一個反事實，即它只佔很小的比例。假設現在是 2030 年，你知道，這些大型語言模型並沒有創造出那麼多的經濟價值。儘管你認為這不太可能。你現在最好的解釋是什麼？為什麼會發生這樣的事情？

Ilya Sutskever
我最好的解釋。所以我真的不認為那是一個很可能發生的情況。

所以這是評論的前言。但如果我要接受你問題的前提，嗯，就像，為什麼事情在現實世界影響方面令人失望？我的答案會是可靠性。如果不知何故最終證明你真的希望它們可靠而它們最終並不可靠，或者如果可靠性被證明比我們預期的更難，我真的不認為會是這樣。但如果我必須選一個，如果我必須選一個而你告訴我，像，嘿，像，為什麼事情沒有成功？那會是可靠性，你仍然需要檢查答案並仔細核對一切。而那確實會對這些系統能夠產生的經濟價值造成很大的抑制。

Dwarkesh Patel
它們在技術上會成熟。問題只是它們是否足夠可靠。

Ilya Sutskever
是的，嗯，在某種意義上，不可靠意味著技術上不成熟，如果你明白我的意思。

## 通往 AGI 的技術範式：侷限與超越

Dwarkesh Patel
是的，說得有理。

生成模型之後是什麼？所以，在你研究強化學習之前，這基本上就是它了嗎？這是一個能讓我們達到 AGI 的範式嗎？或者在這之後還有別的東西？

Ilya Sutskever
我的意思是，我認為這個範式會走得非常非常遠，我不會低估它。我認為這個確切的範式很可能不會完全是 AGI 的形式因素。我的意思是，我猶豫是否要精確地說下一個範式會是什麼，但我認為它可能會涉及整合過去出現的所有不同想法。

Dwarkesh Patel
你指的是某個具體的想法嗎？還是…

Ilya Sutskever
我的意思是，很難具體說明。

Dwarkesh Patel
所以你可以說，下一個標記預測只能幫助我們達到人類的表現水平，也許無法超越。要超越人類表現水平需要什麼？

Ilya Sutskever
所以我質疑下一個標記預測無法超越人類表現的說法。

表面上看來，它似乎不能。表面上看來是這樣。如果你只是學習模仿，預測人們做什麼，這意味著你只能複製人們。

但這裡有一個反駁的論點，說明為什麼可能不完全是這樣。如果你的神經網路，如果你的基礎神經網路足夠聰明，你只需問它，像，什麼會，什麼樣的人會感覺擁有卓越的洞察力、智慧和能力會怎麼做？

也許這樣的人不存在，但很有可能神經網路能夠推斷出這樣一個人會如何行事。你明白我的意思嗎？

Dwarkesh Patel
是的。儘管它會從哪裡獲得關於那個人會做什麼的洞察力，如果不是來自普通人的數據？

Ilya Sutskever
因為，就像，如果你想一想，足夠好地預測下一個標記意味著什麼？它實際上意味著什麼？這，實際上，這是一個比看起來更深的問題。很好地預測下一個標記，意味著你理解了導致那個標記產生的潛在現實。

這不是統計學，就像，它是統計學，但什麼是統計學？

為了理解那些統計數據，為了壓縮它們，你需要理解是什麼關於世界創造了這些統計數據？然後你說，好吧，我有所有那些人。是什麼關於人創造了他們的行為？嗯，他們有，你知道，他們有思想，他們有感情，他們有想法，他們以某些方式做事。所有這些都可以從下一個標記預測中推斷出來。我會認為這應該使得，不是無限期地，而是到一個相當可觀的程度，可以說，嗯，你能猜到如果你把一個具有，像，這種特徵和那種特徵的人放在一起，你會做什麼嗎？像這樣的人不存在，但因為你在預測下一個標記方面如此出色，你仍然應該能夠猜到那個人會做什麼。這個假設的、虛構的、心智能力遠超我們其餘人的人。

Dwarkesh Patel
當我們在這些模型上進行強化學習時，還有多久大部分強化學習的數據會來自 AI 而不是人類？

Ilya Sutskever
我的意思是，現在大部分強化學習的數據已經來自 AI 了。是的，嗯，就像人類被用來訓練獎勵函數，但是之後，但是之後獎勵函數與模型的交互是自動的。所有在強化學習過程中生成的數據都是由 AI 創建的？所以，像，如果你看看當前的，我會說，技術範式，由於聊天機器人 GPT 而受到相當多關注。來自人類回饋的強化學習。有人類回饋。人類回饋被用來訓練獎勵函數，然後獎勵函數被用來創建訓練模型的數據。

Dwarkesh Patel
明白了。有沒有希望完全把人類從循環中移除，讓它以某種 AlphaGo 的方式自我改進？

Ilya Sutskever
是的，當然。我的意思是，我覺得在某種意義上，我們的希望，像，我們的計劃，非常如此。你真正想要的是，告訴 AI 教導 AI 的人類教師，讓他們與 AI 合作，你可能想這樣想。你可能想把它想像成一個世界，人類教師做 1% 的世界和工作，而 AI 做 99% 的工作。你不希望它是 100% 的 AI，但你確實希望它是人機協作，來教導下一個機器。

Dwarkesh Patel
所以目前，我的意思是，我有機會把玩這些模型。它們在多步驟推理方面似乎很糟糕，它們一直在變得更好，但要真正超越那個障礙需要什麼？

Ilya Sutskever
我的意思是，我認為專門的訓練會讓我們達到目標。更多，更多基礎模型的改進會讓我們達到目標。但是，像，從根本上說，我也不覺得它們在多步驟推理方面那麼糟糕。我實際上認為它們在心理上的多步驟推理方面很糟糕，但它們不被允許大聲思考。但當它們被允許大聲思考時，它們相當不錯。

我預計這會顯著改善，無論是透過更好的模型還是透過特殊訓練。

Dwarkesh Patel
你在網路上耗盡推理標記了嗎？它們夠用嗎？

Ilya Sutskever
我的意思是，你知道。好的，關於這個問題的背景，像，有，有說法認為，確實，在某個時刻，我們將會耗盡用於訓練這些模型的通用標記。而且，是的，我認為這總有一天會發生。到那時，我們需要有其他訓練模型的方法，其他有效提高它們能力和磨練它們行為的方法，確保它們完全、精確地按照我們的意願行事，而無需更多數據。

## 數據、多模態與機器人學的挑戰

Dwarkesh Patel
你還沒有耗盡數據？還有更多。

Ilya Sutskever
是的，我會說數據情況仍然相當好。還有很多路要走，但在某個時刻，是的，在某個時刻，數據將會耗盡。

Dwarkesh Patel
好的，最有價值的數據來源是什麼？是 Reddit、Twitter？書籍？

你會用其他種類的許多標記來交換什麼？

Ilya Sutskever
一般來說，你會想要那些談論更聰明事物的標記，那些更有趣的標記。

Dwarkesh Patel
是的。

Ilya Sutskever
所以，我的意思是，你提到的所有來源，它們都是有價值的。

Dwarkesh Patel
好的，所以也許不是 Twitter，但我們是否需要轉向多模態來獲取更多標記，或者我們仍然有足夠的文本標記剩下？

Ilya Sutskever
我的意思是，我認為僅靠文本仍然可以走得很遠，但轉向多模態似乎是一個非常有成果的方向。

Dwarkesh Patel
如果你方便談論這個，像，我們還沒有抓取標記的地方在哪裡？是的。

Ilya Sutskever
哦，我的意思是，是的，顯然。我的意思是，我不能替我們回答那個問題，但我確定對每個人來說，那個問題都有不同的答案。

Dwarkesh Patel
僅僅透過算法改進，而不是來自規模或數據，我們能獲得多少個數量級的提升？

Ilya Sutskever
很難回答，但我確定有一些。

Dwarkesh Patel
一些是很多，還是一些很少？

Ilya Sutskever
我的意思是，只有一種方法可以找出答案。

Dwarkesh Patel
好的，讓我聽聽你對這些不同研究方向的快速看法。檢索 Transformer。所以就像，以某種方式將數據存儲在模型本身之外並進行檢索。

Ilya Sutskever
不知何故似乎很有希望。

Dwarkesh Patel
但你認為這是一條前進的道路，還是…

Ilya Sutskever
我認為這似乎很有希望。

Dwarkesh Patel
機器人學。OpenAI 放棄這個領域是正確的一步嗎？

Ilya Sutskever
是的，它是。就像，那時候，繼續從事機器人學研究真的不可能，因為數據太少了。就像那時候，如果你想做機器人，如果你想從事機器人學研究，你需要成為一家機器人公司。你真的需要有一個龐大的團隊來建造機器人、維護它們並擁有它們。

即使那樣，像，如果你只有。如果你將擁有 100 個機器人，那已經是一個巨大的運營了，但你不會得到那麼多數據。

所以在一個大部分進展來自計算和數據結合的世界裡，對吧，這就是我們一直以來的情況，計算和數據的結合推動了進展，沒有從機器人學中獲取數據的途徑。

所以在過去，當你決定停止從事機器人學研究時，沒有前進的道路。

Dwarkesh Patel
現在有了嗎？

Ilya Sutskever
所以我會說，現在創造一條前進的道路是可能的，但需要真正致力於機器人學的任務。你真的需要說，我要建造，像，數千個，數萬個，數十萬個機器人，並以某種方式從它們那裡收集數據，並找到一條漸進的路徑，讓機器人做一些稍微更有用的事情，然後它們從這些機器人那裡得到的數據，然後獲得並用於訓練模型的數據，它們再做一些稍微更有用的事情。所以你可以想像這種漸進的改進路徑，你建造更多的機器人，它們做更多的事情，你收集更多的數據等等，但你真的需要致力於這條路徑。如果你說，我想讓機器人學成為現實，這就是你需要做的。我相信有一些公司正在考慮這樣做，正是這樣做。但我認為你需要真正熱愛機器人，並且需要真正願意解決處理它們的所有物理和後勤問題。這與軟體完全不同。

所以我認為今天只要有足夠的動力，就可以在機器人學方面取得進展。

Dwarkesh Patel
你有什麼想法很想嘗試，但因為它們在當前硬件上效果不好而無法實現？

Ilya Sutskever
我不認為當前的硬件是一個限制因素。

Dwarkesh Patel
好的。

Ilya Sutskever
我認為情況並非如此。

Dwarkesh Patel
明白了。所以。但任何你想嘗試的事情，你都可以馬上開始。

Ilya Sutskever
或者，我的意思是，當然，像，你可能會說，嗯，我希望當前的硬件更便宜，或者也許它有更高的，像，也許。也許如果處理器內存帶寬更高會更好，比方說。

但總的來說，硬件只是限制。

## 對齊：定義、方法與挑戰

Dwarkesh Patel
讓我們談談對齊（alignment）。你認為我們最終會對對齊有一個數學定義嗎？

Ilya Sutskever
數學定義，我認為不太可能。

Dwarkesh Patel
嗯哼。

Ilya Sutskever
就像，我確實。我確實認為我們將會有多個，像，而不是，而不是達成一個數學定義。我認為我們將會達成多個從不同方面看待對齊的定義，我認為這就是我們將如何獲得我們想要的保證的方式。

我的意思是，你可以觀察行為，你可以觀察在各種測試中、在各種對抗性壓力情況下的行為。你可以觀察神經網路內部是如何運作的。

我認為你必須同時考慮所有這些因素中的幾個。

Dwarkesh Patel
在你將模型發佈到野外之前，你必須有多短的時間？是 100% 還是 95%？

Ilya Sutskever
取決於模型的能幹程度。模型越能幹，你就需要越自信。

Dwarkesh Patel
好的，所以就說它是幾乎達到通用人工智慧（AGI）的東西。AGI 在哪裡？

Ilya Sutskever
嗯，這取決於你的 AGI 能做什麼。請記住，AGI 是一個模棱兩可的術語。也像你的普通大學本科生就是一個 AGI，對吧？

Dwarkesh Patel
我會說這一切，是的，但是你…

Ilya Sutskever
明白我的意思。關於 AGI 指的是什麼，存在顯著的歧義。因此，根據你設定這個標記的位置，你需要或多或少地自信。

Dwarkesh Patel
嗯，你之前提到了幾條通往對齊的道路。你認為目前最有希望的是哪一條？

Ilya Sutskever
我認為這將會是一個組合。我真的認為你不會只想擁有一種方法。我認為人們會想要一種方法的組合，我們會花費大量的計算來對抗性地，可能是為了找到我們想要教導的行為與它實際展現的行為之間的任何不匹配。我們會審視內部，審視神經網路內部，使用另一個神經網路來理解它內部是如何運作的。我認為所有這些都將是必要的。像這樣的每一種方法都會降低錯位的概率。

而且你也希望處在一個你的對齊程度的增長速度快於模型能力增長速度的世界裡。我會說，現在我們對我們模型的理解仍然相當初級。我們取得了一些進展，但還有更多的進展是可能的。所以我預計最終真正會成功的是當我們有一個小的、被充分理解的神經網路，它的任務是研究一個大的、不被理解的神經網路的行為，來驗證它。

Dwarkesh Patel
到什麼時候大部分的 AI 研究是由 AI 完成的？

Ilya Sutskever
由 AI，我的意思是，所以今天當你使用 copilot 時，對吧，比例是多少？你如何劃分？所以我預計在某個時刻，你會問你的 charge apt 的後代，你會說，嘿，我正在考慮這個和這個。你能建議一些我應該嘗試的有成果的想法嗎？你實際上會得到有成果的想法，我認為這將使你能夠解決你以前無法解決的問題。

Dwarkesh Patel
明白了。但不知何故，它只是告訴人類，給他們想法，更快或者別的什麼。它本身並沒有與…互動。

Ilya Sutskever
一個例子。我的意思是，你可以從各種角度來剖析它，但我認為瓶頸在於好的想法、好的洞見，而這正是神經網路可以幫助我們的地方。

Dwarkesh Patel
如果你能設計一個像十億美元獎金，用於某種對齊研究成果或產品，你會為那個十億美元獎金設定什麼樣的具體標準？是否有什麼對這樣的獎金來說是有意義的？

Ilya Sutskever
你問這個很有趣。我實際上正在思考這個確切的問題。

我還沒有想出確切的標準。也許是某種，有益處的東西，也許是一個獎項，我們可以說兩年後或三年或五年後，我們回顧時會說那是主要的成果。

所以與其說有一個承諾的獎項，立即決定，不如等待五年然後追溯性地頒發。

Dwarkesh Patel
但目前還沒有我們可以確定的具體事物。好像如果你解決了這個特定的問題，你就取得了很大的進展。

Ilya Sutskever
取得了很大的進展，是的。我不會說那是全部。

Dwarkesh Patel
你認為端到端訓練是越來越大的模型的正確架構嗎？還是我們需要更好的方式來僅僅連接事物？

Ilya Sutskever
我認為端到端訓練非常有前途。我認為將事物混合在一起非常有前途。

Dwarkesh Patel
一切都很有前途。

所以 OpenAI 預計 2024 年的收入將達到十億美元。這很可能是正確的，但我只是好奇，當你在談論一種新的通用技術時，你如何估計它將會帶來多大的意外之財？

比如，為什麼是那個特定的數字？

Ilya Sutskever
我的意思是，你看看當前的，你看看。我們已經有一個。所以我們已經有一個產品相當長一段時間了，從 GPT-3 時代開始，從兩年前透過 API。我們已經看到它是如何增長的。我們也看到對 Dali 的反應是如何增長的。所以你看到對 chat GPT 的反應是怎樣的。我認為所有這些都給了我們信息，使我們能夠對 2024 年做出相對合理的推斷。

也許那會是一個答案。像，你需要有數據。你不能憑空捏造那些東西，否則你的誤差範圍會像，偏離。

你的誤差範圍將會像每個方向 100 倍。

## 後 AGI 時代：人類意義與 AI 整合

Dwarkesh Patel
我的意思是，但大多數指數增長不會保持指數增長，尤其是當它們進入越來越大的數量級時。對吧？在這種情況下，你如何確定？

Ilya Sutskever
我的意思是，像，你會賭 AI 輸嗎？

Dwarkesh Patel
跟你談過之後就不會了。

讓我們談談，像，後 AGI 時代的未來會是什麼樣子。像你這樣的人？你知道，我猜你每週工作 80 小時，朝著這個你真正痴迷的宏偉目標努力。在一個你基本上生活在 AI 養老院的世界裡，你會感到滿足嗎？或者，像，那個詞是什麼？你具體在做什麼，在 GI 到來之後？

Ilya Sutskever
我認為關於我將會做什麼或者人們在 GI 到來之後會做什麼的問題是一個非常棘手的問題。

我認為，人們將在哪裡找到意義？但我認為那是 AI 可以幫助我們的事情。

我想像的一件事是，我們都能變得更加開明，因為我們將與一個 AGI 互動，它將幫助我們更正確地看待世界，透過互動在內心變得更好。就像，想像一下與歷史上最好的冥想老師交談。

我認為那將是一件有幫助的事情。但我也認為，因為世界將會發生很大的變化，人們將很難理解到底發生了什麼以及如何真正做出貢獻。我認為有些人會選擇做的一件事是成為部分 AI，以便真正擴展他們的思想和理解，並真正能夠解決社會將面臨的最困難的問題。

Dwarkesh Patel
那你會成為部分 AI 嗎？

Ilya Sutskever
非常誘人。確實很誘人，是的。

Dwarkesh Patel
嗯，你認為 3000 年還會有肉身的人類嗎？

Ilya Sutskever
3000 年？哦，我怎麼知道 3000 年會發生什麼？

Dwarkesh Patel
像，它看起來像什麼？地球上還有人類在走動嗎？或者你們有沒有具體地想過你們實際上希望這個世界是什麼樣子？

Ilya Sutskever
3000 年？嗯，我的意思是，事情是這樣的。事情是這樣的。讓我向你描述一下我認為這個問題不太對勁的地方。像，它暗示著。像，哦，像，我們可以決定我們希望世界是什麼樣子。

我不認為那種圖景是正確的。我認為變化是唯一不變的。所以，當然，即使在 AGI 被建造出來之後，也不意味著世界將會是靜止的。世界將會繼續變化，世界將會繼續演變，它將會經歷各種各樣的轉變。

我真的沒有，我不認為任何人知道 3000 年世界會是什麼樣子。但我確實希望會有許多人類的後代過著幸福、充實的生活，他們可以自由地做他們想做的事，做他們認為合適的事，他們是自己解決自己問題的人。像，我不想看到的一個世界，我會覺得非常無趣的一個世界是，我們建造了這個強大的工具。然後政府說，好吧，所以 AGI 說社會應該以這樣的方式運行，現在我們將以這樣的方式運行社會。我更願意生活在一個人們仍然可以自由地犯自己的錯誤並承擔後果，並透過自己的力量逐步在道德上進化和前進的世界。明白我的意思嗎？AGI 提供更像是一個基礎的安全網。

你花多少時間思考這類事情，相對於僅僅做研究？

Ilya Sutskever
我確實花相當多的時間思考那些事情。是的，我認為那些是非常有趣的問題。

Dwarkesh Patel
那麼，我們今天擁有的能力在哪些方面超越了你在 2015 年的預期？又在哪些方面仍然沒有達到你預期到這個時候的水平？

Ilya Sutskever
我的意思是，公平地說，它們確實超越了我在 2015 年的預期。在 2015 年，我的想法更像是。我只是不想賭輸深度學習。我想對深度學習下最大的賭注。不知道怎麼做，但它會想出辦法的。

Dwarkesh Patel
但是否有任何具體的方式超出了你的預期或低於你的預期，比如你在 2015 年做出的某個具體預測被證明是…？

Ilya Sutskever
你知道，不幸的是，我不記得我在 2015 年做出的具體預測。但我絕對。但我絕對認為總的來說，在 2015 年，我只是想採取行動，對深度學習進行最大的賭注。但我並不確切知道。我對於七年後事情會發展到什麼程度沒有具體的想法。嗯，我的意思是，2015 年，我在 2016 年、也許是 2017 年確實和人們打了所有這些賭，認為事情會發展得很遠，但具體細節…

所以就像，兩者都有。既令我驚訝，我也在做這些激進的預測，但我認為也許我內心只相信了 50%。

Dwarkesh Patel
嗯，你現在相信什麼，即使是 OpenAI 的大多數人也會覺得難以置信？

Ilya Sutskever
我的意思是，我認為因為我們在 OpenAI 進行了大量溝通，人們對我的想法有相當好的了解。所以，是的，我們達到了 OpenAI 的觀點。我認為我們在所有這些問題上都看法一致。

Dwarkesh Patel
所以 Google 有其定制的 TPU 硬件。它擁有來自所有用戶、Gmail 等的所有數據。這是否在訓練更大、更好的模型方面給了它比你更大的優勢？

Ilya Sutskever
所以我想，像，當 TPU 剛出來的時候，我印象非常深刻，我想，哇，這太神奇了。但那是因為我當時對硬件不太了解。

真正的情況是，TPU 和 GPU 幾乎是同一樣東西。

它們非常非常相似。就像，我認為 GPU 芯片稍微大一點。我認為 TPU 芯片稍微小一點。它可能稍微便宜一點，但他們生產的 GPU 比 TPU 多。所以我認為 GPU 可能最終更便宜。

但從根本上說，你有一個大的處理器，你有很多內存，而這兩者之間存在瓶頸。

TPU 和 GPU 都在試圖解決的問題是，在你將一個浮點數從內存移動到處理器所需的時間內，你可以在處理器上執行數百次浮點運算，這意味著你必須進行某種批處理。從這個意義上說，這兩種架構是相同的。所以我真的覺得硬件在某種意義上。關於硬件唯一重要的是成本。每浮點運算成本，整體系統成本。

Dwarkesh Patel
好的，沒有太大區別。

Ilya Sutskever
嗯，實際上我不知道。我的意思是，我不知道 TPU 的成本是多少，但我會懷疑可能不是，如果有的話，可能 TPU 更貴，因為數量更少。

當你在做你的工作時，有多少時間花在配置正確的初始化、確保訓練運行順利以及獲得正確的超參數上？又有多少時間花在提出全新的想法上？

Ilya Sutskever
我會說這是一個組合，但我認為提出全新的想法是一個組合，但提出全新的想法實際上並不是…

這就像是工作的一小部分。當然，提出新想法很重要，但我認為更重要的是理解結果，理解現有的想法，理解正在發生的事情。因為通常你有這個，你知道，神經網路是一個非常複雜的系統，對吧？你運行它，你會得到一些難以理解正在發生什麼的行為，理解結果，弄清楚下一個該運行什麼實驗。很多時間都花在這上面，理解可能出了什麼問題，可能導致神經網路產生了意想不到的結果。

我會說很多時間也花在這上面。當然，提出新想法，但不是新想法。我想，像，我不太喜歡這種框架。並不是說它是錯誤的，但我認為主要的活動實際上是理解。

Dwarkesh Patel
你認為兩者之間的區別是什麼？

Ilya Sutskever
所以至少在我看來，當你說提出新想法時，我就像，哦，像，如果你做了這樣那樣會怎麼樣？

而理解，更像是，這整個事情是什麼？正在發生的真正潛在現象是什麼？潛在的影響是什麼？像，為什麼我們這樣做而不是那樣做？當然，這與可以被描述為提出想法非常接近。但我認為理解部分才是真正發生作用的地方。

Dwarkesh Patel
這是否描述了你的整個職業生涯？比如回想 Imagenet 或類似的事情，那更多是一個新想法還是更多是理解？

Ilya Sutskever
哦，那絕對是理解。絕對是理解。那是對非常古老事物的新理解。

Dwarkesh Patel
在 Azure 上進行訓練的體驗如何？使用 Azure 的體驗如何？

Ilya Sutskever
太棒了。我的意思是，是的，我的意思是，Microsoft 一直是我們非常非常好的合作夥伴，他們真的幫助我們把 Azure 帶到了一個真正適合機器學習的水平，我們對此非常滿意。

## 地緣政治風險與硬體依賴

Dwarkesh Patel
整個 AI 生態系統對於可能在台灣發生的事情有多脆弱？比如說台灣發生了海嘯之類的。

總的來說，AI 會發生什麼？

Ilya Sutskever
像，這肯定，這肯定會是一個重大的挫折。它不會像，它可能相當於，像，幾年內沒有人能得到更多，更多的電腦，但我預計電腦會出現。像，例如，我相信英特爾有幾代以前的晶圓廠。所以這意味著如果英特爾願意，他們可以生產出像四年前那樣的 GPU 類產品。所以，是的，這不是最好的，比方說。我實際上不確定我關於英特爾的說法是否正確，但我確實知道台灣以外有晶圓廠，雖然沒那麼好。但你仍然可以使用它們，並且仍然可以走得很遠。只是，只是成本。這只是一個挫折。

Dwarkesh Patel
隨著這些模型變得越來越大，推理會不會變得成本過高？

Ilya Sutskever
所以我對這個問題有不同的看法。並不是說推理會變得成本過高。

更好模型的推理確實會變得更昂貴。

但這是否令人望而卻步？

嗯，這取決於它有多大用處。就像，如果它的用處大於它的成本，那麼它就不是令人望而卻步的。就像給你一個類比，像，假設你想和律師談談，你有個案子或者需要一些建議之類的，你完全樂意花費每小時 500 美元，對吧？所以如果你的神經網路能給你，像，真正可靠的法律建議，你會說，我樂意為那個建議花費 400 美元。突然之間，推理變得非常不令人望而卻步。

問題是，神經網路能否以這個成本產生足夠好的答案？

Dwarkesh Patel
是的。而且你只會有，像，價格歧視。不同的，不同水平的不同模型。

Ilya Sutskever
我的意思是，今天已經是這樣了。所以在我們的產品上，API 為不同大小的多個神經網路提供服務，不同的客戶根據他們的用例使用不同大小的不同神經網路。

像，如果有人可以拿一個小模型進行微調，並得到令他們滿意的東西，他們就會使用那個。是的，但如果有人想做更複雜、更有趣的事情，他們就會使用最大的模型。

Dwarkesh Patel
你如何防止這些模型僅僅變成商品，讓這些不同的公司相互壓低價格，直到基本上只剩下 GPU 運行的成本？

Ilya Sutskever
是的，我認為毫無疑問，有一股力量正試圖創造這種局面。答案是，你必須不斷取得進展，你必須不斷改進模型，你必須不斷提出新想法，讓我們的模型更好、更可靠、更值得信賴，這樣你才能信任它們的答案。

所有這些事情。

Dwarkesh Patel
是的，但假設現在是 2025 年，而 2024 年的模型有人只是以成本價提供？而且它仍然相當不錯。如果僅僅一年前的模型，你知道，甚至更好，人們為什麼會使用 2025 年的新模型？

Ilya Sutskever
所以這裡有幾個答案。對於某些用例來說，這可能是真的。將會有一個來自 2025 年的新模型，它將驅動更有趣的用例。還會有一個推理成本的問題。像，你可以，你可以進行研究以更低的成本提供相同的模型。所以會有不同的，相同的模型將會提供，對於不同的公司來說，服務成本會不同。我也可以想像一定程度的專業化，一些公司可能會嘗試在某個領域進行專業化，在一個更狹窄的領域比其他公司更強大。我認為那也可能，那可能是對商品化的一種回應。

Dwarkesh Patel
在一定程度上，隨著時間的推移，這些不同的公司，它們的研究方向是趨同還是發散？隨著時間的推移，它們做的事情是越來越相似，還是它們正在走向，分支到不同的領域？

Ilya Sutskever
所以我會說在短期內，看起來存在趨同。

我預計將會出現發散-趨同的行為，近期工作上會有大量的趨同。長期工作上將會有一些發散。但一旦長期工作開始產生結果，我認為會再次出現趨同。

Dwarkesh Patel
明白了。

當其中一個找到最有希望的領域時，每個人都只是，沒錯。

Ilya Sutskever
現在顯然發表得少了，所以需要更長的時間才能重新發現這個有希望的方向。但這就是我想像的樣子。我認為將會是趨同。發散。趨同。

Dwarkesh Patel
是的，我們一開始稍微談到了這個，但隨著外國政府了解到這些模型的能幹程度，你是否擔心間諜或某種攻擊來獲取你的權重，或者以某種方式濫用這些模型並了解它們？

Ilya Sutskever
是的，這絕對是，你絕對不能忽視的事情。

Dwarkesh Patel
是的。

Ilya Sutskever
是的，這是我們盡最大努力防範的事情，但這將是每個建造這個東西的人都會遇到的問題。

## 模型能力的湧現與可預測性

Dwarkesh Patel
你如何防止你的空隙洩漏或者什麼？

Ilya Sutskever
我的意思是，你有像真正優秀的…

Dwarkesh Patel
安全人員，像，有多少人擁有，如果他們想只是像 ssh 進入權重，一個機器，有多少人可以做到？

Ilya Sutskever
我的意思是，像，我能說的是我們擁有的安全人員，內建的，他們做得非常好。所以我真的不擔心它被洩露的方式。好的，明白了。

Dwarkesh Patel
你期望這些模型在這種規模下會出現什麼樣的突現屬性（emergent properties）？

是否有什麼東西是從無到有產生的？

Ilya Sutskever
我確定會有事情發生。我確定真正新的、令人驚訝的屬性會出現。我不會感到驚訝。我真正興奮的事情，或者我希望看到的事情是可靠性和可控性。我認為這將是非常非常重要的一類突現屬性。如果你有可靠性和可控性，我認為這有助於你解決很多問題。可靠性意味著你可以信任模型的輸出。可控性意味著你可以控制它，我們會看到的，但如果那些突現屬性確實存在，那將非常酷。

Dwarkesh Patel
有沒有辦法可以提前預測？

像在這個參數數量下會發生什麼？在那個參數數量下會發生什麼？

Ilya Sutskever
我認為對特定的、特定的能力做出一些預測是可能的，儘管這絕對不簡單，而且你無法以超級精細的方式做到，至少在今天不行。但我認為在這方面做得更好非常重要，任何對此感興趣、有關於如何做到這一點的研究想法的人，我認為都可以做出有價值的貢獻。

Dwarkesh Patel
你對這些擴展定律（scaling laws）有多認真？

有一篇論文說，像，哦，你只需要增加這麼多個數量級就能得到所有的推理能力。像，你認真對待這個嗎？還是你認為它在某個時刻會失效？

Ilya Sutskever
嗯，問題是擴展定律告訴你當你… 當你對你的日誌… 對你的下一個詞預測準確率做什麼時會發生什麼，對吧？

將下一個詞預測準確率與推理能力聯繫起來是一個完全獨立的挑戰。

我確實相信存在聯繫，但這種聯繫很複雜，我們可能會發現還有其他事情可以讓我們以更少的努力獲得更多的推理能力。

像，例如，一些特殊的鏈接。你知道，你提到了推理標記，我認為它們可以有所幫助。

可能會有某些事情…

Dwarkesh Patel
這是你正在考慮的事情嗎？僅僅僱傭人類為你生成標記？還是所有的標記都將來自已經存在的東西？

Ilya Sutskever
我的意思是，我認為依靠人們來教導我們的模型做事，特別是，你知道，確保它們行為良好並且不產生虛假信息，我認為是一件極其明智的事情。

Dwarkesh Patel
我們在擁有 Transformer 的同時，恰好也擁有我們需要的數據，又恰好在我們擁有這些 GPU 的同時，這不是很奇怪嗎？

所有這些事情同時發生，你覺得奇怪嗎？還是你不這麼看？

Ilya Sutskever
我的意思是，這絕對是一個有趣的…

這是一個有趣的情況，確實如此。我會說這很奇怪，但在某種程度上又不那麼奇怪。這就是為什麼它不那麼奇怪。數據存在、GPU 存在、Transformer 存在的驅動力是什麼？所以數據存在是因為計算機變得更好、更便宜。我們有了越來越小的晶體管。突然在某個時刻，每個人擁有一台個人電腦變得經濟可行。一旦每個人都有了個人電腦，你真的想用網絡把它們連接起來。你就有了互聯網。一旦有了互聯網，你突然就有了大量出現的數據。GPU 同時也在改進，因為你有越來越小的晶體管，你在尋找用它們做的事情。遊戲被證明是你可以做的一件事。然後在某個時刻，遊戲 GPU，Nvidia 說，等等，也許把它變成一個通用 GPU 計算機。也許有人會發現它有用。結果證明它對神經網路很有用。所以情況可能是，也許 GPU 會晚五年或十年到來。如果。假設遊戲不是一回事，這有點難以想像。如果遊戲不是一回事意味著什麼？

但它可能。也許存在一個反事實的世界，GPU 在數據出現五年後或數據出現五年前到達，在這種情況下，也許事情會稍微移動一點。事情就不會像現在這樣準備就緒了。但這就是我想像的圖景，所有這些維度的所有這些進展都非常交織在一起。你無法選擇在哪些維度上事情會改進，這不是巧合，如果你明白我的意思。

Dwarkesh Patel
這種進步有多必然？所以如果，像，比如說，你和 Jeffrey Hinton 以及其他幾位先驅，如果他們從未出生，深度學習革命會在大致相同的時間發生嗎？會延遲多少？

Ilya Sutskever
我想也許會有一些延遲，也許像一年的延遲。這真的很难。

Dwarkesh Patel
真的嗎？就這樣。

Ilya Sutskever
很難說。我的意思是，我猶豫是否要給出更長的答案，因為，好吧，那麼你就會有。GPU 會不斷改進，對吧？然後在某個時刻，我看不到怎麼會有人沒有發現它，因為還有另一件事，好吧，所以假設沒有人做過。計算機不斷變得更快更好，訓練這些神經網路變得越來越容易，因為你有更大的 GPU，所以需要的工程努力更少。訓練一個。你不需要那麼多地優化你的代碼。

當 Imagenet 數據集問世時，它非常龐大，而且使用起來非常非常困難。現在想像你等了幾年，下載變得非常容易，人們可以隨便擺弄。所以我會想像最多像幾年的時間，這會是我的猜測。我猶豫。我猶豫是否要給出更長的答案，儘管如此。

你無法重演世界。你不知道。

Dwarkesh Patel
讓我們回到對齊（alignment）一會兒。作為一個深刻理解這些模型的人，你對對齊會有多難的直覺是什麼？

Ilya Sutskever
我想。所以。這是我會說的。我認為以目前的能力水平，我認為我們有一套相當好的關於如何對齊它們的想法。但我不會低估與實際上比我們更聰明的模型、能夠歪曲其意圖的模型的對齊難度。

就像，我認為。我認為這是需要大量思考和研究的事情。我認為這也是一個領域，順便說一句，你知道，像，學術研究人員經常問我，他們在哪裡可以做出最好的貢獻？我認為對齊研究是一個我認為學術研究人員可以做出非常有意義貢獻的地方。

Dwarkesh Patel
除此之外，你認為學術界會提出更多關於實際能力的見解嗎？還是到了這個階段，只有公司才能做到？

Ilya Sutskever
公司會實現這些能力。我認為學術研究很有可能提出那些見解。我認為只是，出於某種原因，似乎並沒有發生那麼多。但我認為學術界沒有什麼根本性的問題。像，並不是說學術界不能。我認為也許他們只是沒有思考正確的問題或者別的什麼，因為也許在這些公司內部更容易看到需要做什麼。

Dwarkesh Patel
我明白了。但有可能有人會突然意識到。

Ilya Sutskever
是的，我完全這麼認為。像，為什麼？為什麼我會排除這種可能性？你明白我的意思嗎？

Dwarkesh Patel
這些語言模型開始實際影響原子世界而不僅僅是比特世界的具體步驟是什麼？

Ilya Sutskever
嗯，你看，我不認為比特世界和原子世界之間存在一個區別，一個清晰的區別。假設神經網路告訴你，嘿，這是你應該做的事情，它會改善你的生活，但你需要以某種方式重新佈置你的公寓。然後你去，結果你重新佈置了你的公寓。

神經網路影響了原子世界嗎？只是…

Dwarkesh Patel
是的，說得有理。說得有理。你認為達到超人 AI 還需要幾個像 Transformer 一樣重要的額外突破嗎？還是你認為我們基本上已經在書本的某個地方掌握了見解，我們只需要實現它們並將它們連接起來？

Ilya Sutskever
所以，我真的不認為這兩種情況之間有那麼大的區別。讓我解釋一下原因。

像，我認為什麼是。過去取得進展的方式之一是，我們理解了某件事一直具有一種屬性，一種理想的屬性，而你沒有意識到。

所以那是一個突破嗎？你可以說，是的，它是。那也是書本上某件事的實現嗎？也是，是的。所以我的感覺是，其中一些很可能會發生，但在事後看來，它不會感覺像是一個突破。每個人都會說，哦，嗯，當然。像，這樣那樣的事情能成功是完全顯而易見的。你看，對於 Transformer，它被提出作為一個具體進展的原因是，它是那種對幾乎任何人來說都不明顯的事情。所以人們可以說，是的，像，這不是他們知道的事情。但如果一個進展來自於像，讓我們考慮一下深度學習最根本的進展，即用反向傳播訓練的大型神經網路可以做很多事情。像，新穎性在哪裡？它不在於神經網路。它不在於反向傳播。

但不知何故，它是那種。但它曾經是。它絕對是一個巨大的概念性突破，因為在很長一段時間裡，人們就是沒有看到這一點。

但是，現在每個人都看到了，每個人都會說，嗯，當然。像，這完全顯而易見。大型神經網路。像，每個人都知道它們可以做到。

Dwarkesh Patel
你對你以前的導師新的前向-前向算法（forward-forward algorithm）有何看法？

Ilya Sutskever
我認為這是試圖在沒有反向傳播的情況下訓練大腦和神經網路。

我認為如果你有動力去嘗試理解大腦可能是如何學習其連接的，這尤其有趣。原因在於，據我所知，神經科學家非常確信大腦無法實現反向傳播，因為突觸中的信號只沿一個方向移動。

因此，如果你有神經科學的動機，並且你想說，好吧，我如何想出一些試圖近似，近似反向傳播的良好特性而不進行反向傳播的東西。這就是前向-前向算法試圖做的。但如果你只是想設計一個好的系統，沒有理由不使用反向傳播，就像它是唯一的算法，真的。

Dwarkesh Patel
我想我在不同的場合聽你談到過，把人類作為 AGI 存在的現有例證。

在什麼時候你會不再那麼認真地看待這個比喻，並且不再覺得有必要在研究中追求它，因為它作為一個存在例證對你很重要？

## AI 發展的必然性與靈感來源

Ilya Sutskever
到什麼時候我不再關心人類作為…的存在例證？

Dwarkesh Patel
智能，或者作為那種，作為你在模型中追求智能方面想要遵循的榜樣？

Ilya Sutskever
我明白了。

我的意思是，像，你得。我認為從人類那裡獲得靈感是好的。我認為從大腦那裡獲得靈感是好的。我認為正確地從人類和大腦那裡獲得靈感是一門藝術，因為很容易抓住人類或大腦的一個非本質特徵。我認為許多在學校裡的人，許多研究試圖從人類和大腦獲得靈感的人，往往會變得有點具體。人們會變得有點太。好吧，所以，像，我們應該遵循什麼認知科學模型？與此同時，考慮一下神經網路本身的想法，人工神經元的想法。這也是受到大腦啟發的，但結果證明它極其富有成果。

那麼你該怎麼做呢？人類的哪些行為是必不可少的，以至於你說，像，這證明了這是可能的。哪些是不必要的？不，實際上，這是像某種更基本事物的突現現象。我們只需要專注於我們自己的，我們自己的，把我們自己的基礎打好。我會說。我會說，這就像，我認為一個人應該。一個人可以而且應該謹慎地從人類智能中獲得靈感。

Dwarkesh Patel
最後一個問題。為什麼在你這裡，成為深度學習革命的先行者與仍然是頂尖研究人員之一之間存在如此強烈的相關性？你會認為這兩件事不會那麼相關，但為什麼存在這種相關性？

Ilya Sutskever
我不認為那些事情超級相關。確實。我覺得就我而言，我的意思是，老實說，很難回答這個問題。你知道，我只是不斷地，我一直非常努力地嘗試，結果證明到目前為止這就足夠了。

Dwarkesh Patel
明白了。所以是堅持不懈。

Ilya Sutskever
我認為這是必要但不充分的條件。像，你知道，很多事情需要結合在一起才能真正弄清楚一些事情。

像，你需要真正地去追求它，也需要有正確的看待事物的方式。所以很難。很難給他們，像一個真正有意義的答案來回答這個問題。

Dwarkesh Patel
好的，Ilya，這真是一次愉快的經歷。非常感謝你來到月球協會。我很感激你帶我們來到辦公室。所以謝謝你。

Ilya Sutskever
是的，我真的很享受。非常感謝。

Dwarkesh Patel
嘿，大家好，希望你們喜歡那一集。

