---
layout: post
title: "大數據時代的因果推論|Jas Sekhon"
date: 2025-03-30
categories: [
   'Jasjeet Sekhon',
  'Alberto Abadie',
  'Devavrat Shah',
  Bradly Stadie',
  '機器學習',
  '醫療保健',
  '選舉研究',
  '因果推論',
  '2025'
]
description: "這篇文章主要記錄了 Jasjeet Sekhon 教授關於機器學習在因果推論中的應用演講，特別討論了轉移學習、隨機森林等技術在處理效應估計中的應用，以及在醫療保健、選舉研究等領域的實際案例分析。演講中深入探討了 X-learner、S-learner 和 T-learner 等方法的理論基礎和實際應用，並強調了在大數據時代如何有效利用不平衡數據集。
"
toc: true  # 啟用目錄功能

---

<span class="original-link">原文連結： [大數據時代的因果推論|Jas Sekhon](https://youtu.be/kiW9lsg9Yhk?si=vF5Zm9-KzENd3dNw)</span>


[Alberto Abadie]：
今天我非常興奮能夠邀請 Jasjeet Sekhon 來參加這場傑出研討會。我對 Jasjeet 的尊敬與欽佩可以追溯到我們還是哈佛大學的年輕教員時期，當時我們都在研究因果推論。那時候，因果推論還不算是一門顯學，你告訴別人你在研究因果推論，他們會問你：「因果推論？你到底在說什麼？」因此，我們自然而然地相互吸引，一起在這個領域內探索與研究（聽不清楚的部分）。

今天能夠邀請他來這裡真是太棒了（聽不清楚的部分）。他很快就要從西岸搬到東岸，但目前 Jasjeet 是加州大學柏克萊分校統計學與政治科學的教授。今天，他將為我們帶來「大數據時代的因果推論」這場演講。請大家一起歡迎 Sekhon 教授！

（掌聲）

[Jasjeet Sekhon]：
謝謝你的邀請，Alberto。很高興能來到這裡，今天過得很愉快。希望我還有足夠的聲音來完成這場演講。

正如 Alberto 所說，今天我要談論的是大數據的因果推論，這場演講涵蓋了我與不同合作者共同撰寫的多篇論文，我會在過程中盡量感謝他們。首先，我想提供一些背景資訊，因為今天的聽眾來自不同領域，所以我會先做一些鋪陳，儘管在這個研究機構裡，我想大多數人對這些內容應該都已經有所了解。

## 大數據時代的挑戰與機遇

如果你對因果推論，特別是針對人類行為的因果推論感興趣，那麼現在可以說是黃金時代，因為我們獲取的數據量前所未有。然而，這些數據也帶來一些挑戰，因為很多數據是私有的，無法公開使用，這對學術界來說是一個需要克服的難題，但總體來說，這個時代的數據仍然是前所未有的。

我們擁有大量的行政記錄，涵蓋教育、刑事司法、稅務等。例如，我的一位經濟學研究生 Yotam Shem-Tov，目前是 NBER（美國國家經濟研究局）的博士後研究員，即將加入加州大學洛杉磯分校的經濟學系。他擁有完整的學校記錄，並將其與犯罪記錄進行合併，甚至獲得美國國稅局（IRS）的批准，能夠將這些數據與北卡羅來納州長達 20 年的稅務記錄進行匹配。

我常開玩笑說：「你現在可以直接估算班級規模對犯罪的影響了。」但這真的就是他要做的研究，例如分析班級規模的網絡效應，而這甚至不是他博士論文的核心議題。

這些數據的獨特之處並不只是規模龐大，因為我們長期以來一直擁有大型數據集。真正的新特點是這些數據擁有極為細緻的個體資訊，也就是說，它們的樣本數（n）很大，但同時變數數量（k）也非常多，這就帶來了許多推論上的挑戰。當然，這也讓我們能夠做以前無法做到的事情，而這些數據的「寬度」正是關鍵。

大多數相關的例子來自大型網路公司，它們擁有大量的瀏覽、搜尋、購買行為數據，這些數據規模空前，而且我們還只是處於這個發展的初期，因為物聯網（IoT）即將帶來更多的即時數據。此外，在醫學領域，隨著電子病歷（EMR）與基因標記的發展，研究人員也能獲取龐大的變數數據。

舉例來說，我曾經參與一項研究，其中包含英國所有加護病房（ICU）入院患者長達五年的完整記錄，這使我們能夠進行更深入的分析。此外，我們還可以結合隨機實驗數據，以提高推論的外部效度，這樣的數據可說是前所未見的。

這些數據集不僅「寬」，而且「長」，這導致了許多前所未見的推論問題，而今天的演講將會探討其中的一些問題。對於政策制定者而言，無論是在醫療保健、政府政策或企業經營方面，個人化決策都變得極為重要。如果我們的數據集非常龐大且包含細緻的個人資訊，那麼我不僅僅希望在平均層面上控制政策風險，更希望能夠針對特定群體進行控制，這就引發了許多新的方法與挑戰。

僅僅關注「平均風險」並不足夠，因為這可能會決定一家企業是存活還是倒閉，或者影響一項政策是否能夠獲得公眾支持。因此，這些問題對於企業與政策制定者而言都是至關重要的。

你希望擁有一個能夠準確建模的行為模式，而這正是企業用來創造市場的基礎。例如，對於 Uber 這類共乘公司（聽不清楚的部分），你可能認為它們的經濟模式只是取代了傳統計程車產業，然而事實上，Uber 的影響遠超於此。  

以舊金山灣區為例，Uber 單在這個地區的營收就比過去整個計程車產業的規模高出好幾個數量級。這表示它不只是取代了計程車，而是創造了一個全新的市場，甚至改變了汽車製造商的資產配置。而這背後高度依賴數據，因此相關的推論問題極為複雜且多樣。  

這些數據的異質性極高，體現在多個層面。例如，數據異質性的一部分來自於不同的子群體，此外，當數據量增長時，它的極限性質（limiting properties）也會與我們的直覺不同。  

傳統統計學的一種觀點是，隨著數據量增加，透過集中不等式（concentration inequalities），問題應該變得更簡單。然而，在當前的大數據環境下，情況並非如此。舉例來說，假設你已經收集了 20 億名使用者的數據，那麼接下來新增的 1 億名使用者可能與先前的 20 億名使用者截然不同，因此，他們並不具備可交換性（exchangeability）。換句話說，數據的異質性可能會隨著數據量的增加而上升，而非下降。  

你可能會試圖透過某些假設來克服這個問題，但本質上，這些數據的異質性是我們以往較少考慮的。這對政策制定者來說影響深遠，無論是在醫療保健、政府政策還是企業策略上，決策者希望能夠「最佳分配治療方案」，而不只是關心整體平均效果。  

我們每個人最終都會成為醫療體系的患者。如果醫生告訴你：「這種藥物的平均療效良好」，這或許有點用處，但你更想知道的是：「這種藥物對我個人是否有效？」即使這樣的資訊來自觀察性研究（observational study），而非隨機對照試驗（RCT），你仍然會對其產生興趣，因為它更具個人化的價值。  

然而，這類數據的易得性與分析能力的提升，也讓「p-hacking」的問題變得更加嚴重。在大型網路公司內部，你可以輕易地根據 p 值來篩選子群體，並且隨時監控實驗結果，這可能導致不當的結果操縱。在過去，這類問題通常由醫院倫理委員會等機構來監管，例如在雙盲試驗中，只有獨立監管機構才能決定何時終止試驗，而不是讓設計實驗的人自行決定。但現在，這種界線變得越來越模糊。  

因此，我的研究重點之一是發展「始終有效的 p 值」（always valid p-values），即便研究者能夠隨時啟動或終止實驗，也能確保統計推論的正確性。此外，解釋性（interpretability）在這樣的環境下變得至關重要。  

隨著這些統計推論變得越來越複雜，人們使用的演算法也越來越先進，但如果這些方法缺乏可解釋性，那麼它們在許多情境下就無法被應用。例如，在線廣告推薦系統中，即使推薦算法的決策機制無法完全解釋，人們通常也不會太在意，畢竟廣告的影響極為微小，錯誤推薦的損害幾乎可以忽略不計。但如果這類算法被用於醫療領域，情況就完全不同了。如果系統錯誤地分配了治療方案，導致你獲得本該給別人的藥物，那麼這將帶來嚴重後果，人們絕對不會對此無動於衷。  

這也是為什麼演算法的可解釋性成為歐盟（EU）監管重點的原因之一。歐盟的「解釋權規則」（Right to Explanation）要求演算法必須提供明確的決策邏輯，甚至比人類決策者還要嚴格。人類的決策過程常常是模糊且難以解釋的，但歐盟的規則要求演算法具備比人類更高的透明度。然而，這在技術上並不容易達成，因為現代 AI 演算法的複雜程度極高，例如 Facebook 的新聞推送算法，即便是內部工程師也無法完全理解它的運作機制。  

綜上所述，這些問題構成了當前大數據時代因果推論所面臨的挑戰。在這場演講中，我主要探討的是如何使用機器學習來做因果推論，而因果推論本身就帶來了一系列獨特的問題。我們的目標是預測那些無法直接觀察到的結果。  

舉例來說，假設我們有 100 萬張圖片，其中的動物是貓還是狗已經被標註清楚，因此我們可以透過這些標籤來訓練機器學習模型。然而，在因果推論的情境中，即使我們擁有 1 億名受試者，我們仍無法直接觀察對每個個體的「真實因果效應」（ground truth causal effect）。我們只能透過統計方法來估算平均效應，因為部分人接受了治療，部分人作為對照組。但我們無法確切知道某個特定個體的治療效果，也無法在沒有強假設的情況下推估中位數的治療效果。  

這就帶來了一個核心問題：如果我們想要調整機器學習演算法，使其能夠準確預測因果效應，那麼我們該如何進行？傳統的機器學習通常依賴「真實標籤」（ground truth），但在因果推論中，我們只能得到「估計值」，而這些估計值本身就包含不確定性（noise），即使在超大規模數據下，這種不確定性仍然存在，並且會對推論過程產生極大影響。

當我剛進入這個領域時，我常開玩笑說：「龐大的數據帶來微小的效果量」（With huge data comes small effect sizes）。意思是，如果你的數據足夠大，而你的政策又會影響到大量的人，那麼即便是極小的效果，也會具有重大的經濟與政策意義。因此，你必須開始關心這些細微的影響。  

從最基本的概念來說，干預（intervention）涉及反事實（counterfactuals）：也就是「如果進行了某種處理，與沒有進行處理相比，結果會如何？」然而，這些反事實是無法直接觀察的，因此我們試圖估算的是一個「反應排程」（response schedule），而不僅僅是對模型的直接預測。這使得驗證過程變得極為複雜，我稍後會深入探討這點。  

如果我們沒有隨機對照試驗（RCT），那麼隨機分配的結果可能會受到混雜因素（confounding）的影響。舉例來說，如果某種干預措施主要被女性接受，而較少被男性接受，那麼我們的結果就會存在偏差。此時，增加數據量並不能解決這個問題，因為更多的數據只會降低變異性（variance），但它無法消除偏誤（bias），反而會讓你得到一個極為精確但仍然有偏的估計值。  

## 預測結果 vs. 預測因果效應：核心區別

這是許多領域都會犯的錯誤，無論是政治競選還是科技企業的廣告投放。舉個例子，假設某個競選團隊希望透過政策來提高選民的投票率，他們可能會問：「我們應該將這個政策推廣給哪些人？」或者，一家科技公司希望投放廣告來促進書籍銷售，他們可能會問：「我們應該把廣告投放給誰？」  

在這些場景中，人們經常直覺地選擇那些「已經高度認同這項政策的人」或「已經很可能會購買這本書的人」，但這其實是一種錯誤的策略。舉個真實的例子，有人想要投放支持墮胎權的廣告，他們有一些實驗數據顯示這個廣告有效，然後他們決定：「我們應該把廣告投放給那些已經強烈支持墮胎權的人。」這聽起來很奇怪，因為這些人早就已經認同了這個觀點，因此廣告對他們的影響極小。正確的策略應該是針對那些對墮胎權持中立或搖擺態度的人，這樣才更有可能改變結果。  

這種錯誤的根源在於，我們無法直接觀察過去的「處理效果」（treatment effect）。舉例來說，假設我們想要預測一個人未來是否會買書，在觀察性數據中，我們知道他去年買過書，那麼他未來買書的機率也會較高。這就是為什麼當你在 Amazon 上買了一台冰箱後，系統仍然不斷推送冰箱廣告給你。即使對於一個像冰箱這樣的耐用品，算法應該知道你不會頻繁購買，但由於它是基於「過去行為來預測未來行為」，這種現象仍然普遍存在。  

然而，在異質性處理效果（heterogeneous treatment effects, HTE）的預測中，這樣的方式並不起作用。因為我們並沒有「過去的處理效果」可以作為標籤數據。這導致了一個根本性的挑戰：如果你請我預測你的未來行為，我可以使用你的過去行為作為依據，但如果你請我預測你的未來處理效果，我沒有過去的處理效果可參考，因為每個人只能經歷一次干預。  

## 理論 vs. 算法的實務應用：統計建模的兩種文化

在當今的大數據時代，我們正在使用越來越複雜的算法來處理這些問題，但許多這些算法的理論基礎並不牢固。我將討論一些這類算法，而這些算法的理論之所以成立，往往是基於一些理論假設，這些假設的本質其實是「忽略算法本身」。這聽起來很諷刺，但這就是現實。  

通常，我們在機器學習中有兩種不同的論證方式，而這兩種方式經常被混淆，無論是在學術界、科技公司，還是其他應用場景中都可以看到這種混淆。這種區別可以追溯到 Leo Breiman 的著名論文《統計建模的兩種文化》（The Two Cultures），這是一篇值得一讀的論文。  

第一種論證方式是，統計理論之所以有效，是因為相關的理論能夠解釋它的行為。這種方式能夠產生一些「極小極大」（minimax）結果，我稍後會討論這些結果，但我要強調的是，這些結果通常不能真正描述在有限數據（即使是數千萬筆數據）下的實際情況。這種論證方式的特點是，它通常基於「假設數據是由某種模型生成的」，然而，在真實世界中，這種假設並不一定成立。  

第二種論證方式則是基於實驗與驗證數據（test-training loop）。這種方法的核心思想是：「我不知道這個算法的理論基礎，但我有大量的測試與驗證數據，它在這些數據上表現良好，所以它應該有效。」這並不是一種壞的論證方式，事實上，深度學習（deep learning）之所以能夠取得成功，並不是因為我們對其理論理解得非常透徹，而是因為我們知道隨機梯度下降（SGD）本質上是一種正則化方法（regularizer）。  

這兩種方式各有優缺點。在某些情境下，傳統的統計理論能夠提供穩健的結果，但在現代大規模數據場景中，我們經常不得不依賴第二種方式，透過大量實驗來驗證模型的有效性，即使我們無法完全解釋它的機制。

到底它是如何作為一種正則化方法的？沒有人確切知道。我們知道 dropout 和核範數（nuclear norm）有某種關聯，但它究竟是如何勝出的？我不知道，對吧？人們也不知道。它之所以成功，是因為它在測試環境下運作良好，而理論理解則是事後才慢慢跟上的。你不希望搞混為什麼要採用其中一種方式，然而這種混淆卻非常普遍，並且已經持續了很長時間。  

有一句名言來自 de Finetti 的概率論書籍，他將這句話歸因於 Poincaré，談的是常態分佈。他說，實驗學家相信常態分佈是因為他們認為這是一條數學定理——中央極限定理（central limit theorem）。而數學家則相信常態分佈，因為他們認為這是一個經驗事實（empirical fact）。這是一個有趣的現象，但這並不是一個你希望置身其中的世界。  

常態分佈是一個有趣的案例，我這裡不會深入探討，因為許多科技公司的問題涉及的是極重尾（fat tail）分佈。我們並不確定中央極限定理是否適用，或者即使適用，它的收斂速度如何，因為這些分佈的尾部極端厚重。例如，在大多數線上廣告實驗中，99% 的數據都是零——99% 的人不點擊廣告，而點擊廣告的 99% 的人最終也不會購買產品。而那些最終購買的人，他們帶來的收入則呈現極重尾分佈。  

現在，假設你想要判斷這則廣告是否能帶來收入，這其實是一個非常有趣且複雜的問題。舉個例子，這張圖表基於某家大型網際網路供應商的 278 項不同實驗，每個實驗的樣本量約為 1 億人。你在這些實驗中，對許多不同的子群體進行估算，並且你正在估算各種不同的處理效應（treatment effects）。你總共估算了 25,000 種不同的處理效應，僅僅是基於一個「均值差異估計量」（difference-in-means estimator）。  

所以你可以想像，我有一個實驗，我想知道這對男性或女性的影響——對 iPhone 用戶與 Android 用戶的影響——這類問題不斷延伸。最終，我們有 25,000 種處理效應，而每個效應的樣本量約為 110 萬人。你稍微計算一下就會發現：「嘿，這裡肯定有重複的樣本，因為我們談論的數據量已經達到數十億。」是的，這些樣本中確實有重複的個體，但我們忽略了這一點。  

你現在看到的圖表，所繪製的是所有這些實驗的標準化均值差異估計量（difference-in-means estimator standardized across all those experiments），這就是你的密度分佈。這份研究論文是我和 Yotam 合作的，這篇論文之所以能夠獲得這家網路公司的數據，是因為它是一篇極具理論性的論文。這篇論文的目標是提供一個一致的變異數估計量，用於估算樣本平均處理效應（sample average treatment effect for the treated, SATT），這個估計量是逐點可識別的（point-wise identified），與「平均處理效應」（average treatment effect, ATE）的變異數估計量不同，後者在 Neyman 模型下是不可識別的（unidentified）。如果你知道這些概念，那很好；如果不知道，也沒關係。  

但關鍵是，我們能夠獲得這些數據，僅僅是因為這篇論文過於無聊，以至於沒有任何記者會對它感興趣。因此，這家科技公司才允許我們公開這些數據。我無法透露具體的數據內容，但這裡的核心重點是，大部分的處理效應幾乎為零。它們是如此趨近於零，以至於這不是一個「我應該以零作為先驗假設，並使用常態分佈來建模」的問題，而是應該使用雙指數分佈（double exponential distribution），更具體地說，應該是拉普拉斯分佈（Laplacian distribution）。  

因此，如果我要進一步進行實驗，來估計不同子群體的處理效應，那麼我應該認真對待「零」這個結果。我應該選擇一種方法，使得它要麼會正式地收縮至零（shrink to zero），要麼具有識別零的特性（properties to find zero）。  

我們需要一個例子來說明，在獲得大量數據時，我們不必糾結於「這是好是壞？」這類討論。我只需進入他們的數據庫，提取這些數據並加以利用。然而，我無法討論這些特定的實驗，因此我會談論其他的實驗數據。  

我接下來要討論的數據，來自於「催票實驗」（get-out-the-vote experiments）。有趣的是，這類數據是公開的，因為在美國，一個人是否投票是公共記錄（public record）。雖然你投給誰是私人資訊（private），但你是否投票則是公開資訊。因此，我們可以查閱數據庫來進行搜索，這其實有點令人毛骨悚然。  

當我住在 Berkeley 時，我的鄰居會對我說：「Hey, Jas，你上次沒去投票。」而我只能回應：「哦，太棒了，現在我得和你討論這件事了。這一點也不奇怪，對吧？」這就是現實。  

有一個非常特殊的實驗曾經被公開，然而，隨著這些催票實驗變得越來越有效，許多數據最終變成了機密。這種情況在科學領域非常常見——當一個研究結果極為成功時，它就變得非常有價值，然後就被隱藏起來，不再公開。  

這項實驗是一個「社會壓力實驗」（social pressure experiment），由 Alan Gerber 和 Don Green 進行，當時他們都在 Yale。這個實驗的做法是，他們向人們寄送明信片。

你所做的只是寄送一張明信片——這使得選民的投票率提高了 8%。這對於一張明信片來說是非常大的影響，對吧？你可以想像，政治競選活動會對此感興趣，因為他們只會針對他們想要的選民進行目標投放。所以，你知道，寄一張明信片，看起來非常無聊。  

根據隨機化實驗，事實證明，你實際上不需要色彩和閃光。你需要的是一份看起來非常無聊、正式的文件，並且你會說，「如果你的鄰居知道你是否投票，你會怎麼做？」然後你會加上一些文字——「請投票，這是你和你鄰居的投票歷史，我們將在選舉結束後更新它。」  

所以你會列出人們的名字，對吧？你會列出他們過去是否投過票，並且給未來留空欄。就像說的，我們會更新並將這些資料發送給你和你的鄰居。所以，一小部分人會感到不安，但它對投票率的影響巨大，平均來說是 8%。  

這種設計的特點，也是現在這類大規模實驗中非常常見的，控制組有 20 萬人，而處理組只有 3 萬人。所以處理組比控制組小得多。你很容易就能看出這種情況為什麼會發生，這在科技公司中經常出現，控制組只是你本來就會做的事情，而我會在這上面獲得數億條觀察數據，處理組則是我能夠從中提取的，並且處理組會小得多。  

因此，我有一個巨大的控制組和處理組之間的不平衡，但我會在估計中利用這一點。對吧？所以，如果你這麼做，並且原始作者只想估算整體的平均處理效應，我則希望估算條件平均處理效應（conditional average treatment effect），我們會在幾張幻燈片後正式定義它。  

目前，你可以將其視為，條件下的處理效應和一些觀察到的協變量之間的關係。對吧？你會發現，在這個實驗中，處理效應的平均值為 8%，而結果是 0 或 1，是否投票的二元結果，這實際上是條件平均處理效應的效果。你會發現——嘿，實際上這裡有很大的異質性，大部分的處理效應集中在這個子群體中。這裡的效應不大，甚至可能有一些證據顯示該子群體的處理效應為負數。哦，你可能應該只針對這裡的選民進行投放，這樣可以省錢。我會這麼做。  

這裡的陰影表示在假設檢驗中該區間的顯著性比例，而對這類問題進行置信區間估算並不是一件簡單的事，能夠真正有效的方法不多。稍後我會解釋為什麼。這樣的結果其實並不容易解釋，你無法說服任何競選活動負責人採用這些結果，因為他們看到這個直方圖會說「你在說什麼？」這簡直是瘋狂的。他們會希望看到的結果是——好的，我會分解這些數據。  

我會按照之前的投票歷史將其分解，這是你過去的投票紀錄——從來沒投過票，總是投票，或是介於兩者之間——這是我估算的處理效應的密度分佈，然後你會說——嘿，不要針對那些總是投票的人，不要針對那些從不投票的人，針對那些處於中間的人。  

技能測試問題——為什麼在民主黨一方，如果我告訴你不要針對這些人投放，他們會感到不安？因為這些人往往來自較低的社會經濟地位和特定族群。人們會說——「嘿，你怎麼不針對他們？」我會回答——「是的，但我想贏得選舉，所以就針對他們。」對吧？但你從這張幻燈片上就能看出這一點。  

現在，這些數據是相關的，所以你可以看出，還有一些其他的協變量可能是在作為這些因素的代理變量，比如年齡等等。另一種方式是，你可以從這些箱型圖中看到處理效應的分佈，包括四分位數範圍，處理效應的變異程度。  

好吧，那麼我們如何獲得這些結果呢？我們如何獲得這些置信區間？你可以使用大量的數據來進行這樣的分析。那個實驗數據量巨大，這個則是小型數據集。這是一個非常著名的數據集，來自我的兩位研究生 David Brockman 和 Josh Kalla。David 現在在 Stanford GSB，而 Josh 現在在 Yale。  

這是關於，如果你敲開人們的門，能否改變他們對跨性別權利的看法的一個著名研究。這篇原始論文最初發表在《科學》期刊，但後來發現它是假的。後來他們重新進行實驗，並且得出了正確的結論。這項研究同樣產生了巨大的影響，並且發現它對某些子群體的效果特別顯著。  

這項研究中，政策制定者非常擔心會有負面反應，但實際上並未發現任何證據顯示有這樣的反向效果。這些先驗假設並未成立。他們對於像墮胎污名化這樣的問題進行了相同類型的處理，但並未發現任何顯著的處理效應，基本上是零的。  

那麼，如何處理這些問題呢？首先需要意識到，估算處理效應的異質性是非常困難的問題。這是一個很難解決的問題，原因有很多，其中之一是「p 值問題」（p-hacking）。如果我讓你將數據分成一千個子群體，並讓你選擇其中一個來進行分析——哇，這樣就很難控制一型錯誤了，對吧？  

你會開始數據過擬合，這會非常困難。人們不喜歡預分析計劃，這在醫學領域很常見，會說「哦，你必須告訴我你會查看哪些子群體」，而當我們查看這些子群體時，我就可以進行各種校正。結果顯示，即使在醫學領域，人們實際上也會定期違反他們的預分析計劃，而審稿人又太懶得去檢查。所以，這也存在一個政策和研究者之間的動態博弈。  

預分析計劃已經進入了像臨床醫學、政治學、經濟學以及發展經濟學等領域。由於人們會將所有分析都放進計劃中，這就形成了有趣的博弈，而許多方法並沒有已知的統計屬性。接下來，我將強調條件平均處理效應的分析方法，特別是在我們想要使用的更複雜方法上，它的漸近理論對有限樣本來說是一個非常差的指導。  

我將提供一組估計量，在一組假設下，它們具有相同的最小最大速率（minimax rates）。但它們在有限樣本下的屬性會有很大差異。我認為這一點非常直觀。所以，對於這些黑箱模型，我們可以得到最小最大結果，但對於條件平均處理效應來說，它們並沒有揭示出我們所希望的那麼多。我在處理平均處理效應時並不會遇到這樣的問題，因為那是一個平均數，只有一個參數。而條件平均處理效應是一個向量，所以要理解它會變得更加困難。

所以，那個向量長什麼樣子呢？好，我們先來統一一些符號，確保我們在同一頁上。現在，我們想做但無法做到的事情是估計個體處理效應（Individual Treatment Effect，ITE），稱為 \( Y_{i1} \)，代表個體 \( i \) 在接受處理時的結果，以及 \( Y_{i0} \)，代表個體 \( i \) 在對照組時的結果。這些都是概念上的數值，舉例來說：「Jane 投票與否——如果我敲她的門或不敲，她是否會投票？」但我們只能觀察其中一個結果，將其稱為 \( D_i \)，並稱 \( \hat{\tau}_i \) 為 \( D_i \) 的估計值。因此，我們在這裡要做的是估計所有協變數等於 \( X_i \) 的個體的條件平均處理效應（Conditional Average Treatment Effect, CATE）。  

接下來，我們展開這個期望值，並做個說明，因為現在有很多不同領域對這個問題感興趣，因此存在一些混淆。  

如果我們分解這個估計值的均方誤差（Mean Squared Error，MSE），你會發現它有兩個不同的部分。第一部分是估計誤差（Estimation Error）。假設 \( X \) 只有一個變數，例如性別（你是男性還是女性）。如果你想估計男性的 CATE，那麼第一個部分就是我對男性的平均估計值與男性的真實平均值之間的差異。如果這只是剛才舉的簡單例子，那麼這個誤差會隨著樣本數 \( n \) 增加而下降，誤差的下降速度是 \( 1/n \)，變異數的下降速度是 \( 1/\sqrt{n} \)。在這種情況下，推論是相對簡單的。  

（聽眾提問，無法聽清）  

[Jasjeet Sekhon]：……有一種誤差是不會消失的，那就是近似誤差（Approximation Error）。這表示：假如有個全知的神諭告訴我，對於男性某種藥物的平均效果是多少，而我是男性，那我就能直接知道這個值，這樣就沒有誤差。但實際上，我這個個體與「所有男性的平均效應」之間的差距可能很大，也可能很小，這取決於情況，而觀察數據無法區分這種誤差。我必須做出非常強的假設才能繼續分析。  

在計算機科學（CS）文獻中，有很多論文聲稱可以估計個體處理效應（ITE），但這需要非常強的假設。在 CATE 估計過程中，我們希望利用現代機器學習方法來處理這個問題。這樣的話，誤差不會以 \( 1/n \) 速度下降，而是以 \( 1/\sqrt{n} \) 速度下降。即使我們使用各種複雜的方法（如樣本拆分等，我待會會詳細講解），這些誤差仍然以 \( 1/\sqrt{n} \) 的速度下降，因此偏差在一階誤差中是無法忽略的。  

在數據中，偏差是一個非常難以掌握的問題。在這裡，情況變得更複雜，因為即使我們有一個保留數據集（Hold-out Set），我們仍然無法知道真正的值是什麼，而我們要估計的是一個向量參數。因此，漸近理論（Asymptotic Theory）是否能夠有效描述這個估計過程，甚至在大數據集的情況下，也會遇到挑戰，因為我們試圖估計的是一個條件平均處理效應（CATE）。  

## 估計 CATE 的元學習器（Meta-Learners）概覽

所以，這場演講的第一部分，我會介紹一些用於估計 CATE 的元學習器（Meta-Learners）。基本上，我們要做的就是將 CATE 分解為一些子回歸問題，然後你可以選擇任何回歸模型來估計這些問題。你可以用神經網絡（Neural Networks）、隨機森林（Random Forest）、\( k \)-均值（K-Means）、普通最小二乘回歸（OLS）等方法，然後將其轉換為 CATE 估計器。我待會也會展示，所選的基本學習器（Base Learner）會極大影響其在有限樣本下的表現。  

當我說「有限樣本」時，這其實是一個半開玩笑的說法，因為我的「有限樣本」通常還是非常大，例如數千萬個樣本。但即便如此，有限樣本的特性仍然對學習器的實際估計方式產生重要影響，而這正是理論與實際之間的一個落差。理論上的分析通常基於最小最大（Minimax）速率，但這忽略了實際估計器的一些關鍵特性。  

好，那麼有哪些方法呢？事實上有很多種，在這場演講中，我會盡可能介紹一些方法，並在 Q&A 時間討論更多細節。  

首先，如果我們要估計 CATE，根據期望運算的線性性（Linearity of Expectation），它可以分解為處理組的期望值與對照組的期望值之間的差異。這樣，我們就可以使用文獻中最古老的 CATE 估計方法之一，即所謂的「T-學習器（T-Learner）」。這個名稱是來自 Susan Athey 和 Guido Imbens 的研究。我們將數據拆分為處理組和對照組，然後對這兩組數據分別進行回歸估計，最後對同一個 \( X \) 計算處理組預測值與對照組預測值之間的差異，從而得到 CATE 的估計值。在特定的假設條件下，這種方法可以達到最小最大速率。  

## X-學習器：處理不平衡數據的策略

接下來，我們介紹另一種不同的方法，它在某些假設下也可以達到最小最大速率。這種方法的基本想法是：假設處理效應與其他協變數一樣，是模型中的一個變數。我們暫時假設這是一個隨機實驗（Randomized Experiment），即沒有混雜因素（Confounding），因此不需要估計傾向分數（Propensity Score）。這就是所謂的「S-學習器（S-Learner）」或單一模型（Single Model）。  

在 S-學習器中，我們不會將數據拆分為處理組和對照組，而是將「是否接受處理」作為模型中的一個協變數。然後，我們對一個固定的 \( X \) 進行預測，分別設定「接受處理」和「不接受處理」的條件，計算兩者的差異，這就是 CATE 的估計值。  

這兩種方法（T-Learner 和 S-Learner）雖然在某些假設下可以達到相同的最小最大速率，但它們的實際表現卻非常不同。為了幫助理解這個區別，我們可以用決策樹（Decision Trees）來舉例。如果使用隨機森林（Random Forest）算法，T-Learner 的做法就像是在隨機森林的根節點（Top Node）上直接根據「處理組與對照組」進行分裂，然後再對兩部分數據分別建模。而 S-Learner 則不進行這樣的分裂，而是將「處理」視為模型中的一個變數，讓模型自己學習其影響。

所以這樣的資訊整合是非常有限的——它從處理組與控制組中提取的資訊非常少，而這將導致某些特定的特性。另一種方法是——我不會強制分割，而是將處理作為普通變數來納入模型。  

因此，在這種情況下，我的分割點可能會選擇根據處理與否來進行分割，也可能不會。我將這種方法稱為 S-learner，因為它是單一模型。我只是——直覺地來說，假設處理沒有影響，你會選擇哪種方法？如果我直接告訴你處理沒有影響，你會選擇哪種方法？S，對吧？因為我希望對數據進行完全整合，而演算法有時會隨機選擇處理與否來分割數據，但這對演算法並不好。  

好，接下來有第三種方法，由 Wager 和 Athey 提出的 Causal Forest。這種方法的做法是：「好，我要在最底層強制進行處理與控制的分割，然後利用這個分割來估計條件平均處理效應（CATE）。」這種方法有一些特定的問題，我們可以討論，不過它們都能達到 minimax 速率，但它們的表現會非常不同。  

接下來我要談談理論部分——首先針對隨機森林（Random Forest）方法的第一個版本，我們將使用「誠實性」（honesty），這個概念可以追溯到 Biau 和 Scornet 的研究，而 Wager 和 Athey 可能是第一個真正寫出這類方法程式碼的學者。這與樣本分割（sample splitting）和交叉適配（cross-fitting）技術有許多相似之處，這些技術在這個領域內的許多人都使用過。  

隨機森林的核心概念是這樣的：我拿到一個樣本，對於每個 Bagging 產生的樣本，我將其分成兩半，在第一半數據上生長一棵決策樹，然後刪除該部分的 y 值，並用另一半數據的 y 值來填補，然後進行反向操作，最後取平均值。這種方法的理論基礎之所以可行，是因為透過樣本分割，我使得決策樹和 y 變量之間的關係獨立，從而可以忽略隨機森林演算法內部的複雜性。隨機森林在第一個分割點之後的理論分析變得非常困難，因此這種方法雖然看起來有些滑稽，但確實讓理論能夠成立。  

這樣，我們就能獲得漸進常態性（asymptotic normality），以及變異數估計等結果。  

接下來我要介紹另一種不同的元學習（meta-learning）演算法——它叫做 X-learner，我會這樣來說明它的動機。  

假設我們的樣本量非常不均衡——處理組與控制組的樣本數量非常不同。這種情況在「催票行動」（get-out-the-vote）和許多線上實驗中都很常見。例如，藍色代表處理組，X 代表控制組。如果我要對這些數據擬合一個函數，假設我們使用 T-learner，你會發現一個問題：在某些區域內，我的數據很少，因此我可能只會擬合一條直線；而在其他區域內，我的數據量較大，因此可以擬合一個更複雜的函數。這裡的數據是模擬的，但我的大部分演講內容是基於真實數據的。  

問題來了——我的條件平均處理效應函數（CATE），也就是兩個函數的差值，最終變得相當複雜。在這個特定的例子中，實際上的真實治療效果是虛線所示的。然而，這裡的問題在於——由於處理組的數據較少，我對其擬合的模型較為簡單，而控制組的數據較多，因此擬合的模型較為複雜。當我計算兩者之間的差異時，我忽略了一個事實——即處理組的數據不足，且我並未直接針對條件平均處理效應函數進行優化，結果導致了一個非常複雜的函數，而我實際上並沒有足夠的數據來支持這樣的估計。  

因此，我們可以使用另一種方法。假設在某種假設下（例如，處理組與控制組的數據分布平衡），X-learner 的 minimax 速率與前面兩種方法相同；然而，在另一種假設下（例如，數據極度不平衡，例如控制組的樣本數遠多於處理組），X-learner 的 minimax 速率會比前兩種方法更好。  

直覺上，X-learner 的做法是這樣的：我仍然會將問題分解為兩個回歸問題，但是，如果控制組的數據量遠大於處理組，那麼我會先估計控制組的反應函數，即 E[Y | 0, X]，然後對於觀察到的處理組數據，我不需要額外估計，因為我直接觀察到了處理後的結果。接著，我會使用控制組的回歸模型，來對處理組的個體進行「填補」（imputation），即利用這個回歸函數來推測如果該個體沒有接受處理，會得到什麼結果。這樣一來，我就能夠根據這些填補後的數據來估計條件平均處理效應。  

這個方法只需要做一次填補，而不像某些方法需要來回進行估計。從演算法的角度來看，我們可以這樣來實現它——（接下來可能會是具體的演算法步驟）。

我要做的事情是估計反應函數。所有藍色的部分就是我要估計的內容，對吧？這可以是隨機森林（random forest），也可以是其他方法。要進行填補，我只需要採用最後一行的內容並在這裡複製它。但我也可以反過來做。我可以估計一個處理組的模型，然後用這個模型來處理我的觀察數據。因此，我估計了處理組的模型，然後對於控制組的觀察數據，我可以使用觀察到的控制數據來對應我估計的控制數據，並為它們估計條件平均處理效應（CATE）。  

你明白我的意思吧？對於每個接受處理的人，我可以推測如果他們在控制組會發生什麼，而對於控制組，我可以推測如果他們接受處理會發生什麼。這樣，我會得到兩種不同的估計方式，而這兩種方式都可以用來計算條件平均處理效應。然後，我可以對這些估計值進行加權處理。  

有各種不同的加權方式。我可以用一種方式加權，得到一個雙重穩健（double robust）估計量，也可以用另一種方式加權，例如按傾向得分（propensity score）加權。不過，按照這種方式加權的結果並不會是雙重穩健的，但目前我是考慮實驗數據，所以我不需要擔心這個問題。我會根據模型更容易估計的地方來加權。  

舉例來說，如果在極限情況下，我有無限多的控制組數據，那麼我會將所有的權重都放在控制組的模型上，而不放在處理組的模型上。這就是這個遊戲的玩法。在這個遊戲中，你可以得到有趣的結果，例如最佳性結果（optimality results）或 minimax 結果。  

## 不同學習器的比較與評估

你還可以利用這個方法來處理大量數據。我仍然需要進行估計，但我可以設想自己在進行一個社會實驗，我可以估計整個數據的條件平均處理效應。我可以用 T-learner 進行估計，並假設這就是真實的結果。  

你可以估計兩個不同的模型，然後假設這就是正確的模型——對吧？你明白我的意思吧？然後，在有限樣本中，我可以從這些數據中抽樣，並評估不同的估計量在有限樣本中的表現，前提是我在完整樣本中使用 T-learner 進行估計。這就是正確的模型，因為我確實是從這個模型中抽樣的，然後我會估計三種不同的學習方法。  

即使 T-learner 是真實的模型，並且這裡的訓練樣本量是 30,000——這條線代表 30,000 個觀察值——它仍然具有最差的均方誤差（MSE），即使它是正確的模型。  

原因在於，這個樣本中有兩個影響因素。在這個數據集中，樣本量非常不均衡，因此 X-learner 可以利用這一點。而 S-learner 在這種情況下會有一種奇怪的行為，它的均方誤差會先上升，然後才開始慢慢下降。  

最終，隨著數據量的增加，S-learner 的均方誤差會不斷降低。但在這個過程中，會發生一件事情——S-learner 為什麼會先出現均方誤差上升？這是因為當它獲得更多數據時，它開始決定要根據處理與否來進行分割，因為處理變數變得更有意義。但它其實並不擅長這件事，因此均方誤差就會上升，然後才慢慢下降。  

這裡有一個關鍵的教訓——如果你分別看變異數和偏差，你會發現當數據量較少時，S-learner 的偏差很高，因為它完全不對處理變數進行分割。但這其實沒關係，因為它的變異數很低。當數據量增加時，它開始進行處理變數的分割，但這件事它做得並不好，因此均方誤差一開始會上升。最終，隨著數據量進一步增加，它的行為才會變得更好。但在這種不均衡的數據環境下，X-learner 一直表現得更好。  

這次的模擬並不是隨意捏造的，因為我是基於 T-learner 是真實模型的假設來進行的，但我有一個樣本可以利用。另一件事是，在有限數據中，這個「變性恐懼症（transphobia）」的實驗並不完全符合實際數據的表現。在《Science》期刊上發表的實際數據中，T-learner 顯示的平均處理效應（ATE）超過 3。這是一個高統計檢定力（well-powered）的實驗，但這次檢定力主要來自於研究生們收集的高效預測變數，而不是來自樣本量。  

在這個研究中，Y0 對這些預測變數的 R² 約為 0.8，這等效於將樣本量增加五倍，因為共變數調整帶來了額外的統計能力。所以當你使用 X-learner 進行估計時，你會看到——這條黑線代表的是簡單的均值差異估計量（difference-in-means estimator）對於平均處理效應的結果，你可以看到處理效應的不均衡性。  

在這個例子中，由於樣本數量相等，因此 minimax 速率對於 X-learner、T-learner 和 S-learner 來說應該是一樣的。這是 X-learner 的結果，這是 T-learner 的結果。你可以看到 T-learner 的估計結果出現了非常大的波動，因為它是基於兩個不同的模型進行差值計算的。這當然會有一些特定的特性。  

更令人不安的是這是 S-learner 的結果。請記住，這應該是一個平均處理效應的估計量，但它的表現完全不像均值差異估計，它的結果嚴重偏移，並且極端地向零縮減。即使在這個樣本規模不算太大的實驗中（樣本量約為 1,000），由於共變數調整的影響，實際上這相當於 5,000 個樣本的效果。  

但問題在於，當樣本量不夠大時，如果我開始使用這些方法來估計條件平均處理效應（CATE），結果的變異性會很大，並且不同方法之間的估計結果差異極大。這種現象是非常令人不安的。一旦你意識到這一點，你應該會開始懷疑這些方法的置信區間——無論是以何種方式計算的置信區間，這些結果都不太可信，因為這些估計量的偏差尚未消除，並且它們的偏差還相當極端。

當你開始進行這些模擬時，你會看到這些現象。這個設定來自 Wager 和 Athey，這是一個對處理函數來說相當複雜的設定。你可以看到這裡是因果森林（causal forest），這裡是 S learner，這裡是 X learner——它在這個情況下表現得不錯。基礎學習器（base learners）確實會產生影響，這裡是隨機森林（random forest），這裡是貝葉斯回歸樹（Bayesian regression trees），它是一種貝葉斯森林（Bayesian forest）。  

它進行了更多的收縮（shrinkage），因此當這種收縮有效時，它的表現就會很好；但當收縮不利時，它的表現就會很糟糕，這是可以想像的。在無處理效應的情境下，哪種方法會表現得更好？答案是 S learner，它是這條綠線（Green Line）。它的表現好得多。然後，有些方法會抵抗混淆（confounding），這些方法並不是雙重穩健（doubly robust）估計量，但它們仍然能夠抵抗混淆。  

## 理論基礎、最小最大速率與限制

此外，基礎學習器的選擇會帶來巨大的影響，特別是在隨機森林和 R 之間。現在，如果你想討論一點理論內容，那麼我們可以這樣思考——不過，我可能會時間不夠，我會先講一些理論，然後再談另一個內容，最後就會沒時間了。  

好，讓我們來建立一些理論背景。我們假設處理（treatment）變數服從伯努利分佈（Bernoulli distribution），我們有 \( y_0 \) 和 \( y_1 \)，它們的分佈是這樣的，然後我們需要在 \( \tau \) 上施加一些正則性條件（regularity conditions），以獲得較好的收斂速率。  

要直觀地理解這一點，可以想像 \( y_0 \) 可能會變得非常複雜。我只是試圖對控制組進行預測，但在大多數情境下，這是一個非常複雜的函數，而且我有許多變數 \( w \)。在我的經驗中，它並不是稀疏的（sparse）。在大多數數據集中，當有人說要估計你的控制函數時，他們通常會假設稀疏性（sparsity），但這並不會真的發生。  

條件平均處理效應（CATE）通常是稀疏的，並且通常是相對簡單的。還記得我之前展示的拉普拉斯分佈（Laplacian distribution）嗎？它的值通常是零，這就很簡單，對吧？所以，如果條件平均處理效應具有某種稀疏性或平滑性，我就可以在 X learner 中加以利用，因為它有一個額外的步驟來處理這個問題。  

另一個關鍵點是，如果我使用交叉擬合（cross-fitting）和一系列技巧來估計 \( y_0 \) 和 \( y_1 \)，然後估計 CATE，那麼我的 \( \xi_i \) 和 \( \xi_j \) 的誤差將會變得不相關（uncorrelated），因為我對數據進行了拆分，這迫使它們變得不相關。  

我們第一篇論文中的最簡單結果就是這樣的：我們假設「可忽略性」（ignorability），這是一種對變數選擇的假設，這種假設非常常見。假設真實的處理效應是線性的，然後我們對 \( \mu_0 \)（即控制函數）施加 Lipschitz 平滑性條件，然後我們估計 X learner，結果會如何？  

好，我們將達到 \( n \) 的參數收斂速率（parametric rate），這時我們討論的所有方法——S learner、T learner、因果森林（causal forest）等等——都可以達到這個速率，因為這個速率其實不難達到。  

然而，如果我們假設控制組的數量遠多於處理組的數量，那麼我們仍然可以回到參數收斂速率。原因是什麼呢？我們在估計控制函數時表現會很差，因為它是一個非常複雜的函數，但如果條件平均處理效應 \( \tau \) 是線性的，那麼在第二步進行組合時，我仍然可以達到參數收斂速率。  

在我們的論文發表之後，Foster——我總是念錯這個人的名字——我想 Foster 是 MIT 的一名博士後研究員，他們對我們的估計方法（特別是雙重穩健版本）給出了一個更一般化的結果。我在論文的投影片中有列出這個版本的估計方法。他們使用了一種曾經非常流行的方法，叫做 Neyman 正交性（Neyman orthogonality），這基本上意味著我們可以達到「神諭（oracle）速率」，也就是說，如果我們知道真實的傾向得分（propensity score），並且擁有真實的 \( y_0 \) 模型，那麼我們就可以獲得與這些條件下相同的參數收斂速率。  

這聽起來很酷，但其實大多數提出的方法都能做到這一點。因為這基本上是一種學術篩選機制（filtering of journals）——如果你的方法不具備這個性質，別人就不會接受你的論文。因此，幾乎所有方法都會聲稱自己達到了 minimax 速率，但這些方法在實際應用中的表現卻有很大差異。  

## 進階方法：結合神經網絡的 X-學習器

也就是說，單純地遵守 minimax 速率本身對我們這個問題來說並不是特別有用。而我最後要講的，是一篇獨立的論文，這篇論文的作者包括 Sören Künzel、Bradley Stadie（他是我的學生）、兩名本科生，還有 Pieter Abbeel，他是加州大學柏克萊分校（UC Berkeley）的一名機器人專家。我們在這篇論文中使用了 X learner，並且將其與神經網絡（neural network）結合起來。

原因在於 X learner 的問題是，你可以從概念上思考它，我會估計一個條件平均處理效應模型，我會估計 \( y_0 \) 和 \( y_1 \) 的模型，但你知道，我並沒有告訴我的模型，我會最終估計條件平均處理效應。所以它們會去尋找非常好的 \( y_0 \) 的估計，可能它們不應該這麼做，對吧？因為當我進入下一步並取其差異時，這些差異並不重要。那麼，神經網絡（neural nets）擅長做什麼？我可以創建層並將信息反向傳播。因此，在神經網絡中，你可以做的最簡單的一件事是，說「哦，我要拿我的條件平均處理效應模型，然後從那裡反向傳播到我的 \( y_0 \)、\( y_1 \) 和我的數據」。但實際上你並沒有這麼做。如果你這麼做的話，最終的結果是，你會實際上低估數據的調整。這就是在因果森林中出現的問題，因為有一些協變數，條件平均處理效應並不是其函數，但這些協變數在預測 \( y_0 \) 時非常有用，而這些協變數與處理效應並沒有互動，它們對於減少均方誤差是有用的。所以你需要抓住這些。

所以在這個複雜的過程中，你會說「嘿，我創建了一個包含很多不同頭部的神經網絡」，其中一些頭部將來自於——我會轉到算法形式，因為我覺得這樣會稍微容易一點——一些頭部來自於，這是控制組。我將為控制組創建一個網絡來預測我的觀察值 \( Y_{obs} \)，然後我會更新一個網絡來預測控制組的 \( Y_{obs} \) 加上我的處理效應，然後我會更新一個網絡來做反向操作。我會為控制組、處理組分別做這些事——我錯了——然後這件事我們沒有一個很好的理論結果可以解釋，它的情況和 GANs 一樣，像我在設置 GAN 時那樣，你知道，大家不喜歡觸碰 GANs，因為當它有效時，它就有效，你稍微推動一下，它就會爆炸。

原因是對抗學習器（adversarial learner）和生成模型（generating models）必須同時進行進化，它們必須共同發展。如果我一開始就用一個非常強大的辨別器（discriminator），那麼它就不會有任何進展，對吧？你會發現，辨別器必須足夠差，才能和生成模型的部分匹配，當它們達到平衡時，這樣就有效了。這有點像是讓 GAN 工作的魔法，當你開始觸碰它們時，如果失去了平衡，最終你會得到一個非常糟糕的 GAN。這裡也發生了類似的事情，因為沒有直接的反向傳播，所以你必須讓針對 \( y_0 \)、\( y_1 \) 和 \( \tau \)（條件平均處理效應）的模型共同發展，它們必須在某種程度上共同學習，「哦，這是一個對於 X 有用的信息，對於 \( y_0 \) 是否是條件平均處理效應的有用信息？」所以這引出了一個非常有趣的問題，嘗試理論性地分析這個問題是一項滑稽的練習，它不會很好地工作，而這就是使它有效的原因，並且在應用中表現得比 X learner 更好，這與 GANs 的運作方式一樣，這是一個比較難以分析或理解的過程，我不會討論這些數據。

## 總結與未來挑戰

好吧，現在有很多轉移學習（transfer learning）的問題，我有一堆不同的實驗，我想從一個設定轉移到另一個設定。人們可以進行貝葉斯收縮（Bayesian shrinkage），但現在是現代時代，我會把這當作一個轉移學習問題來處理。我可以將神經網絡從一個實驗熱啟動到下一個實驗並看看我學到了什麼。更一般地說，我們期望從實驗中學到更多的東西。我的個人觀點是，我們花了數百萬美元來進行隨機實驗。當我們這麼做時，我們希望保護第一類錯誤率（type 1 error rate），這就是我們為什麼要做這些事情。

如果你有一個隨機實驗，我會請求你不要做一些削弱第一類錯誤率的事情，因為那是我們唯一知道如何控制的東西。在觀察性研究中，會有不同的需求，而這樣的研究本身就已經足夠困難了。條件平均處理效應的統計功效（power）是一個非常嚴重的問題，這種功效隨後會與超參數調整（hyperparameter tuning）相關，因為我不知道真實的基準，我必須估計它，這變得非常困難。隨著方法越來越複雜，它們遠遠超出了我們的理論理解，唯一能夠回歸的就是進行實際數據的驗證，但這很難，因為我們的估計比我們希望的更嘈雜，偏誤也很大且難以控制。所以，我們就停在這裡。哦，這是我今天所提到的各篇論文的共同作者 *掌聲* [Devavrat Shah]：好的，我們有時間提問。原因在於 X learner 的問題是，你可以從概念上思考它，我會估計一個條件平均處理效應模型，我會估計 \( y_0 \) 和 \( y_1 \) 的模型，但你知道，我並沒有告訴我的模型，我會最終估計條件平均處理效應。所以它們會去尋找非常好的 \( y_0 \) 的估計，可能它們不應該這麼做，對吧？因為當我進入下一步並取其差異時，這些差異並不重要。那麼，神經網絡（neural nets）擅長做什麼？我可以創建層並將信息反向傳播。因此，在神經網絡中，你可以做的最簡單的一件事是，說「哦，我要拿我的條件平均處理效應模型，然後從那裡反向傳播到我的 \( y_0 \)、\( y_1 \) 和我的數據」。但實際上你並沒有這麼做。如果你這麼做的話，最終的結果是，你會實際上低估數據的調整。這就是在因果森林中出現的問題，因為有一些協變數，條件平均處理效應並不是其函數，但這些協變數在預測 \( y_0 \) 時非常有用，而這些協變數與處理效應並沒有互動，它們對於減少均方誤差是有用的。所以你需要抓住這些。

所以在這個複雜的過程中，你會說「嘿，我創建了一個包含很多不同頭部的神經網絡」，其中一些頭部將來自於——我會轉到算法形式，因為我覺得這樣會稍微容易一點——一些頭部來自於，這是控制組。我將為控制組創建一個網絡來預測我的觀察值 \( Y_{obs} \)，然後我會更新一個網絡來預測控制組的 \( Y_{obs} \) 加上我的處理效應，然後我會更新一個網絡來做反向操作。我會為控制組、處理組分別做這些事——我錯了——然後這件事我們沒有一個很好的理論結果可以解釋，它的情況和 GANs 一樣，像我在設置 GAN 時那樣，你知道，大家不喜歡觸碰 GANs，因為當它有效時，它就有效，你稍微推動一下，它就會爆炸。

原因是對抗學習器（adversarial learner）和生成模型（generating models）必須同時進行進化，它們必須共同發展。如果我一開始就用一個非常強大的辨別器（discriminator），那麼它就不會有任何進展，對吧？你會發現，辨別器必須足夠差，才能和生成模型的部分匹配，當它們達到平衡時，這樣就有效了。這有點像是讓 GAN 工作的魔法，當你開始觸碰它們時，如果失去了平衡，最終你會得到一個非常糟糕的 GAN。這裡也發生了類似的事情，因為沒有直接的反向傳播，所以你必須讓針對 \( y_0 \)、\( y_1 \) 和 \( \tau \)（條件平均處理效應）的模型共同發展，它們必須在某種程度上共同學習，「哦，這是一個對於 X 有用的信息，對於 \( y_0 \) 是否是條件平均處理效應的有用信息？」所以這引出了一個非常有趣的問題，嘗試理論性地分析這個問題是一項滑稽的練習，它不會很好地工作，而這就是使它有效的原因，並且在應用中表現得比 X learner 更好，這與 GANs 的運作方式一樣，這是一個比較難以分析或理解的過程，我不會討論這些數據。

好吧，現在有很多轉移學習（transfer learning）的問題，我有一堆不同的實驗，我想從一個設定轉移到另一個設定。人們可以進行貝葉斯收縮（Bayesian shrinkage），但現在是現代時代，我會把這當作一個轉移學習問題來處理。我可以將神經網絡從一個實驗熱啟動到下一個實驗並看看我學到了什麼。更一般地說，我們期望從實驗中學到更多的東西。我的個人觀點是，我們花了數百萬美元來進行隨機實驗。當我們這麼做時，我們希望保護第一類錯誤率（type 1 error rate），這就是我們為什麼要做這些事情。

如果你有一個隨機實驗，我會請求你不要做一些削弱第一類錯誤率的事情，因為那是我們唯一知道如何控制的東西。在觀察性研究中，會有不同的需求，而這樣的研究本身就已經足夠困難了。條件平均處理效應的統計功效（power）是一個非常嚴重的問題，這種功效隨後會與超參數調整（hyperparameter tuning）相關，因為我不知道真實的基準，我必須估計它，這變得非常困難。隨著方法越來越複雜，它們遠遠超出了我們的理論理解，唯一能夠回歸的就是進行實際數據的驗證，但這很難，因為我們的估計比我們希望的更嘈雜，偏誤也很大且難以控制。所以，我們就停在這裡。哦，這是我今天所提到的各篇論文的共同作者 *掌聲* [Devavrat Shah]：好的，我們有時間提問。

[Jasjeet Sekhon]: 當然。後面那位。 [觀眾提問 1]: 所以，你提到 X learner、S learner 和 T learner 都能達到 minimax 比率嗎？所以我的理解是，收斂速度會依賴於函數的平滑性。所以當你說它們達到 minimax 比率時，你是指它們達到的 minimax 比率取決於 CATE 的平滑性，還是取決於兩個潛在結果中最差的一個？ [Jasjeet Sekhon]: 啊，好吧。所以，如果樣本是非無偏的——抱歉，是非平衡的，所以它們有相同的平衡，而我並不是——所以它們是平衡的，對吧，抱歉，我使用的是確切的形式，它們會這麼做，它們會達到最差的 \( y_0 \)、\( y_1 \)。只是一般意義上的做法。現在，還有一些我沒有提到的事情，這些事情會導致一種雙重穩健估計器，它從一個變換模型開始——我可以拿我的 \( Y \)，如果你知道它也是一個東西——我有一個無偏估計器，並且對一個人進行實驗，那麼我的無偏估計對一個人來說是什麼呢？假設它是一個平衡實驗的擲硬幣。哦，這就像是如果它是處理組則是 \( 2 \times y \)，如果是控制組則是 \( -2 \times y \)。我實際上就是這麼做的，我將我的 \( y \) 進行這樣的變換，現在我直接針對 CATE，現在它的 minimax 比率將依賴於該函數的平滑性。

問題是，如果我去做這個，我就無法從協變數調整中獲得任何利用增益。所以我首先將數據殘差化，然後再進行變換，這樣我就能做了，然後還有一堆不同的估計器可以試圖利用。 [觀眾提問 2]: 是 R learning，對吧？ [Jasjeet Sekhon]: R learning 可以做到，對。

現在，R learning 可以做到，但對處理效應的假設，處理效應模型的線性假設。現在沒有免費午餐了，然後在觀察數據中，現在非常依賴於 p 分數，這是分母，所以發生了什麼——你知道，這與逆概率加權（inverse probability weighting）是相同的——什麼時候好，什麼時候不好——嘿，如果那些概率接近於零或一，這就是真正糟糕的行為，這對於平均處理效應來說是其中一個問題。對於條件平均處理效應來說，在隨機實驗中，我估計接近零和一的東西，因為隨機——在我得到足夠多的協變數的數據時。這樣我可以達到，我可以看到最優結果並不難，我們擅長證明這些東西，我們有動機證明這些——那...？這是關於這個問題的好問題。

還有其他人舉手了嗎？ [觀眾提問 3]: 你有推薦的套件嗎？ [Jasjeet Sekhon]: 套件是做什麼的？——是我提到的隨機森林，它在線上，它在 forestry 套件中，你可以在 GitHub 上找到它。這個套件的另一個優點是，我認為它是我所知道的最快速的誠實實現，速度非常快。

我們還在這個套件中做了線上 ridge，這就是隨機森林發生的事情，它並不太好，我不想太多談它，它在 S learner 和 X learner 中更重要，只是這些純粹的算法問題，對吧？隨機森林做什麼呢？它就像現代世界一樣，對吧，這個算法有點像——它是做什麼的呢？就像「哦，一個隨機森林——在我的森林中，我的預測器就是一個葉子，它是葉子的平均值——但如果那裡有一個強趨勢，那麼它就不太好，它無法利用那個趨勢。所以我們做的就是在每個葉子的底部做 ridge。其他人以前做過這個，難點是——我們做的是線上 ridge——當隨機森林分割時，它知道它要運行 ridge，所以這些分割是最優的，知道它會在底部葉子運行 ridge，你明白我的意思吧？在底部，它不是平均數，而是白板——沒有墨水，我現在不做了——但如果根平均數中有趨勢，平均估計將會很糟糕，它會在那裡進行 ridge 迴歸。所以如果有趨勢，它會捕捉到這個趨勢。這只是說，知道隨機森林對於哪些函數很難近似是什麼？ [觀眾中的某人說話不清晰] 只是直線！這樣做就行了，或者假設它是一個 V，假設真實函數是 V，隨機森林應該做什麼，如果它能做 ridge？它應該分裂多少次？一次。所以它會分裂一次，現在它會變成兩條直線，這就是它要做的，這是正確的做法。其他實現並不像這樣聰明，因為它們沒有做線上 ridge，也沒有進行測試，因為你可以從計算上來看，你在額外增加這個多項式時間項，對吧，這是非常難的。

如果你只在最後運行 ridge 或 lasso，而不是把它構建到優化中，它會過度分裂，然後再運行 ridge。無論如何，這些都在 forestry 套件中，你可以在 GitHub 上查看。現在有很多其他的套件。你問我，我會給你這個。


在這些數據科學挑戰中，BART 表現得相當好，所以你也應該看看這個。[觀眾提問 4]: （聽不清） [Jasjeet Sekhon]: 我的意思是，a) 如果有人告訴我「你有 1 億個觀察值，你可以以任何方式分配來最大化效能」，我當然會告訴他們做一個等量的樣本分割，但這不是選擇。選擇是你可以有 1 億個控制組，還是只有 100 萬個處理組，你想要 100 萬個控制組還是 1 億個？說「給我少一些數據」不是一個好的答案。我的意思是「給我 1 億個數據，然後 X learner 就會利用這些數據來運用它」，這就是答案，這就是激勵我們這麼做的原因。

[Jasjeet Sekhon]: 人們已經在這種情境中使用過它，有些人已經在藥物發現公司中使用它。我曾經做過一些醫學方面的工作，但現在不再做了。我並沒有在很多醫療數據上使用過它，所以說——像生活中的大多數事情一樣，這會取決於情況。醫療環境中通常發生的問題是，它們有高維度的協變數，並且它們的實驗規模相當小。所以如果有人真的想要有效的推論，這將會很困難，對吧？這將會相當困難。正如我所說，樣本大小如果變得相當大，比如我談到的出門投票實驗，推論就會相當好，因為原因是你有大約 230,000 個觀察值，大約有 6 個協變數，7 個協變數。大多數都是離散的。所以猜猜看，最後它就變成了——哦，天啊，最後它就變成了一個密度估計問題，任何隨機森林都能做得相當好，但這並不是醫療環境的樣子。所以我對這個在小樣本大小中的表現有一些擔憂。在哪裡它可能會表現得很好，我有一些較舊的論文，當我有一個隨機實驗和一個大型觀察數據集時。這其中有一篇是關於（聽不清）導管插入術，它是一個心臟監測設備，你有一個隨機實驗，樣本是 500 人。這是一個非常重要的實驗，因為我們將這個設備放入人體，我們每年花費 20 億美元，結果證明它實際上沒有治療效果，零。 我們可能不應該花 20 億——二十億，應該說，是十億——但我們有一個 2 萬人的觀察數據集，所以你應該在那裡加以利用，利用我們可以在線下討論的方式。讓我這麼說——二萬個樣本在估計控制模型時非常好，如果沒有其他的，至少能將你的誤差降低。

[Alberto Abadie] 最後一個問題，然後我們可以稍後繼續這個對話。我們在 TPP 區有一個接待會，就在這條走廊的盡頭，右邊。[觀眾提問 5]: 你經常提到使用 GANs，我有點好奇，如果不使用你的機器學習作為預測器，而是使用生成式或條件生成模型來生成基本上——\( p(y \mid x, 1) \) 和 \( p(y \mid x, 0) \)，讓它進行生成——那會發生什麼？什麼不管用？

[Jasjeet Sekhon]: 這是一個很好的問題。我曾與研究生 Bradly Stadie 合作過，他現在在 Vector（研究所），我和他正好在做這個。[觀眾提問 5]: 看起來，使用機器學習作為預測器——你在開始前就把自己送進了墳墓。看起來你真的在尋找隱藏的模型。

[Jasjeet Sekhon]: 所以，我們會看到這正是我們正在做的。這是我們在做的事情，因為我們覺得「嘿，這似乎是我們想要的東西。」現在，你必須小心的是——在這種方法中，我們實際上要看的就是數據無法區分個別的處理效應。我可以給你一些 DGP（資料生成過程），讓觀察數據無法——我應該說，觀察數據無法區分的東西。所以我擔心的是，如果我們這麼做的話，它會正常工作——正如我所說，不同於一般情境，你只會得到非常嘈雜的信息，來告訴你它運作得如何，對吧？正確，正確，這就是我擔心的，但我認為這是一個很好的問題——我認為我們問了一樣的問題，我們現在正在努力，還太早無法給出答案。我希望它能夠順利運作，因為如果它能順利運作，將會非常棒。謝謝。

[Alberto Abadie]: 好的，現在我們的時間到了，謝謝大家。 *掌聲*

