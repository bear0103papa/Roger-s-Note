{"componentChunkName":"component---src-templates-blog-post-js","path":"/2025-03-25-Jack/Content/","result":{"data":{"site":{"siteMetadata":{"title":"Roger's Note"}},"markdownRemark":{"id":"a38b3903-37fd-5de7-9ff0-7e48b1e1f658","excerpt":"大家對歷史可能還不太了解，所以我會花一些時間把它整理一下。 今天我主要會講兩個內容： 第一個是context，也就是報告AI產業的背景。我會從望遠鏡的研究角度，來看看整個AI產業的現況，以及了解我們當前所處的位置。 第二個是我們繪製了一些簡單的產業地圖，目的是建立全局觀，然後再決定我們下一步如何進入目標領域。 AI…","html":"<p>大家對歷史可能還不太了解，所以我會花一些時間把它整理一下。</p>\n<p>今天我主要會講兩個內容：</p>\n<p>第一個是context，也就是報告AI產業的背景。我會從望遠鏡的研究角度，來看看整個AI產業的現況，以及了解我們當前所處的位置。</p>\n<p>第二個是我們繪製了一些簡單的產業地圖，目的是建立全局觀，然後再決定我們下一步如何進入目標領域。</p>\n<h2 id=\"ai概念的萌芽期\" style=\"position:relative;\"><a href=\"#ai%E6%A6%82%E5%BF%B5%E7%9A%84%E8%90%8C%E8%8A%BD%E6%9C%9F\" aria-label=\"ai概念的萌芽期 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AI概念的萌芽期</h2>\n<p>我先從AI產業的context開始。</p>\n<p>這次的研究是從1950年開始看的，從圖靈測試那時候開始。我把1950到1970年這段時間稱為AI概念的萌芽期。這段時間的特徵是，AI首先是在學術界興起的。1950年，AI的最初關鍵是圖靈測試。這是英國數學家圖靈在他發表的論文《Computing Machinery and Intelligence》中提出的。他提出了一個問題：機器是否能夠思考，是否能像人類一樣思考？他認為，如果機器能夠透過回答問題讓人誤以為是人類的回答，那麼這就證明這台機器有可能擁有智能。</p>\n<p>這個問題引起了大家對AI的關注，讓大家開始意識到人工智慧作為一個獨立學科的可能性。1956年是非常重要的一年，那時有一位叫做John McCarthy的學者，也就是麥卡吉，他在美國達特茅斯學院主辦了一場人工智能研討會，並且邀請了Marvin Minsky等人參加。他們召集了這個領域的學者，開始討論AI的相關議題。當時有些科學家對AI抱持非常樂觀的看法，這一切都源自於圖靈測試。那時麥卡吉就提出了一個定義：他認為，如果機器能夠執行需要人類專業知識才能完成的任務，那麼這就可以視為AI的存在。</p>\n<p>當時參與研討會的這些人，後來成為了AI領域的重要人物。這裡有一張圖，展示了1956年這些科學家如何從一開始的AI預算開始，共同討論AI的狀況和他們的觀察。這些科學家對AI非常樂觀，並預測在10年或20年內，AI可能就能完成一些人類所能做的任務。</p>\n<p>接著在1958年，出現了一個重要的轉折點，那就是Lisp程式語言的誕生。這也是由John McCarthy在麻省理工學院發明的。Lisp是一種程式語言，它在早期的AI發展中扮演了非常重要的角色，是當時AI開發的主要工具。接著在1959年，MIT的AI實驗室也相繼成立，這也是由McCarthy和Minsky共同創立的。這標誌著早期AI研究機構的成立，並且後來發布了大量的相關論文。</p>\n<p>在這段時間內，主要是學術界的發展。不過，除了學術界之外，當時也開始出現一些早期的AI應用。這些應用和實驗展示了機器在特定任務上具有智能的潛力。1962年，Joseph提出了一個模仿心理治療對話的程式，這是當時AI應用的一個代表性例子。</p>\n<p>有一個叫做Alisa的聊天機器，我覺得非常有趣。這是人類史上第一個聊天機器，它可以進行非常逼真的對話，有時候用戶會以為自己在和人類交流。其實它是基於規則的（rule-based），也就是說，開發者將邏輯寫進Alisa中，然後它根據這些邏輯來回答問題。</p>\n<p>我還能使用這個聊天機器人，並且在網站上進行了對話。我跟它聊了一下，問它是否是心理治療的聊天機器。它回答說：「哈囉，我叫Alisa。」並且說它是我的心理治療師。然後我回答：「嗨，我叫Jack。」它回應說，我們不需要名字，這樣讓我有些不開心，因為我來做心理治療，結果還被嗆了，心情就更糟了。</p>\n<p>接著，我告訴它我很難過，問它能怎麼幫我。它開始問我一些問題。其實它的回答很笨，就是我問它問題，它會反問我問題。這樣的對話讓當時的人產生了一種錯覺，覺得自己被傾聽了，達到了某種心理治療的效果。我告訴它，我很難過。它回應說：「那你可以告訴我更多關於這個情緒嗎？你感覺怎麼樣？」我回答：「我很悲傷，我很生氣，我很沮喪。」然後它就繼續回答我的問題。雖然這個過程有些荒謬，但它確實是人類史上最早的聊天機器，這點我覺得很酷。這個聊天機器出現的時間是1966年。</p>\n<p>另外，第二個應用是1969年，這是最早的機器人。在史丹佛研究所，當時發明了這個行走機器人，叫做Shakey。Shakey是第一個可以移動的機器人，它整合了攝影機和感測器。Shakey可以推動物體，雖然它當時只能做推動東西這個簡單的工作，但它仍然是機器人發展史上的一個重要里程碑。</p>\n<p>這就是當時最早的移動機器人，Shakey，出現於1969年。因為這些應用的問世，科學家們當時都非常興奮，認為AI即將起飛。當時的科學家，包括亞瑟·山廟（Arthur Samuel）和紐維爾·西蒙（Newell &#x26; Simon），這些人都是1956年研討會中的參與者。他們根據這些應用嘗試開發新的技術。例如，他們在IBM開發了跳棋對弈程式，讓電腦學會如何下棋，進行遊戲。此外，西蒙也開發了能夠證明數學定理的AI程式等，這些都是早期的AI應用。</p>\n<p>至於早期的AI資金來源，最初是來自美國國防部的一個計畫，叫做ARPA（先進研究計劃署）。當時國防部對AI技術非常感興趣，於是開始向學術機構提供大量經費，主要集中在麻省理工學院和史丹佛大學。他們在這些地方成立了許多AI研究計畫，並穩定地提供資金支持。例如，1963年MIT就從這個計劃中獲得了220萬美元資助。此外，像Minsky、McCarthy這些科學家創立的AI研究組，也每年獲得超過300萬美元的資金支持，一直到1970年代。</p>\n<h2 id=\"第一次ai寒冬1970-1980\" style=\"position:relative;\"><a href=\"#%E7%AC%AC%E4%B8%80%E6%AC%A1ai%E5%AF%92%E5%86%AC1970-1980\" aria-label=\"第一次ai寒冬1970 1980 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>第一次AI寒冬（1970-1980）</h2>\n<p>然而，為什麼資金支持會持續到1970年代呢？這是因為1970年到1980年期間，AI經歷了第一次寒冬，也就是第一次AI的崩潰。1970年代到1980年代這十年間，是AI的第一個“崩潰期”。至於為什麼會崩潰，我簡單說明一下原因。首先，雖然技術在持續發展，包括推出一些新程式語言或是1974年斯坦福的某位研究者開發了一些系統，但當時的技術還無法解決很多實際問題。例如，有一個叫做MYCIN的系統，它根據醫療知識來推論病人可能感染的細菌並推薦抗生素，這是很有應用潛力的技術。</p>\n<p>然而，在1970到1980年期間，AI的發展遇到了三個主要問題。首先，最大的問題是運算能力。當時的電腦計算能力非常有限，存儲空間也很小，而且處理速度很慢，這使得它無法解決許多實際的AI問題。換句話說，當時的AI應用更多的是像玩具一樣的實驗，並未能解決真正複雜的問題，例如機器人或聊天機器人等應用。</p>\n<p>其實那時的AI應用，某種程度上都可以看作是玩具。例如，有一位科學家叫做Ross Creen，他當時想做自然語言方面的研究，但他只能使用20個單字來進行測試，因為當時的內存有限，無法容納更多的資料，儲存空間和運算能力都非常有限。這使得當時的技術無法前進，因此運算能力成為AI發展的瓶頸。</p>\n<p>第二個問題是資料不足。很多重要的AI應用，如視覺和語言處理，要求系統對大量的世界資訊、訊息和資料進行處理。只有這樣，程式才能理解它所看到或聽到的內容。然而，這需要程式至少具備兒童水平的認知能力，也就是能夠辨識和理解世界上的事物。然而，在1970年，沒有人能夠建造出這樣龐大的資料庫，也沒有人知道如何讓程式學到這些豐富的訊息。因此，當時的研究者發現，儘管解決一些數學問題相對簡單，但解決一些簡單的視覺或語言問題卻極為困難，因為這些問題需要大量的計算能力，而當時並沒有足夠的算力來支持這些需求。</p>\n<p>因此，AI只能解決一些簡單的問題，無法應用到現實世界中。這些挑戰使得當時資助AI的國防部和其他機構開始縮減對AI的投資。1973年，英國政府發表了一份報告，指出AI的發展成果非常有限，雖然有很多討論，但實際上交付的成果卻很少。因此，英國政府決定全面停止對AI的資助。</p>\n<h2 id=\"專家系統的興起1980-1988\" style=\"position:relative;\"><a href=\"#%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1%E7%9A%84%E8%88%88%E8%B5%B71980-1988\" aria-label=\"專家系統的興起1980 1988 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>專家系統的興起（1980-1988）</h2>\n<p>然而，即使在這樣的情況下，學術界並沒有放棄AI的發展。學術界繼續成立促進會和研討會，並在1980年代，矽谷的一些新創公司依然看好這個領域，並為下一個階段的發展做準備。這個新階段是所謂的專家系統，旨在將專家系統和LISP程式語言商品化。當時，美國矽谷的一些AI新創公司很多是從MIT的AI實驗室衍生出來的，這些公司致力於開發基於LISP語言的硬體和軟體。在這段時間裡，誕生了兩家公司，其中之一是LISP Machine，專門開發LISP相關的硬體。</p>\n<p>另外一家公司是Symbolics，這家公司做的是LISP軟體和硬體，這兩家當時較大的硬體公司都在這個時期成立。雖然政府大規模的資金支持縮減，但仍有一些小規模的應用在持續支持。到了1980年，AI領域中很多理論依然帶有哲學成分，一些哲學家指出，如果電腦只是盲目地執行指令，並給出回應，而完全不理解它所說的內容，這種情況非常侷限。因此，當時學者們決定將AI的應用範圍縮小，從早期的通用AI轉向專注於垂直領域的專家系統。</p>\n<p>專家系統的出現，主要是為了能夠在特定領域內發揮作用，這也是1980到1988年間，專家系統興起的背景。所謂的專家系統，簡單來說，就是將人類的知識和規則輸入到電腦中，這樣電腦就可以通過搜尋和推論來處理問題。這樣的系統可以解決一些垂直領域的問題。</p>\n<p>例如，1980年，數位設備公司（Digital Equipment Company，簡稱DEC）成功部署了一個專家系統來自動分配訂單，這是最早的商業化應用之一。由於他們是硬體公司，每天都有很多企業與他們進行訂單交易，他們通過這個系統將訂單規則輸入電腦，讓系統自動處理訂單分配。這一系統每年為公司節省了約4000萬美元的成本，對公司來說是相當大的節省。而當時的DEC，是全球第二大的公司。</p>\n<p>DEC的營收在1980年代高達140億美元，且每年能夠節省4000萬美元，這顯示出AI在商業中確實具備顯著的價值。這是AI應用於商業領域的初步展示。隨著這個成功案例的展示，許多國家，包括日本和美國，開始再次投入到AI的研究，尤其是從國防領域開始。</p>\n<p>在1985年，隨著DEC成功降成本的案例，開始出現了開發這些系統的軟體公司。過去十年中，一些硬體公司已經成立，而1985年則開始有了專注於軟體的公司，例如Technology和Intelco（儘管這些公司後來逐漸沒落）。這些公司開始投入資源，推動AI發展。到了1985年，許多公司在AI領域的年投入總額已超過10億美元，這使得1980年代成為AI較為熱絡的時期。</p>\n<p>此外，1986年，學術界也取得了一個重要突破。Jeffrey Hinton，一位在深度學習領域的關鍵科學家，發明了一種演算法，證明了神經網絡可以通過訓練來學習更複雜的模型。這是當時學術界在AI領域的一個重要突破。</p>\n<p>整體來看，1980年代的AI發展主要集中於專家系統，專注於解決特定領域的問題，並幫助企業減少成本。</p>\n<h2 id=\"第二次ai寒冬1988-1993\" style=\"position:relative;\"><a href=\"#%E7%AC%AC%E4%BA%8C%E6%AC%A1ai%E5%AF%92%E5%86%AC1988-1993\" aria-label=\"第二次ai寒冬1988 1993 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>第二次AI寒冬（1988-1993）</h2>\n<p>1988年到1993年，專家系統的商業化價值和成功後，AI領域迎來了第二次的AI crash。這次危機的原因是專家系統暴露出了一些明顯的問題，首先是維護成本極高。專家系統無法處理非結構化資料，且對外界環境的變化反應不足，它只能穩定地處理固定的問題，一旦環境發生變化，系統無法靈活調整，這使得專家系統難以落地實現。</p>\n<p>其次，專家系統的擴展性問題也很嚴重。這些系統依賴手動輸入大量的規則（如 if-then 條件），隨著規則數量的增加，維護難度加大，人工成本逐漸攀升。這使得系統難以擴展，且開發和維護成本高昂，企業也因此放棄了專家系統的應用。</p>\n<p>此外，專家系統並不具備學習能力，它只是按照預設的規則執行，並無法從資料中自我學習和進化，這限制了其發展和應用的潛力。因此，專家系統無法在更大範圍內得到擴展和應用，最終導致了AI領域的第二次低潮。</p>\n<p>另外，一個非常重要的事件發生在1987年。當時，我提到過這些公司全部使用LISP這個程式語言，但在1987年，LISP遭遇了重大顛覆，無論在軟體還是硬體層面。當時，LISP的硬體售價介於7萬到10萬美元之間。然而，在1980年代，SUN Microsystems（生洋電腦）推出了一款工作站，僅需1萬到2萬美元，且其系統性能更好，導致LISP的硬體成本無法與之競爭。</p>\n<p>此外，C語言和UNIX生態系開始崛起，這些新興技術逐步取代了原本的LISP語言。這使得原本依賴LISP的軟體可以直接移植到新的生態系統中，無需依賴舊有的硬體設備。據一位AI科學家的說法，1987年，生洋電腦推出的更具成本效益的UNIX工作站吞併了LISP機器的市場。</p>\n<p>因此，在1987年，AI專用工作站的銷量急劇下降，整個市場的銷量減少了50%。這也導致了大量依賴LISP的AI創業公司在五年間倒閉或被併購。根據統計（雖然我無法提供具體來源），在這段期間，約有300家公司因為這場生態系變革而倒閉，這些公司多數是以LISP為基礎成立的。這一系列事件直接引發了第二次AI寒冬，資金再次撤離這一領域，並且美國政府的戰略計畫也停止了對AI研究的支持。</p>\n<h2 id=\"機器學習的崛起1990-2000\" style=\"position:relative;\"><a href=\"#%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%9A%84%E5%B4%9B%E8%B5%B71990-2000\" aria-label=\"機器學習的崛起1990 2000 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>機器學習的崛起（1990-2000）</h2>\n<p>這就是第二次AI寒冬的結束。隨後，從1990到2000年，機器學習逐漸崛起。經過80年代末期的挫敗，研究者發現專家系統無法繼續發展，因為過去的AI基本上是基於規則的，將各種規則寫進系統。然而，到了1990年代，人們開始意識到，AI應該轉向以數據為驅動力的方向。</p>\n<p>隨著電腦運算能力和數據量的提升，AI進入了一個新的時代。當時，個人電腦的計算能力顯著增強，這為機器學習的興起提供了基礎。1990年，貝爾實驗室的楊立奎（Yann LeCun）使用卷積神經網絡（CNN）來辨識數字，這一技術被應用於郵政編碼和支票識別等領域，這是神經網絡的一個早期應用。</p>\n<p>到了1991年，微軟研究院正式成立，並開始吸引頂尖學者，積極從事語音識別、計算機視覺和對話系統的研究。1992年，Jaron Lanier開發了可以自我對弈的棋類系統，這套系統能夠分析所有可能的棋步，並決定最優的下一步，這展示了AI的潛力和進步。</p>\n<p>這一時期，AI的基礎發生了重要轉變，從基於規則的系統，逐步轉向依賴機率和數據的模型，這是一個根本的底層變革。1994年，Numerous Communication（後來與蘋果公司合作的技術）以及其他語音技術公司開始興起，並逐步形成了語音識別技術的初步商業化。</p>\n<p>1997年，IBM的深藍（Deep Blue）擊敗了世界西洋棋冠軍卡斯帕羅夫，這是AI的重要突破，標誌著深度學習和AI技術的一個里程碑。隨後，1998年，Google成立，而1999年，NVIDIA推出了第一款GPU，這些技術最初主要應用於3D遊戲領域，但也為未來的AI發展奠定了基礎。</p>\n<p>在這個時期，確實可以看到一些技術的突破，特別是在神經網絡應用方面，企業也逐步進入AI領域，例如Google的成立以及GPU的出現。綜觀這段時期，AI的發展經歷了一個重大的轉變，從早期偏向哲學和邏輯推理的思維，逐漸轉向數學建模、數據處理和資料學習的方向。這一時期的AI開始涉及視覺辨識、語音識別等領域，並且有了初步的應用方案，為後來的發展奠定了基礎。</p>\n<p>整體而言，這個時期的AI主要是在積累基礎技術，而真正的突破出現是在2000年之後。這一時期數據驅動的AI和網際網路時代的到來，帶來了大量的海量數據和計算資源的迅速增長。隨著互聯網的普及，AI系統能夠在更大規模的數據上進行訓練，這使得AI的精度有了顯著的提升。例如，2011年推出的姨媽可不如模型（或稱語言模型）就是通過訓練大量的網絡文本，顯著提升了翻譯的品質。</p>\n<p>此外，2004年，Google收購了一家語音技術公司，並且同年，Facebook也成立，這些網絡公司帶來了大量的數據。在Facebook成立後，大量用戶生成的數據進一步推動了AI技術的發展。2005年，Yahoo收購了圖像識別的新創公司，並且同年YouTube成立，這也創造了大量的影音數據，進一步推動了語音和圖像領域的發展。</p>\n<p>在這一時期，隨著AI應用場景的拓展，李飛飛等人於2006年啟動了Imagine.net，進一步推動了圖像識別和人工智能領域的進步。</p>\n<p>在這段時間裡，李飛飛等人啟動了圖像數據庫專案，開始收集數以千計的帶有雕塑圖像的資料。當時他們認識到，要解決這個問題並為未來的AI技術奠定基礎，尤其是圖像識別，這些關鍵的訓練資料是必須的。因此，這項工作成為了未來AI發展的關鍵一步。</p>\n<p>同一年，另一個重要的發展是Jeffrey Hinton（我前面提到的AI科學家）與他的徒弟共同發表了Deep Belief Network，這是無監督式學習的突破，能夠訓練神經網路來提取特徵和信息，並且被認為是Deep Learning的復興起點。事實上，Deep Learning在此之前沉寂了一段時間，但這一事件使得它重新成為了焦點。</p>\n<p>2007年，Facebook成立了AI小組，開始研發新聞推送的演算法，這也顯示出Facebook在AI領域的投入，並且這個發展非常早期。同年，NVIDIA推出了CUDA，這是個重要的里程碑，因為NVIDIA從原本專注於3D繪圖，轉向為AI計算提供加速，對於GPU的應用起到了至關重要的作用。</p>\n<p>到2009年，Stanford大學開始進行自動駕駛實驗，這也促使Google成立了無人駕駛車隊，最終這項研究演變成了今天的Waymo。這一時期也是微軟研究院與Google大量使用神經網絡技術，成功降低語音辨識錯誤率，超越了以往的模型。此外，GPU技術的引入，為這些領域的計算需求提供了強大的支撐，極大地推動了AI技術的發展。</p>\n<p>在這段期間，GPU的加速運算在實驗和訓練中扮演了重要角色，並且在2010年之前，GPU技術就已經開始廣泛應用於AI領域。</p>\n<p>在2011到2012年之間，Google成立了Google Brain，這個項目是由福溫達推動的，最初的目標是讓AI能夠自動觀看影片並識別其中的物體，尤其是辨識出貓。這是因為貓的外觀和行為多樣，AI需要學會理解並區分哪些行為和動作是貓的表現。因此，這個貓的辨識成為了Google Brain最初的實驗任務。</p>\n<h2 id=\"深度學習的突破2010-2012\" style=\"position:relative;\"><a href=\"#%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E7%9A%84%E7%AA%81%E7%A0%B42010-2012\" aria-label=\"深度學習的突破2010 2012 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>深度學習的突破（2010-2012）</h2>\n<p>接下來的2010到2012年，被認為是深度學習的全面突破期。在2011年，IBM的Watson開始引起關注。Watson是在IBM的Deep Blue之後，開始研發的AI系統，並在2011年贏得了智力競賽，這標誌著Watson的應用突破。Watson成功的應用展示了AI技術的商業潛力。</p>\n<p>此外，2012年也是深度學習歷史上的一個重大突破。Jeffrey Hinton（前面提到的神經網路科學家）帶領兩名學生參加了ImageNet視覺辨識挑戰賽。他們使用了一個神經網路模型——AlexNet，並成功地將影像辨識的錯誤率大幅降低，最終贏得了比賽。這個比賽的成功也突顯了深度學習結合GPU的強大潛力，因為以往影像辨識是依賴CPU處理，而2012年是首次有團隊使用GPU來進行這項挑戰，結果顯著提升了性能。值得注意的是，Jeffrey Hinton的兩名學生中，其中一位就是後來成為OpenAI技術長的Lyla，他後來在AI領域取得了重要成就。</p>\n<p>在2012年，Jeffrey Hinton的兩名學生創立了DNN Research公司，這家公司專注於深度學習的研究。2013年，Google收購了這家公司，將Jeffrey Hinton及其團隊引入Google。這一收購標誌著深度學習領域的重要突破，因為這些研究成就加速了AI的進展。</p>\n<p>2014年，出現了一個技術上的重大突破。EM（可能指的是Ian Goodfellow）推出了生成對抗網絡（GAN）的架構。GAN的核心思想是讓兩個神經網絡互相競爭，一個生成假數據，另一個辨別真假，通過這種競爭過程來提升生成效果。這樣的架構開啟了生成AI的時代，AI開始能夠生成近乎真實的圖像和影音內容，這也奠定了生成對抗網絡在現代AI應用中的基礎。</p>\n<p>2016年，Google的DeepMind團隊使用AlphaGo打敗了圍棋世界冠軍，這成為了AI領域的一個重大突破，讓AI的潛力得到了全球關注。</p>\n<h2 id=\"transformer模型的誕生2017\" style=\"position:relative;\"><a href=\"#transformer%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AA%95%E7%94%9F2017\" aria-label=\"transformer模型的誕生2017 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Transformer模型的誕生（2017）</h2>\n<p>2017年，另一個突破性進展來自Google Brain團隊，他們提出了Transformer模型。這個模型解決了以往語言處理中的一個問題，傳統的神經網絡處理文本時是逐字逐字地讀取，無法有效理解上下文和句子的結構。Transformer模型能夠一次性處理大量文本，使AI能夠更好地理解句子結構，這大大提升了語言模型的學習效果。基於Transformer架構的預訓練大語言模型，如今是許多先進AI系統的基礎。</p>\n<p>在2017年，Google發表了突破性論文，提出了Transformer模型。隨後，在2018年，Google發布了BERT模型，並且OpenAI於2018年發表了GPT-1，這是OpenAI開始進軍大型語言模型領域的開始。接著，在2019年，OpenAI公開了GPT-2，這時模型的參數和能力都大幅提升。GPT-2的參數數量已經達到了15億，這使得AI開始能夠生成流暢且有邏輯性的文本，打破了之前的語言生成局限，能夠創造出更加可讀的文字。</p>\n<p>你提到的李飛飛，確實是這波AI領域崛起的關鍵人物之一，她在圖像識別和深度學習領域的貢獻是不可忽視的。關於GPT系列的發展，也離不開這些背後的關鍵人物，正是這些人的努力，讓AI技術進步得如此迅速。</p>\n<p>此外，張忠謀在半導體產業的成功，也正如你所說，得益於他在德雲環境中的深厚訓練和格局。這些人物的背景與貢獻，對現代科技產業的發展起到了決定性作用。</p>\n<p>至於OpenAI在2020年推出的GPT-3，這款模型的參數已經達到了1750億，與GPT-2相比，參數的增加使得GPT-3能夠處理更複雜的語言任務，並生成更高質量的文本，這也是AI領域的一個重大突破。</p>\n<p>你提到的關鍵人物，無論是AI領域的李飛飛、Jeffrey Hinton，還是半導體界的張忠謀，他們的影響力確實對當今科技發展有深遠影響。</p>\n<p>經由海量文本進行預訓練，GPT-3展現出了令人驚訝的自然語言生成能力。它可以透過你的Chrome自動編寫文章或產生對話，開始在某些任務上接近人類水平。到了2022年，GPT-3的能力被進一步確定和完善，這也標誌著大語言模型的快速發展，至今已經突破性的出現。</p>\n<p>我的takeaway是，首先我認為AI發展的脈絡主要聚焦於兩次大的起伏。第一次AI崛起時，學術界主導了這一波熱潮，圖靈測試提出了關於人工智慧的基本問題，AI研討會也成為了這一領域的重要推動力。當時的頂尖科學家及其後繼者，對AI領域產生了深遠的影響，並且在學術界引領了AI的所有後續發展。這段歷史其實和半導體歷史中那些關鍵人物的故事相似，也可以在軟體領域找到類似的情況。</p>\n<p>那時候，學界對AI充滿激情和期待，AI的發展也處於一個非常激動人心的階段。早期的AI應用，如Aliza聊天機器人和Shaking機器人等，雖然看似初步，但也揭示了AI的潛力。然而，這一波熱潮隨後迎來了第一次的崩潰，因為計算力、存儲以及資料的不足，讓人們發現AI無法解決現實世界中的複雜問題。因此，早期的資金支持，特別是來自政府的資金，開始大量撤出AI領域。</p>\n<p>第二次的崛起，則是AI進入專業領域，成為某些領域的專家。它根據特定領域的工作和需求，將邏輯輸入系統中，成功實現商業化。例如，我提到的DEC（數字設備公司）就成功利用AI，每年節省了4000萬美元的成本。</p>\n<p>根據當時的架構，許多新創軟體和硬體公司在那時期相繼成立，這些公司當時的歷史語境與硬體和軟體的綁定密切相關。然而，隨著通用硬體的持續進化，特別是像生揚電腦這樣的公司在不斷迭代的過程中，成本大幅下降，同時效能顯著上升，這使得過去這種綁定策略逐漸變得不再有效。結果，那些基於這種綁定策略的新創公司也面臨了破產的命運。</p>\n<p>回顧整個AI的發展浪潮，我們當下所處的這波AI熱潮，其實可以追溯到1995年。當時，深度學習仍處於起步階段，並未廣泛被應用，但這一年的開始，為未來的發展奠定了基礎。</p>\n<p>這一波被稱為第三次AI崛起。在這次崛起中，學術界轉向了數據驅動的機器學習（Machine Learning）。這項技術經過了十多年持續的積累和堆疊，逐漸成熟。2000年後，互聯網的崛起為這場革命提供了大量的數據和計算資源，這些都為AI的突破和進步提供了無與倫比的條件，使得AI可以在大規模數據上進行訓練，從而帶來重大突破。</p>\n<p>接下來，深度學習的突破便成為了關鍵的推動力。在這一過程中，像李飛飛等人對深度學習理論的貢獻，為我們現在所看到的深層式AI奠定了堅實的基礎，也使得今天的大語言模型能夠如雨後春筍般蓬勃發展，成為現今AI領域的主流技術。</p>\n<p>我目前總結起來的觀察是這樣的。從投資的角度來看，有幾個重要的啟示。首先，從第一次的崩潰（Crash）中，我們可以看到，一旦計算力（Compute）、儲存空間（Storage）和數據（Data）這三個要素遇到瓶頸，它們將會限制當時AI的發展進程。後來的技術突破，實際上都是圍繞著這三個領域展開，因此可以預見，這三者很可能是AI產業的關鍵驅動力，而並非僅僅是模型本身，像是大語言模型（Large Language Models）可能並不是唯一的關鍵。</p>\n<p>第二個啟示是，從第二次崩潰中，我們看到了應用端的挑戰。具體來說，應用端必須解決成本、投資回報率（ROI）和擴展性這三個關鍵問題。如果這些問題無法得到有效解決，AI的發展就會停滯。因此，當時的Lisk被聖揚電腦顛覆，這一顛覆其實是在軟體和硬體兩個層面上的全面革新。那些建立在這種過時架構上的公司最終會被淘汰。因此，這一歷史經驗對我們今天的AI發展是一個很好的借鏡。</p>","headings":[{"value":"AI概念的萌芽期","depth":2,"id":"ai概念的萌芽期"},{"value":"第一次AI寒冬（1970-1980）","depth":2,"id":"第一次ai寒冬1970-1980"},{"value":"專家系統的興起（1980-1988）","depth":2,"id":"專家系統的興起1980-1988"},{"value":"第二次AI寒冬（1988-1993）","depth":2,"id":"第二次ai寒冬1988-1993"},{"value":"機器學習的崛起（1990-2000）","depth":2,"id":"機器學習的崛起1990-2000"},{"value":"深度學習的突破（2010-2012）","depth":2,"id":"深度學習的突破2010-2012"},{"value":"Transformer模型的誕生（2017）","depth":2,"id":"transformer模型的誕生2017"}],"frontmatter":{"title":"Jack談AI歷史","date":"March 25, 2025","description":"這篇文章探討了人工智慧（AI）的歷史發展，從1950年代的圖靈測試開始，經歷了兩次AI的崛起與崩潰，直到現今的深度學習和大語言模型的興起。文章中提到的關鍵人物包括圖靈、John McCarthy、Marvin Minsky、Jeffrey Hinton、李飛飛等，他們在AI的不同階段中扮演了重要角色。AI的發展歷程中，學術界和產業界的互動，以及計算能力、數據和儲存空間的進步，都是推動AI技術進步的關鍵因素","categories":["Turing","John McCarthy","Marvin Minsky","Jeffrey Hinton","李飛飛","人工智慧","深度學習","大語言模型","2025"]}}},"pageContext":{"id":"a38b3903-37fd-5de7-9ff0-7e48b1e1f658","previousPostId":"0e7c23ec-695f-5834-8f0d-65c0b8058872","nextPostId":"1a2578bf-f3be-5793-bfbc-d2cc63eea345"}},"staticQueryHashes":["1324386404"],"slicesMap":{}}